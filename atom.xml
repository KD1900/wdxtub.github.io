<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小土刀</title>
  <subtitle>Agony is my triumph</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wdxtub.com/"/>
  <updated>2016-11-19T08:29:45.000Z</updated>
  <id>http://wdxtub.com/</id>
  
  <author>
    <name>wdxtub</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>『通天塔』作品集介绍</title>
    <link href="http://wdxtub.com/2016/11/19/babel-series-intro/"/>
    <id>http://wdxtub.com/2016/11/19/babel-series-intro/</id>
    <published>2016-11-19T04:12:12.000Z</published>
    <updated>2016-11-19T08:29:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>『通天塔』作品集源于我和华章两位老师的畅谈后萌生的想法，是我在计算机学科教育上一系列尝试的第一步。本文聊聊我做这事儿的『初心』。</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<ul>
<li>2016.11.19: 初稿完成</li>
</ul>
<h2 id="为什么要写？"><a href="#为什么要写？" class="headerlink" title="为什么要写？"></a>为什么要写？</h2><p>通天塔也叫<a href="https://zh.wikipedia.org/wiki/%E5%B7%B4%E5%88%A5%E5%A1%94" target="_blank" rel="external">巴别塔</a> ，传说中的故事是这样的：</p>
<blockquote>
<p>当时地上的人们都说同一种语言，当人们离开东方之后，他们来到了示拿之地。在那里，人们想方设法烧砖好让他们能够造出一座城和一座高耸入云的塔来传播自己的名声，以免他们分散到世界各地。上帝来到人间后看到了这座城和这座塔，说一群只说一种语言的人以后便没有他们做不成的事了；于是上帝将他们的语言打乱，这样他们就不能听懂对方说什么了，还把他们分散到了世界各地，这座城市也停止了修建。这座城市就被称为“巴别城”。（来自维基百科）</p>
</blockquote>
<p>之所以为作品集取名『通天塔』，当然是希望能借用其中的隐喻，即使不能『通天』，能站得高一点，也许能看到更好的风景。</p>
<p>兴趣是最好的老师，『通天塔作品集』想成为的是对计算机学科感兴趣的同学的『助教』，至少让有志于此的朋友们在追求知识的道路上不太孤单。</p>
<p>我不喜欢培训班的短平快，也痛心于高校与业界的脱节，想找到一种方式，能够把原理和基础说明白的同时，通过实际可操作的案例来让大家意识到自己学习的东西是有用的，凭借自己的努力可以打造出不一样的东西。</p>
<p>于是便有了『通天塔』这个系列。</p>
<h2 id="能给读者带来什么？"><a href="#能给读者带来什么？" class="headerlink" title="能给读者带来什么？"></a>能给读者带来什么？</h2><p>以下几点是我非常想要借助『通天塔』系列带给读者的：</p>
<ul>
<li>学以致用的思维与能力</li>
<li>好奇心与打破沙锅问到底</li>
<li>计算机系统基础知识的理解</li>
<li>业界常见解决方案的使用</li>
<li>架构和系统设计的思路</li>
<li>发现问题解决问题的能力</li>
<li>安排计划，学会学习的能力</li>
</ul>
<p>当然，博客的形式还是有较多局限的，对读者的要求也比较高，不会有人催促，甚至也不会有及时的答疑，一切靠自己。另外，系统和解决方案的构建大多是从单机开始再拓展到集群，在流程和规范上肯定不如大公司来的专业，不过只要知道了原理，其实工作一段时间自然就会掌握。</p>
<h2 id="主要写什么？"><a href="#主要写什么？" class="headerlink" title="主要写什么？"></a>主要写什么？</h2><p>基于自己的工作和实践，目前的已经列入计划的有：</p>
<ul>
<li>日志分析平台：基于 ElasticStack</li>
<li>数据平台：存储采用 Elasticsearch，后端用 Go，前端用 jQuery</li>
<li>静态博客：打造自己的品牌</li>
<li>W.I.S.E：详情可见<a href="http://wdxtub.com/2016/10/17/wise-plan/">W.I.S.E 计划</a></li>
</ul>
<p>如果大家有任何意见或者建议，欢迎以各种方式跟我聊聊，联系方式可以在<a href="http://wdxtub.com/thanks/">这里</a>找到</p>
<h2 id="写作格式"><a href="#写作格式" class="headerlink" title="写作格式"></a>写作格式</h2><p>每一篇都会包含：</p>
<ul>
<li>系列目录：方便查阅</li>
<li>任务目标：带着目的学习</li>
<li>试一试：实践部分</li>
<li>总结：回顾学过的内容</li>
</ul>
<p>这四个固定模块，完成每篇文章的任务后，都会有一个可交付可展示的东西，像打怪升级一样，以此鼓励大家。</p>
<h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>『通天塔』作品集会是一个长期的项目，希望对此感兴趣的同学和朋友能够以远程合作的形式参与进来，众人拾柴火焰高嘛。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;『通天塔』作品集源于我和华章两位老师的畅谈后萌生的想法，是我在计算机学科教育上一系列尝试的第一步。本文聊聊我做这事儿的『初心』。&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="通天塔" scheme="http://wdxtub.com/tags/%E9%80%9A%E5%A4%A9%E5%A1%94/"/>
    
      <category term="原理" scheme="http://wdxtub.com/tags/%E5%8E%9F%E7%90%86/"/>
    
      <category term="实践" scheme="http://wdxtub.com/tags/%E5%AE%9E%E8%B7%B5/"/>
    
      <category term="尝试" scheme="http://wdxtub.com/tags/%E5%B0%9D%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>【通天塔之日志分析平台】零 系列简介与环境配置</title>
    <link href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-0/"/>
    <id>http://wdxtub.com/2016/11/19/babel-log-analysis-platform-0/</id>
    <published>2016-11-19T03:11:11.000Z</published>
    <updated>2016-11-21T14:27:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>作为开篇，本文会介绍『日志分析平台』系列的内容梗概并完成基本的环境配置。作为『通天塔』这一技术主题合集的首个系列，我会尝试和『读薄/读厚 CSAPP』系列不一样的风格，但是目的是一致的，就是让感兴趣的朋友少走点弯路。</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<ul>
<li>2016.11.19: 初稿完成</li>
</ul>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><ul>
<li><a href="http://wdxtub.com/2016/11/19/babel-series-intro/">『通天塔』技术作品合集介绍</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-0/">零 系列简介与环境配置</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-1/">壹 ELK 环境搭建</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-2/">贰 Kafka 缓冲区</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-3/">叁 监控、安全、报警与通知</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-4/">肆 从单机到集群</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-5/">伍 Logstash 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-6/">陆 Elasticsearch 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-7/">柒 Kibana 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-8/">捌 实例：接入外部应用日志</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-9/">玖 业界：大厂实践</a></li>
</ul>
<h2 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h2><ol>
<li>理解日志分析平台出现的背景</li>
<li>掌握日志从收集、传输到最终统一处理的基本流程中的重要概念</li>
<li>了解 ElasticStack 的各个组成部分及对应的角色</li>
<li>配置好 Linux 基本环境，为之后的工作打好基础</li>
</ol>
<h2 id="什么是日志分析平台"><a href="#什么是日志分析平台" class="headerlink" title="什么是日志分析平台"></a>什么是日志分析平台</h2><p>要回答这个问题，先得弄清楚什么是日志。于是让我们把记忆拉回刚学编程那会儿，想想当时我们是如何写程序运行程序的。具体很多细节我已经记不太清楚，但是把需要检测的变量用 <code>printf</code> 输出到命令行这个简单粗暴的方法，到现在我还时不时会用到。这其实就可以看做是一个『记日志』的行为，虽然非常不靠谱，但是仍提供给我们一些有用的信息。</p>
<p>代码多了之后，想要弄清楚程度到底在干嘛，干到哪一步了，最好的方法就是在每一步的时候输出一些信息，这样出了问题至少能够知道最后运行正常的部分。除了排错之外，日志本身也能给我们提供非常有价值的信息，比方说服务器提供了 100 个对外接口（假设这些接口是并行的，即关闭哪个都无所谓），忽然老板说我们不能提供这么多，只能保留 50 个。那怎么确定要关闭哪五十个呢？其中一个方法就是把访问次数最少的那些给干掉。这时候我们就可以把过去一个星期的日志找出来，统计一下各个接口的使用情况（假设每次接口被访问都会生成一条日志），然后就能排个序，确定需要去掉的接口了。</p>
<p>回顾一下这整个过程：</p>
<ol>
<li>我们提供一些服务，这些服务每被访问一次都会生成一条日志</li>
<li>一般来说我们会把程序产生的日志按日切割，也就是每天会生成一个新的日志文件</li>
<li>有的时候我们需要对大量日志进行统计以得到某些数据</li>
</ol>
<p>当我们的服务只部署在一台服务器上的时候，所有的日志都在同一个地方，基本的统计可以通过 shell 命令配合管道完成。比方说我们想知道接口每天被访问的次数，直接 <code>wc -l date.log</code> 即可，完全不需要费心去折腾什么日志分析平台。但是，随着服务量的增长，原来一行可以搞定的事情变得非常麻烦。</p>
<p>当我们的服务部署在十台服务器上的时候，日志分散在十个地方，基本的统计首先需要在每台服务器上进行，然后再汇总起来。用前面的例子，统计次数的过程就是把原来的命令在十个地方敲十次。这其实还不是最糟的，如果需要跨机器排个序什么的，就…</p>
<p>所以这个时候，日志分析平台应运而生，一般来说套路分三步：</p>
<ol>
<li>把分散在各个机器的日志汇总到一个地方(Shipper, Broker, Indexer)</li>
<li>把这些日志用某种方式保存并索引起来(Search &amp; Storage)</li>
<li>需要的时候直接在汇总的日志中查询(Web Interface)</li>
</ol>
<p><img src="/images/14795970842446.gif" alt=""></p>
<p>听起来没有很麻烦，因为原理大约总是简单的，但具体到做工程，就有各种问题各种坑了。我个人是不提倡自己重新造轮子的（确实没必要），除了现在很多现成的日志分析平台服务之外，我们也可以选择利用开源的力量自己搭建一个日志分析平台。</p>
<p>这也是正是这个系列想要教给大家的。我会从单机系统说起，最后扩展到集群和更复杂的解决方案。</p>
<h2 id="为什么选择-ElasticStack"><a href="#为什么选择-ElasticStack" class="headerlink" title="为什么选择 ElasticStack"></a>为什么选择 ElasticStack</h2><p>（开个玩笑）原因很简单：因为我在用。</p>
<p>（言归正传）ElasticStack 经过这几年的快速发展，版本号一路从 1.0 狂飙到 5.0（这个真的不是在黑），基本上形成了和 <a href="http://flume.apache.org/" target="_blank" rel="external">Flume</a>分庭抗礼的局面。至于为什么，可能是因为大家都喜欢简单粗暴颜高活好不粘人的解决方案吧。</p>
<p>ElasticStack 最初的核心是 ELK(Elasticsearch, Logstash, Kibana) 三兄弟。其中 Logstash 收集数据，Elasticsearch 索引数据，Kibana 展示数据。</p>
<ul>
<li>Elasticsearch 背靠 Lucene 这一老牌劲旅做到了准实时全文索引</li>
<li>Logstash 的配置直接是 Ruby DSL，非常灵活简单</li>
<li>Kibana 则自带各种查询聚合以及生成报表功能。</li>
</ul>
<p>再加上查询简单、扩展容易之类的特点，大受欢迎其实也在情理之中。官方也在不断吸收社区精华的同时开发了安全、报警、监控、报告等一系列功能，再加上能够轻松和 Hadoop 这类分布式计算框架配合，怎么看都是非常不错的选择。</p>
<h2 id="系列内容"><a href="#系列内容" class="headerlink" title="系列内容"></a>系列内容</h2><p>『通天塔之日志分析平台』这个系列的主要是内容是和大家一起一步一步搭建起来一个完整的日志分析平台，具体的内容通过前面的目录应该能够略知一二，会包含业界通用的解决方案，在介绍原理的同时，每一章都会有一定的产出，这样在学习的时候比较不容易懈怠。</p>
<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><p>关于 ElasticStack 的更多详细介绍会在接下来的文章中继续，现在我们先把系统准备好吧。考虑到现在大部分服务器都在跑 Linux，所以本文会以 Ubuntu 64bit 14.04 这个长期支持版本来作为我们的操作系统。我目前在用的是 MacBook Pro(Retina, 13’, Late 2013)，8GB 内存 2.4 GHz 的 i5，在虚拟机里跑 Ubuntu。</p>
<p>ElasticStack 对系统和软件的配置要求并不高，我们只需要安装 JDK 即可。可以用如下的命令或者是我已经写好的脚本<a href="https://github.com/wdxtub/wdxtools/blob/master/linux-script/ubuntu-java-install.sh" target="_blank" rel="external"><code>ubuntu-java-install.sh</code></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># 添加源 </div><div class="line">sudo add-apt-repository -y ppa:webupd8team/java</div><div class="line"># 更新地址 </div><div class="line">sudo apt-get update</div><div class="line"># 安装 </div><div class="line">sudo apt-get -y install oracle-java8-installer</div></pre></td></tr></table></figure>
<h2 id="试一试"><a href="#试一试" class="headerlink" title="试一试"></a>试一试</h2><p>因为是序章，所以实践的任务比较简单：</p>
<ul>
<li>在命令行中输入 <code>java -version</code>，看看输出是什么</li>
<li>访问 elastic 的<a href="https://www.elastic.co/" target="_blank" rel="external">官方网站</a>，并简单浏览各个产品的信息</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>相信大家现在已经对我们接下来要做的『日志分析平台』有基本的概念了，如果还有不明白的地方也不要担心，带着未知往前走，其实也是非常有意思的过程。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作为开篇，本文会介绍『日志分析平台』系列的内容梗概并完成基本的环境配置。作为『通天塔』这一技术主题合集的首个系列，我会尝试和『读薄/读厚 CSAPP』系列不一样的风格，但是目的是一致的，就是让感兴趣的朋友少走点弯路。&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="通天塔" scheme="http://wdxtub.com/tags/%E9%80%9A%E5%A4%A9%E5%A1%94/"/>
    
      <category term="日志" scheme="http://wdxtub.com/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="平台" scheme="http://wdxtub.com/tags/%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="环境" scheme="http://wdxtub.com/tags/%E7%8E%AF%E5%A2%83/"/>
    
  </entry>
  
  <entry>
    <title>【通天塔之日志分析平台】壹 ELK 环境搭建</title>
    <link href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-1/"/>
    <id>http://wdxtub.com/2016/11/19/babel-log-analysis-platform-1/</id>
    <published>2016-11-19T03:11:10.000Z</published>
    <updated>2016-11-22T12:48:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>前一讲我们对 ElasticStack 进行了简要介绍并完成了基本的系统环境配置，这一次我们要把 Elasticsearch/Logstash/Kibana 安装配置好，并把 Linux 的系统日志导入进来。</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<ul>
<li>2016.11.21: 完成初稿</li>
</ul>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><ul>
<li><a href="http://wdxtub.com/2016/11/19/babel-series-intro/">『通天塔』技术作品合集介绍</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-0/">零 系列简介与环境配置</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-1/">壹 ELK 环境搭建</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-2/">贰 Kafka 缓冲区</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-3/">叁 监控、安全、报警与通知</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-4/">肆 从单机到集群</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-5/">伍 Logstash 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-6/">陆 Elasticsearch 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-7/">柒 Kibana 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-8/">捌 实例：接入外部应用日志</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-9/">玖 业界：大厂实践</a></li>
</ul>
<h2 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h2><ol>
<li>掌握并完成 Elasticsearch, Logstash 和 Kibana 的安装配置</li>
<li>了解 Linux 系统日志的内容及保存位置，并利用 Logstash 导入到 Elasticsearch 中，最终由 Kibana 展示</li>
<li>掌握 Linux 的进程控制机制，学会如何启动和关闭前台/后台应用</li>
</ol>
<h2 id="安装与启动"><a href="#安装与启动" class="headerlink" title="安装与启动"></a>安装与启动</h2><p>无论是 Elasticsearch, Logstash 还是 Kibana，我们都推荐手动安装的方式，毕竟不涉及太多配置操作，用 <code>apt-get</code> 反而有些用牛刀杀鸡了。这里我们直接上命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 进入用户文件夹</span></div><div class="line"><span class="built_in">cd</span> ~</div><div class="line"><span class="comment"># 下载 Elasticsearch</span></div><div class="line">wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.0.1.tar.gz</div><div class="line"><span class="comment"># 下载 Logstash</span></div><div class="line">wget https://artifacts.elastic.co/downloads/logstash/logstash-5.0.1.tar.gz</div><div class="line"><span class="comment"># 下载 Kibana</span></div><div class="line">wget https://artifacts.elastic.co/downloads/kibana/kibana-5.0.1-linux-x86_64.tar.gz</div><div class="line"></div><div class="line"><span class="comment"># 解压 </span></div><div class="line">tar -xvf elasticsearch-5.0.1.tar.gz</div><div class="line">tar -xvf logstash-5.0.1.tar.gz</div><div class="line">tar -xvf kibana-5.0.1-linux-x86_64.tar.gz</div><div class="line"></div><div class="line"><span class="comment"># 把安装包保存到固定文件夹中，这里叫 software</span></div><div class="line">mv elasticsearch-5.0.1.tar.gz software/mv kibana-5.0.1-linux-x86_64.tar.gz software/mv logstash-5.0.1.tar.gz software/</div></pre></td></tr></table></figure>
<p>解压完成之后，ElasticStack 运行前的准备就基本完成了。Logstash 可以在需要时再启用，这里我们先把 Elasticsearch 和 Kibana 给启动起来（这里我们继续用 tmux，关于 tmux 的使用可以参考我写的<a href="http://wdxtub.com/2016/03/30/tmux-guide/">tmux 指南</a>）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 新建 tmux session</span></div><div class="line">tmux</div><div class="line"><span class="comment"># 启动 Elasticsearch</span></div><div class="line"><span class="comment"># 这里注意，最好虚拟机有 4G 内存，不然很容易卡死</span></div><div class="line"><span class="built_in">cd</span> elasticsearch-5.0.1/bin; ./elasticsearch</div><div class="line"><span class="comment"># 启动 Kibana</span></div><div class="line"><span class="built_in">cd</span> kibana-5.0.1-linux-x86_64/; ./bin/kibana</div></pre></td></tr></table></figure>
<p>打开浏览器，访问 <code>localhost:5601</code>，如果看到如下所示的页面，Elasticsearch 和 Kibana 基本就没问题了。</p>
<p><img src="/images/14797108735042.jpg" alt=""></p>
<p>然后我们体验一下 Logstash，输入下列命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 进入文件夹</span></div><div class="line"><span class="built_in">cd</span> logstash-5.0.1/</div><div class="line"><span class="comment"># 启动 logstash，输入和输出均为命令行</span></div><div class="line">bin/logstash <span class="_">-e</span> <span class="string">'input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;'</span></div></pre></td></tr></table></figure>
<p>然后我们随意输入一些内容，显示为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">parallels@ubuntu:~/logstash-5.0.1$ bin/logstash <span class="_">-e</span> <span class="string">'input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;'</span>wdxtub.com updatedSending Logstash<span class="string">'s logs to /home/parallels/logstash-5.0.1/logs which is now configured via log4j2.propertiesThe stdin plugin is now waiting for input:[2016-11-20T22:54:20,014][INFO ][logstash.pipeline        ] Starting pipeline &#123;"id"=&gt;"main", "pipeline.workers"=&gt;2, "pipeline.batch.size"=&gt;125, "pipeline.batch.delay"=&gt;5, "pipeline.max_inflight"=&gt;250&#125;[2016-11-20T22:54:20,038][INFO ][logstash.pipeline        ] Pipeline main started[2016-11-20T22:54:20,088][INFO ][logstash.agent           ] Successfully started Logstash API endpoint &#123;:port=&gt;9600&#125;2016-11-21T06:54:20.036Z ubuntu wdxtub.com updatedwdxtub.com is a personal blog2016-11-21T06:54:41.187Z ubuntu wdxtub.com is a personal blogwdxtub.com is created in 20152016-11-21T06:54:55.190Z ubuntu wdxtub.com is created in 2015</span></div></pre></td></tr></table></figure>
<p>至此，ElasticStack 三大组件都已经运行了一次，我们可以用一个实际的任务来上手了。不过开始之前，我们来简单了解一下 ElasticStack 的发展历程。</p>
<h2 id="ElasticStack-5-0-的变化"><a href="#ElasticStack-5-0-的变化" class="headerlink" title="ElasticStack 5.0 的变化"></a>ElasticStack 5.0 的变化</h2><p>ElasticStack 之所以版本一开始就是 5.0，主要原因是把各个产品进行版本统一。5.0 之前，Elasticsearch 的版本是 2.4，Logstash 的版本也是 2.4，但是 Kibana 是 4.5。这样一来开发者其实很难把各个组件对应起来，于是 Elastic 公司干脆直接统一到 5.0，皆大欢喜。</p>
<p>考虑到不是所有的朋友都有接触过 2.4 及之前版本的 ElasticStack，所以这部分会简明扼要介绍一下 5.0 版本的重大改变：</p>
<ul>
<li>Elasticsearch 的底层引擎是 Lucene，5.0 版本中集成了 Lucene6， 新增的多维浮点字段特性极大提高了对 <code>date</code>, <code>numeric</code>, <code>ip</code> 等类型字段的操作的性能。更直观一点说：磁盘空间少一半；索引时间少一半；查询性能提升25%（底层采用 k-d 树编码，更多信息可以在 <a href="http://lucene.apache.org/" target="_blank" rel="external">Lucene 官网</a>中查阅）</li>
<li>Instant Aggregations 特性在 Shard 层级提供了聚合结果的缓存，如果数据没有变化，Elasticsearch 可以直接返回上次的结果</li>
<li>Scliced Scroll 操作允许并发进行数据遍历，大大提升索引重建和遍历的速度</li>
<li>Profile API 可以帮助进行查询的优化，通过确定每个组件的性能消耗来进行优化（设置 <code>profile:true</code> 即可）</li>
<li>Shrink API 可以对分片(Shard)数量进行收缩（从前是不能更改的），利用这个特性，我们可以在写入压力非常大的收集阶段，设置足够多的索引，充分利用shard的并行写能力，索引写完之后收缩成更少的shard，提高查询性能（利用系统的 Hardlink 来进行链接，速度很快）</li>
<li>Rollover API 可以帮助我们按日切割日志，只需要简单的配置即可更加方便灵活分割日志，不用原来 <code>[YYYY-MM-DD]</code> 这样的模板了</li>
<li>Wait for Refresh 提供了文档级别的刷新</li>
<li>Ingest Node 可以直接在建立索引的时候对数据进行加工，这个功能还是很强大的</li>
<li>Task Manager 任务调度管理，来做离线任务</li>
</ul>
<p>总而言之，5.0 是目前最好的一个 ElasticStack 版本，增加了很多新功能，非常值得试一试，更加详细的变动可以查看如下链接，这里不再赘述</p>
<ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/breaking-changes.html" target="_blank" rel="external">Elasticsearch 5.0 Breaking Changes</a></li>
<li><a href="https://www.elastic.co/guide/en/kibana/current/breaking-changes.html" target="_blank" rel="external">Kibana 5.0 Breaking Changes</a></li>
<li><a href="https://www.elastic.co/guide/en/logstash/current/breaking-changes.html" target="_blank" rel="external">Logstash 5.0 Breaking Changes</a></li>
</ul>
<p>接下来我们先简单了解一下 Elasticsearch 的基本概念，然后就可以上手来完成一个小小的实例了。</p>
<h2 id="Elasticsearch-快速入门"><a href="#Elasticsearch-快速入门" class="headerlink" title="Elasticsearch 快速入门"></a>Elasticsearch 快速入门</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>和 Mongodb 的思路类似，Elasticsearch 中保存的是整个文档(document)，并且还会根据文档的内容进行索引，于是我们得以进行搜索、排序和过滤等操作。在 Elasticsearch 中，利用 JSON 来表示文档。举个例子，下面的 JSON 文档就表示一个用户对象：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="attr">"email"</span>: <span class="string">"dawang@wdxtub.com"</span>,</div><div class="line">    <span class="attr">"name"</span>: <span class="string">"Da Wang"</span>,</div><div class="line">    <span class="attr">"info"</span>: &#123;</div><div class="line">        <span class="attr">"bio"</span>: <span class="string">"Sharp Blade, Shape Mind"</span>,</div><div class="line">        <span class="attr">"age"</span>: <span class="string">"25"</span>,</div><div class="line">        <span class="attr">"interests"</span>: [<span class="string">"games"</span>, <span class="string">"music"</span>]</div><div class="line">    &#125;,</div><div class="line">    <span class="attr">"birthday"</span>: <span class="string">"1990/09/11"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在 Elasticsearch 中存储数据的行为就叫做索引(indexing)，而前面提到的文档，属于一种类型(type)，这里类型会存在索引(index)中，如果列一个表来和传统数据库比较，大概是这样的：</p>
<table>
<thead>
<tr>
<th style="text-align:center">关系型数据</th>
<th style="text-align:center">Elasticsearch</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Databases</td>
<td style="text-align:center">Indices</td>
</tr>
<tr>
<td style="text-align:center">Tables</td>
<td style="text-align:center">Types</td>
</tr>
<tr>
<td style="text-align:center">Rows</td>
<td style="text-align:center">Documents</td>
</tr>
<tr>
<td style="text-align:center">Columns</td>
<td style="text-align:center">Fields</td>
</tr>
</tbody>
</table>
<p>一个 Elasticsearch 集群可以包含多个索引(indices，对应于『数据库』)，每个索引可以包含多个类型(types，对应于『表』)，每个类型可以包含多个文档(document，对应于『行』)，每个文档可以包含多个字段(fields，对应于『列』)</p>
<p>这里有一点需要强调一下，前面出现了两种『索引』，第一种，索引(indexing，动词，对应于关系型数据库的插入 insert)指的是把一个文档存储到索引(index，名词) 中；第二种的索引(index，名词）对应于关系型数据库的数据库，这里一定要根据上下文来进行理解。一般来说，我们会对数据库增加索引（这里是第三种意思，就是传统的索引的定义）来提高检索效率，Elasticsearch 和 Lucene 使用『倒排索引』的数据结构来完成这个工作（传统数据库一般用红黑树或者 B 树来完成）。默认情况下，文档中的每个字段都会拥有其对应的倒排索引，Elasticsearch 也是通过这个来进行检索的。</p>
<h3 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h3><p>我们用一个简单的例子来感受一下 Elasticsearch 的威力吧。设定一个场景，有一天我开了一家名为 “ohmywdx” 的公司，我需要为每个公司里的员工创建记录，我需要做的是：</p>
<ul>
<li>为每个员工的文档(document)建立索引，每个文档包含一个员工的各类信息，类型为 <code>wdxtuber</code></li>
<li><code>wdxtuber</code> 类型属于索引 <code>ohmywdx</code>（这里的索引对应于数据库）</li>
<li><code>ohmywdx</code> 索引存储在 Elasticsearch 集群中</li>
</ul>
<p>我们先来插入几条员工记录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">PUT /ohmywdx/wdxtuber/1</div><div class="line">&#123;</div><div class="line">    <span class="string">"name"</span>: <span class="string">"Da Wang"</span>,</div><div class="line">    <span class="string">"age"</span>: 25,</div><div class="line">    <span class="string">"about"</span>: <span class="string">"First one who is stupid enough to join this company"</span>,</div><div class="line">    <span class="string">"interests"</span>: [<span class="string">"game"</span>, <span class="string">"music"</span>]</div><div class="line">&#125;</div><div class="line"></div><div class="line">PUT /ohmywdx/wdxtuber/2</div><div class="line">&#123;</div><div class="line">    <span class="string">"name"</span>: <span class="string">"Tracy Bryant"</span>,</div><div class="line">    <span class="string">"age"</span>: 20,</div><div class="line">    <span class="string">"about"</span>: <span class="string">"First basketball robot for our company"</span>,</div><div class="line">    <span class="string">"interests"</span>: [<span class="string">"guard"</span>, <span class="string">"forward"</span>]</div><div class="line">&#125;</div><div class="line"></div><div class="line">PUT /ohmywdx/wdxtuber/3</div><div class="line">&#123;</div><div class="line">    <span class="string">"name"</span>: <span class="string">"Shadow Mouse"</span>,</div><div class="line">    <span class="string">"age"</span>: 50,</div><div class="line">    <span class="string">"about"</span>: <span class="string">"Secret agent for our company"</span>,</div><div class="line">    <span class="string">"interests"</span>: [<span class="string">"guitar"</span>, <span class="string">"sugar"</span>]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>具体怎么插入呢，我们可以使用 Kibana 5.0 自带的 Dev Tools 来折腾，把上面的命令粘贴到左边的输入框，然后点击绿色的运行按钮，就可以在右边看到结果了：</p>
<p><img src="/images/14797196056865.jpg" alt=""></p>
<p>按照这个套路，继续把其他两个人的资料插入 Elasticsearch。</p>
<p>有了数据之后，我们来看看如何搜索，简单来说，按照存储的方式来检索即可，不过这里我们使用 GET 方法，如下图所示：</p>
<p><img src="/images/14797197975730.jpg" alt=""></p>
<p>我们可以看到，原始文档内容包含在 <code>_source</code> 字段中。如果说这个搜索太明确了，啥都指定了没意思，我们可以来试试看下面几条搜索</p>
<ul>
<li><code>GET /ohmywdx/wdxtuber/_search</code></li>
<li><code>GET /ohmywdx/wdxtuber/_search?q=name:Da</code></li>
</ul>
<p>这里我们来看看第二个搜索的结果</p>
<figure class="highlight json"><table><tr><td class="code"><pre><div class="line">&#123;  <span class="attr">"took"</span>: <span class="number">11</span>,  <span class="attr">"timed_out"</span>: <span class="literal">false</span>,  <span class="attr">"_shards"</span>: &#123;    <span class="attr">"total"</span>: <span class="number">5</span>,    <span class="attr">"successful"</span>: <span class="number">5</span>,    <span class="attr">"failed"</span>: <span class="number">0</span>  &#125;,  <span class="attr">"hits"</span>: &#123;    <span class="attr">"total"</span>: <span class="number">1</span>,    <span class="attr">"max_score"</span>: <span class="number">0.25811607</span>,    <span class="attr">"hits"</span>: [      &#123;        <span class="attr">"_index"</span>: <span class="string">"ohmywdx"</span>,        <span class="attr">"_type"</span>: <span class="string">"wdxtuber"</span>,        <span class="attr">"_id"</span>: <span class="string">"1"</span>,        <span class="attr">"_score"</span>: <span class="number">0.25811607</span>,        <span class="attr">"_source"</span>: &#123;          <span class="attr">"name"</span>: <span class="string">"Da Wang"</span>,          <span class="attr">"age"</span>: <span class="number">25</span>,          <span class="attr">"about"</span>: <span class="string">"First one who is stupid enough to join this company"</span>,          <span class="attr">"interests"</span>: [            <span class="string">"game"</span>,            <span class="string">"music"</span>          ]        &#125;      &#125;    ]  &#125;&#125;</div></pre></td></tr></table></figure>
<p>除了 <code>_source</code> 的信息之外，我们可以看到有一个 <code>_score</code>，敏感的同学大概会意识到，Elasticsearch 是根据相关性来对结果进行排序的，这个得分就是相关性分数。</p>
<p>除了前面说明的搜索，我们还可以使用 DSL 语句来组合更加复杂的搜索，什么过滤、组合条件、全文、短语搜索，都不在话下，我们甚至可以高亮搜索结果。另外我们还可以利用『聚合』来实现关系型数据库中『Group By』类似的操作。其他诸如推荐、定位、渗透、模糊及部分匹配同样也支持。不过这一篇仅仅是一个简要介绍，就不继续深入了。</p>
<h2 id="实例：收集-Linux-系统日志"><a href="#实例：收集-Linux-系统日志" class="headerlink" title="实例：收集 Linux 系统日志"></a>实例：收集 Linux 系统日志</h2><p>万事俱备，只欠东风，我们现在就把  ElasticStack 用起来！第一个任务很简单，就是把本机的日志给监控起来，这样我们在查询系统发生的事件时，就不用再去 <code>/var/log/</code> 文件夹里『翻箱倒柜』了。</p>
<h3 id="系统日志介绍"><a href="#系统日志介绍" class="headerlink" title="系统日志介绍"></a>系统日志介绍</h3><p>这里简要介绍一下比较通用的系统日志及对应的内容，之后导入日志的时候我会挑选：</p>
<ul>
<li><code>/var/log/apport.log</code> 应用程序崩溃记录</li>
<li><code>/var/log/apt/</code> 用 apt-get 安装卸载软件的信息</li>
<li><code>/var/log/auth.log</code>  登录认证的日志</li>
<li><code>/var/log/boot.log</code>  系统启动时的日志。</li>
<li><code>/var/log/dmesg</code> 包含内核缓冲信息(kernel ringbuffer)。在系统启动时，显示屏幕上的与硬件有关的信息</li>
<li><code>/var/log/faillog</code> 包含用户登录失败信息。此外，错误登录命令也会记录在本文件中</li>
<li><code>/var/log/fsck</code> 文件系统日志</li>
<li><code>/var/log/kern.log</code> 包含内核产生的日志，有助于在定制内核时解决问题</li>
<li><code>/var/log/wtmp</code> 包含登录信息。使用 wtmp 可以找出谁正在登陆进入系统，谁使用命令显示这个文件或信息等</li>
</ul>
<h3 id="启动-Logstash"><a href="#启动-Logstash" class="headerlink" title="启动 Logstash"></a>启动 Logstash</h3><p>这一步的任务是利用 Logstash 把系统日志给导入 Elasticsearch 中。暂时没有使用最新的 Beats 组件，而是继续使用传统的 Logstash 来进行操作（比较重型），用法和之前有些不同，我们会把配置写在一个文件中，而不是直接在命令中输入。</p>
<p>Logstash 使用一个名叫 FileWatch 的 Ruby Gem 库来监听文件变化。这个库支持 glob 展开文件路径，而且会记录一个叫 <code>.sincedb</code> 的数据库文件来跟踪被监听的日志文件的当前读取位置。通过记录下来的 <code>inode</code>, <code>major number</code>, <code>minor number</code> 和 <code>pos</code> 就可以保证不漏过每一条日志。</p>
<p>具体配置如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># 我的习惯是把配置文件统一放到名为 confs 的文件夹中</div><div class="line"># 本配置文件名为 syslog.conf</div><div class="line">input &#123;</div><div class="line">  file &#123;</div><div class="line">    # 确定需要检测的文件</div><div class="line">    path =&gt; [ &quot;/var/log/*.log&quot;, &quot;/var/log/messages&quot;, &quot;/var/log/syslog&quot;, &quot;/var/log/apt&quot;, &quot;/var/log/fsck&quot;, &quot;/var/log/faillog&quot;]</div><div class="line">    # 日志类型</div><div class="line">    type =&gt; &quot;syslog&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"> </div><div class="line">output &#123;</div><div class="line">  # 输出到命令行，一般用于调试</div><div class="line">  stdout &#123; </div><div class="line">    codec =&gt; rubydebug </div><div class="line">  &#125;</div><div class="line">  # 输出到 elasticsearch，这里指定索引名为 system-log</div><div class="line">  elasticsearch &#123; </div><div class="line">    hosts =&gt; &quot;localhost:9200&quot;</div><div class="line">    index =&gt; &quot;system-log&quot; </div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里说一下 File rotation 的情况，为了处理被 rotate 的情况，最好把 rotate 之后的文件名也加到 path 中（如上面所示），这里注意，如果 <code>start_position</code> 被设为 <code>beginning</code>，被 rotate 的文件因为会被认为是新文件，而重新导入。如果用默认值 <code>end</code>，那么在最后一次读之后到被 rotate 结束前生成的日志不会被采集。</p>
<p>有了配置文件，我们就可以把日志导入到 Elasticsearch 了，命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># -f 表示从文件中读取配置</span></div><div class="line">bin/logstash <span class="_">-f</span> confs/syslog.conf</div></pre></td></tr></table></figure>
<p>大概的输出是如下：</p>
<p><img src="/images/14797212868418.jpg" alt=""></p>
<p>如果到这里一切正常，我们就可以去 Kibana 中查看导入的日志了。</p>
<h3 id="使用-Kibana"><a href="#使用-Kibana" class="headerlink" title="使用 Kibana"></a>使用 Kibana</h3><p>Kibana 相当于是 Elasticsearch 的一个可视化插件，所以我们需要在 Management 页面中告诉 Kibana 我们刚才创建的 <code>system-log</code> 索引，完成之后可以看到具体的条目及对应的信息（包括是否可被检索，是否能聚合，是否被分词等）</p>
<p><img src="/images/14797126705730.jpg" alt=""></p>
<p>创建完成后我们就可以在 Discover 面板里查看数据了。</p>
<p><img src="/images/14797126971993.jpg" alt=""></p>
<p>分别介绍下每个面板的作用（更加详细的介绍参见 <a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-7/">柒 Kibana 技巧指南</a>）</p>
<ul>
<li>Discover: 探索数据</li>
<li>Visualize: 可视化统计</li>
<li>Dashboard: 仪表盘</li>
<li>Timelion: 时序，这里我们暂时不用</li>
<li>Management: 设置</li>
<li>Dev Tools: 开发工具，可以方便的测试内置接口</li>
</ul>
<p>这里我简单给出两个实例，介绍一下 Visualize 和 Dashboard 的基本用法</p>
<p>如下图配置，我们可以轻松查看日志都是从哪些文件导入的，除了饼图外，柱状图折线图之类的都是支持的，大家可以自行尝试一下</p>
<p><img src="/images/14797163664177.jpg" alt=""></p>
<p>每个 Visualization 都可以保存，保存之后可以在 Dashboard 面板里集中显示，这样我们只需要看一眼，就对机器运行的状况有一个清晰的了解。</p>
<p><img src="/images/14797164257675.jpg" alt=""></p>
<p>至此，我们就完成了收集系统日志并展示的任务，本章内容到此基本结束。</p>
<h2 id="试一试"><a href="#试一试" class="headerlink" title="试一试"></a>试一试</h2><ol>
<li>搭建完成之后，看看自己的系统中最多出现的 log 是什么？</li>
<li>在 Kibana 中 Dev Tools 的使用 Elasticsearch 的 HTTP 接口来进行简单的查询</li>
<li>尝试 logstash 自己感兴趣的插件，看看能不能为系统日志添加更多字段</li>
<li>创建几个不同的 Visualization 并添加到 Dashboard 中，让内容更丰富一些</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本节中我们完成了 ElasticStack 核心的 ELK 安装，并用一个简单的实例熟悉了相关操作。刚开始接触，一定是会有很多陌生的概念，建议大家去浏览一下官方的快速入门文档，写得还是比较清晰的。下一讲我们会介绍整个日志处理流程中很重要的『缓冲区』- Kafka，有了它，我们的日志分析平台就有了基本的雏形了。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="https://www.elastic.co/guide/index.html" target="_blank" rel="external">Elastic Stack and Product Documentation</a></li>
<li><a href="http://www.infoq.com/cn/news/2016/08/Elasticsearch-5-0-Elastic" target="_blank" rel="external">大数据杂谈微课堂|Elasticsearch 5.0新版本的特性与改进</a></li>
<li><a href="http://www.infoq.com/cn/news/2016/11/Elasticsearch-5-0-publish" target="_blank" rel="external">开源搜索引擎Elasticsearch 5.0版本正式发布</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前一讲我们对 ElasticStack 进行了简要介绍并完成了基本的系统环境配置，这一次我们要把 Elasticsearch/Logstash/Kibana 安装配置好，并把 Linux 的系统日志导入进来。&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="通天塔" scheme="http://wdxtub.com/tags/%E9%80%9A%E5%A4%A9%E5%A1%94/"/>
    
      <category term="日志" scheme="http://wdxtub.com/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="平台" scheme="http://wdxtub.com/tags/%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="环境" scheme="http://wdxtub.com/tags/%E7%8E%AF%E5%A2%83/"/>
    
  </entry>
  
  <entry>
    <title>【通天塔之日志分析平台】贰 Kafka 缓冲区</title>
    <link href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-2/"/>
    <id>http://wdxtub.com/2016/11/19/babel-log-analysis-platform-2/</id>
    <published>2016-11-19T03:11:09.000Z</published>
    <updated>2016-11-22T12:48:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>前一讲我们已经搭建好了 ElasticStack 的核心组件，但是在日常使用中，一般会在 Logstash 和 Elasticsearch 之间加一层 Kafka 用来缓存和控制，这次我们就来看看如何实现这样的功能。</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<ul>
<li>2016.11.21: 完成初稿</li>
</ul>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><ul>
<li><a href="http://wdxtub.com/2016/11/19/babel-series-intro/">『通天塔』技术作品合集介绍</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-0/">零 系列简介与环境配置</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-1/">壹 ELK 环境搭建</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-2/">贰 Kafka 缓冲区</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-3/">叁 监控、安全、报警与通知</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-4/">肆 从单机到集群</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-5/">伍 Logstash 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-6/">陆 Elasticsearch 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-7/">柒 Kibana 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-8/">捌 实例：接入外部应用日志</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-9/">玖 业界：大厂实践</a></li>
</ul>
<h2 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h2><ol>
<li>安装并配置好 Kafka</li>
<li>理解 Kafka 的工作机制</li>
<li>掌握 Kafka 的基本操作，学会基本的错误处理</li>
<li>完成 Logstash-Kafka-Elasticsearch 链路的构建，理解这种架构的优劣</li>
<li>通过实际操作，增加对 ElasticStack 的理解</li>
</ol>
<h2 id="Kafka-简介"><a href="#Kafka-简介" class="headerlink" title="Kafka 简介"></a>Kafka 简介</h2><p>作为云计算大数据的套件，Kafka 是一个分布式的、可分区的、可复制的消息系统。该有的功能基本都有，而且有自己的特色：</p>
<ul>
<li>以 topic 为单位进行消息归纳</li>
<li>向 topic 发布消息的是 producer</li>
<li>从 topic 获取消息的是 consumer</li>
<li>集群方式运行，每个服务叫 broker</li>
<li>客户端和服务器通过 TCP 进行通信</li>
</ul>
<p>在Kafka集群中，没有“中心主节点”的概念，集群中所有的服务器都是对等的，因此，可以在不做任何配置的更改的情况下实现服务器的的添加与删除，同样的消息的生产者和消费者也能够做到随意重启和机器的上下线。</p>
<p>对每个 topic 来说，Kafka 会对其进行分区，每个分区都由一系列有序的、不可变的消息组成，这些消息被连续的追加到分区中。分区中的每个消息都有一个连续的序列号叫做 offset,用来在分区中唯一的标识这个消息。</p>
<p>发布消息通常有两种模式：队列模式(queuing)和发布-订阅模式(publish-subscribe)。队列模式中，consumers 可以同时从服务端读取消息，每个消息只被其中一个 consumer 读到；发布-订阅模式中消息被广播到所有的 consumer 中。更常见的是，每个 topic 都有若干数量的 consumer 组，每个组都是一个逻辑上的『订阅者』，为了容错和更好的稳定性，每个组由若干 consumer 组成。这其实就是一个发布-订阅模式，只不过订阅者是个组而不是单个 consumer。</p>
<p>通过分区的概念，Kafka 可以在多个 consumer 组并发的情况下提供较好的有序性和负载均衡。将每个分区分只分发给一个 consumer 组，这样一个分区就只被这个组的一个 consumer 消费，就可以顺序的消费这个分区的消息。因为有多个分区，依然可以在多个 consumer 组之间进行负载均衡。注意 consumer 组的数量不能多于分区的数量，也就是有多少分区就允许多少并发消费。</p>
<p>Kafka 只能保证一个分区之内消息的有序性，在不同的分区之间是不可以的，这已经可以满足大部分应用的需求。如果需要 topic 中所有消息的有序性，那就只能让这个 topic 只有一个分区，当然也就只有一个 consumer 组消费它。</p>
<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><p>我们可以根据自己的需求来进行简单的配置，具体如下：</p>
<h3 id="1-下载-Kafka"><a href="#1-下载-Kafka" class="headerlink" title="(1) 下载 Kafka"></a>(1) 下载 Kafka</h3><figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 美国主机</span></div><div class="line">wget http://www-us.apache.org/dist/kafka/0.10.1.0/kafka_2.11-0.10.1.0.tgz</div><div class="line"><span class="comment"># 解压</span></div><div class="line">tar -xzf kafka_2.11-0.10.1.0.tgz</div><div class="line"><span class="comment"># 进入文件夹</span></div><div class="line"><span class="built_in">cd</span> kafka_2.11-0.10.1.0</div></pre></td></tr></table></figure>
<h3 id="2-配置-Zookeeper-及-Kafka"><a href="#2-配置-Zookeeper-及-Kafka" class="headerlink" title="(2) 配置 Zookeeper 及 Kafka"></a>(2) 配置 Zookeeper 及 Kafka</h3><p>Zookeeper 的配置在 <code>config/zookeeper.properties</code> 文件中，Kafka 的配置在 <code>config/server.properties</code> 文件中。</p>
<p>Zookeeper 的配置不需要特别更改，注意默认数据存放的位置是 <code>/zookeeper</code>，这里最好放到挂载磁盘上（如果使用云主机，一般来说系统盘比较小，具体可以用 <code>df -h</code> 查看）。Kafka 的默认数据存放位置是 <code>/tmp/kafka-logs</code>，我们把 zookeeper 和 kafka 的数据存放位置一并进行修改</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 在 zookeeper.properties 中</span></div><div class="line">/data/home/logger/kafka-data/zookeeper</div><div class="line"></div><div class="line"><span class="comment"># 在 server.properties 中</span></div><div class="line">log.dirs=/data/home/logger/kafka-data/kafka-logs</div></pre></td></tr></table></figure>
<p>其他配置这里推荐进行一些修改，具体如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># advertised.listerners 改为对外服务的地址</span></div><div class="line"><span class="comment"># 比如对外的 ip 地址是 xx.xx.xx.xx，端口是 8080，那么</span></div><div class="line">advertised.listeners=PLAINTEXT://xx.xx.xx.xx:8080</div><div class="line"></div><div class="line"><span class="comment"># 允许删除 topic</span></div><div class="line">delete.topic.enable=<span class="literal">true</span></div><div class="line"></div><div class="line"><span class="comment"># 不允许自动创建 topic，方便管理</span></div><div class="line">auto.create.topics.enable=<span class="literal">false</span></div><div class="line"></div><div class="line"><span class="comment"># 设定每个 topic 的分区数量，这里设为 100</span></div><div class="line">num.partitions=100</div><div class="line"></div><div class="line"><span class="comment"># 设定日志保留的时间，这里改为 72 小时</span></div><div class="line">log.retention.hours=72</div></pre></td></tr></table></figure>
<h3 id="3-启动-Zookeeper-及-Kafka"><a href="#3-启动-Zookeeper-及-Kafka" class="headerlink" title="(3) 启动 Zookeeper 及 Kafka"></a>(3) 启动 Zookeeper 及 Kafka</h3><figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 可以使用 tmux 或 nohup &amp; 等方式来进行后台运行，这里使用 tmux</span></div><div class="line"><span class="comment"># 启动 Zookeeper</span></div><div class="line">bin/zookeeper-server-start.sh config/zookeeper.properties</div><div class="line"></div><div class="line"><span class="comment"># 启动 Kafka</span></div><div class="line">bin/kafka-server-start.sh config/server.properties</div></pre></td></tr></table></figure>
<p>如果没有出现错误，则启动成功，接下来可以做一个简单的测试</p>
<h3 id="4-内部测试-Kafka"><a href="#4-内部测试-Kafka" class="headerlink" title="(4) 内部测试 Kafka"></a>(4) 内部测试 Kafka</h3><p>先创建一个叫做 wdxtub 的 topic，它只有一个分区和一个副本，命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 创建 topic</span></div><div class="line">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic wdxtub</div></pre></td></tr></table></figure>
<p>然后我们可以使用 <code>bin/kafka-topics.sh --list --zookeeper localhost:2181</code> 命令来查看目前已有的 topic 列表，这时候应该能看到我们刚才创建的名为 wdxtub 的 topic。如果看到程序返回了 <code>wdxtub</code>，那么表示 topic 创建成功。</p>
<p>接下来我们创建一个简单的 producer，用来从标准输入中读取消息并发送给 Kafka，命令为 </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 创建一个向 topic wdxtub 发送消息的 producer</span></div><div class="line"><span class="comment"># 按回车发送，ctrl+c 退出</span></div><div class="line">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic wdxtub</div></pre></td></tr></table></figure>
<p>另外新建一个窗口，启动一个 consumer，用来读取消息并输出到标准输出，命令为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 创建一个从 topic wdxtub 读取消息的 consumer</span></div><div class="line">bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic wdxtub --from-beginning</div></pre></td></tr></table></figure>
<p>启动成功后，我们在 producer 中输入的内容，就可以在 consumer 中看到：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># producer 窗口内容</span></div><div class="line">$&gt; ~/kafka_2.11-0.10.1.0$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic wdxtub</div><div class="line">abcdefu</div><div class="line">dalkdjflka^H^H^H^H^H^H^H</div><div class="line">wdxtub.com</div><div class="line">wdxtub.com is good</div><div class="line"></div><div class="line"><span class="comment"># consumer 窗口内容</span></div><div class="line">$&gt; ~/kafka_2.11-0.10.1.0$ bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic wdxtub --from-beginning</div><div class="line">Using the ConsoleConsumer with old consumer is deprecated and will be removed <span class="keyword">in</span> a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].</div><div class="line">abcdefu</div><div class="line">dalkdjflka</div><div class="line">wdxtub.com</div><div class="line">wdxtub.com is good</div></pre></td></tr></table></figure>
<h3 id="5-Nginx-配置"><a href="#5-Nginx-配置" class="headerlink" title="(5) Nginx 配置"></a>(5) Nginx 配置</h3><p>因为 Kafka 集群的通讯是走内网 ip，而外网访问的端口因为安全考虑只开了少数几个（这里是 8080），所以我们用 Nginx 反向代理来连通内外网</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">upstream mq_pool&#123;</div><div class="line">server ip1:9092 weight=1 max_fails=3 fail_timeout=30s;</div><div class="line">server localhost:9092 weight=1 max_fails=3 fail_timeout=30s;</div><div class="line">&#125;</div><div class="line"></div><div class="line">server&#123;</div><div class="line">listen 8080;</div><div class="line">allow all;</div><div class="line">proxy_pass mq_pool;</div><div class="line">proxy_connect_timeout 24h;</div><div class="line">proxy_timeout 24h;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个配置的意思大概是把所有 8080 端口的消息转发到 <code>mq_pool</code> 的两台机器上（负载均衡），其他的就是常规配置。</p>
<h3 id="6-外部测试-Kafka"><a href="#6-外部测试-Kafka" class="headerlink" title="(6) 外部测试 Kafka"></a>(6) 外部测试 Kafka</h3><p>现在我们的 Kafka 已经在运行了，但是刚才的测试程序是在本机，所以我们无法保证外部应用也能向 Kafka 发送消息（很多时候会用 Nginx 来控制），这里我们就来编写一段简单的 python 脚本来测试能否从其他服务器连接 Kafka。</p>
<p>这里我们采用的 python 包名为 <a href="https://github.com/dpkp/kafka-python" target="_blank" rel="external">dpkp/kafka-python</a>，如果已经有 <code>pip</code> 工具的话，直接 <code>pip install kafka-python</code> 即可。然后我们可以简单编写一个 producer 来进行测试：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 名为 kafka-test.py</span></div><div class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaProducer</div><div class="line"><span class="comment"># 设置 Kafka 地址</span></div><div class="line">producer = KafkaProducer(</div><div class="line">    bootstrap_servers=<span class="string">'your.host.name:8080'</span>)</div><div class="line"></div><div class="line"><span class="comment"># 设置需要发送的 topic 及内容</span></div><div class="line">producer.send(<span class="string">'wdxtub'</span>, <span class="string">'Hello World! This is wdxtub.com.'</span>)</div></pre></td></tr></table></figure>
<p>执行一下 <code>python kafka-test.py</code>，如果能在第(4)步中打开的 consumer 中看到 Hello World 这行字儿，说明能够正确连接。</p>
<h2 id="Kafka-常用操作"><a href="#Kafka-常用操作" class="headerlink" title="Kafka 常用操作"></a>Kafka 常用操作</h2><p>所有的工具都可以在 <code>bin/</code> 文件夹下查看，如果不带任何参数，就会给出所有命令的列表说明，这里只简要说明一些常用的命令</p>
<h3 id="管理-topic"><a href="#管理-topic" class="headerlink" title="管理 topic"></a>管理 topic</h3><p>可以手动创建 topic，或在数据进来时自动创建不存在的 topic，如果是自动创建的话，可能需要根据<a href="http://kafka.apache.org/documentation.html#topic-config" target="_blank" rel="external">这里</a>来进行对应调整。</p>
<p><strong>创建 topic</strong></p>
<p><code>bin/kafka-topics.sh --zookeeper zk_host:port/chroot --create --topic my_topic_name --partitions 20 --replication-factor 3 --config x=y</code></p>
<p>replication-factor 控制复制的份数，建议 2-3 份来兼顾容错和效率。partitions 控制该 topic 将被分区的数目，partitions 的数目最好不要超过服务器的个数（因为分区的意义是增加并行效率，而服务器数量决定了并行的数量，假设只有 2 台服务器，分 4 个区和 2 个区其实差别不大）。另外，topic 的名称不能超过 249 个字符</p>
<p><strong>修改 topic</strong></p>
<p><code>bin/kafka-topics.sh --zookeeper zk_host:port/chroot --alter --topic my_topic_name --partitions 40</code></p>
<p>这里需要注意，即使修改了分区的个数，已有的数据也不会进行变动，Kafka 不会做任何自动重分布</p>
<p><strong>增加配置</strong></p>
<p><code>bin/kafka-topics.sh --zookeeper zk_host:port/chroot --alter --topic my_topic_name --config x=y</code></p>
<p><strong>移除配置</strong></p>
<p><code>bin/kafka-topics.sh --zookeeper zk_host:port/chroot --alter --topic my_topic_name --delete-config x</code></p>
<p><strong>删除 topic</strong></p>
<p><code>bin/kafka-topics.sh --zookeeper zk_host:port/chroot --delete --topic my_topic_name</code></p>
<p>这个需要 <code>delete.topic.enable=true</code>，目前 Kafka 不支持减少 topic 的分区数目</p>
<h3 id="优雅关闭"><a href="#优雅关闭" class="headerlink" title="优雅关闭"></a>优雅关闭</h3><p>Kafka 会自动检测 broker 的状态并根据机器状态选举出新的 leader。但是如果需要进行配置更改停机的时候，我们就需要使用优雅关闭了，好处在于：</p>
<ol>
<li>会把所有的日志同步到磁盘上，避免重启之后的日志恢复，减少重启时间</li>
<li>会在关闭前把以这台机为 leader 的分区数据迁移到其他节点，会减少不可用的时间</li>
</ol>
<p>但是这个需要开启 <code>controlled.shutdown.enable=true</code>。</p>
<p>刚重启之后的节点不是任何分区的 leader，所以这时候需要进行重新分配：</p>
<p><code>bin/kafka-preferred-replica-election.sh --zookeeper zk_host:port/chroot</code></p>
<p>这里需要开启 <code>auto.leader.rebalance.enable=true</code></p>
<p>然后可以使用脚本 <code>bin/kafka-server-stop.sh</code></p>
<p>注意，如果配置文件中没有 <code>auto.leader.rebalance.enable=true</code>，就还需要重新平衡。</p>
<h2 id="深入理解"><a href="#深入理解" class="headerlink" title="深入理解"></a>深入理解</h2><p>这里只是一部分摘录，更多内容可查阅参考链接（尤其是美团技术博客的那篇）</p>
<h3 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h3><p>Kafka 大量依赖文件系统去存储和缓存消息。而文件系统最终会放在硬盘上，不过不用担心，很多时候硬盘的快慢完全取决于使用它的方式。设计良好的硬盘架构可以和内存一样快。</p>
<p>所以与传统的将数据缓存在内存中然后刷到硬盘的设计不同，Kafka直接将数据写到了文件系统的日志中，因此也避开了 JVM 的劣势——Java 对象占用空间巨大，数据量增大后垃圾回收有困难。使用文件系统，即使系统重启了，也不需要刷新数据，也简化了维护数据一致性的逻辑。</p>
<p>对于主要用于日志处理的消息系统，数据的持久化可以简单的通过将数据追加到文件中实现，读的时候从文件中读就好了。这样做的好处是读和写都是 O(1) 的，并且读操作不会阻塞写操作和其他操作。这样带来的性能优势是很明显的，因为性能和数据的大小没有关系了。</p>
<p>既然可以使用几乎没有容量限制（相对于内存来说）的硬盘空间建立消息系统，就可以在没有性能损失的情况下提供一些一般消息系统不具备的特性。比如，一般的消息系统都是在消息被消费后立即删除，Kafka却可以将消息保存一段时间（比如一星期），这给consumer提供了很好的机动性和灵活性。</p>
<h3 id="事务定义"><a href="#事务定义" class="headerlink" title="事务定义"></a>事务定义</h3><p>数据传输的事务定义通常有以下三种级别：</p>
<ul>
<li>最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输。</li>
<li>最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.</li>
<li>精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被一次而且仅仅被传输一次，这是大家所期望的。</li>
</ul>
<p>Kafka 的机制和 git 有点类似，有一个 commit 的概念，一旦提交且 broker 在工作，那么数据就不会丢失。如果 producer 发布消息时发生了网络错误，但又不确定实在提交之前发生的还是提交之后发生的，这种情况虽然不常见，但是必须考虑进去，现在Kafka版本还没有解决这个问题，将来的版本正在努力尝试解决。</p>
<p>并不是所有的情况都需要“精确的一次”这样高的级别，Kafka 允许 producer 灵活的指定级别。比如 producer 可以指定必须等待消息被提交的通知，或者完全的异步发送消息而不等待任何通知，或者仅仅等待 leader 声明它拿到了消息（followers没有必要）。</p>
<p>现在从 consumer 的方面考虑这个问题，所有的副本都有相同的日志文件和相同的offset，consumer 维护自己消费的消息的 offset。如果 consumer 崩溃了，会有另外一个 consumer 接着消费消息，它需要从一个合适的 offset 继续处理。这种情况下可以有以下选择：</p>
<ul>
<li>consumer 可以先读取消息，然后将 offset 写入日志文件中，然后再处理消息。这存在一种可能就是在存储 offset 后还没处理消息就 crash 了，新的 consumer 继续从这个 offset 处理，那么就会有些消息永远不会被处理，这就是上面说的『最多一次』</li>
<li>consumer 可以先读取消息，处理消息，最后记录o ffset，当然如果在记录 offset 之前就 crash 了，新的 consumer 会重复的消费一些消息，这就是上面说的『最少一次』</li>
<li>『精确一次』可以通过将提交分为两个阶段来解决：保存了 offset 后提交一次，消息处理成功之后再提交一次。但是还有个更简单的做法：将消息的 offset 和消息被处理后的结果保存在一起。比如用 Hadoop ETL 处理消息时，将处理后的结果和 offset 同时保存在 HDFS 中，这样就能保证消息和 offser 同时被处理了</li>
</ul>
<h3 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h3><p>Kafka 在提高效率方面做了很大努力。Kafka 的一个主要使用场景是处理网站活动日志，吞吐量是非常大的，每个页面都会产生好多次写操作。读方面，假设每个消息只被消费一次，读的量的也是很大的，Kafka 也尽量使读的操作更轻量化。</p>
<p>线性读写的情况下影响磁盘性能问题大约有两个方面：太多的琐碎的 I/O 操作和太多的字节拷贝。I/O 问题发生在客户端和服务端之间，也发生在服务端内部的持久化的操作中。</p>
<p><strong>消息集(message set)</strong></p>
<p>为了避免这些问题，Kafka 建立了<strong>消息集(message set)</strong>的概念，将消息组织到一起，作为处理的单位。以消息集为单位处理消息，比以单个的消息为单位处理，会提升不少性能。Producer 把消息集一块发送给服务端，而不是一条条的发送；服务端把消息集一次性的追加到日志文件中，这样减少了琐碎的 I/O 操作。consumer 也可以一次性的请求一个消息集。</p>
<p>另外一个性能优化是在字节拷贝方面。在低负载的情况下这不是问题，但是在高负载的情况下它的影响还是很大的。为了避免这个问题，Kafka 使用了标准的二进制消息格式，这个格式可以在 producer, broker 和 producer 之间共享而无需做任何改动。</p>
<p><strong>zero copy</strong></p>
<p>Broker 维护的消息日志仅仅是一些目录文件，消息集以固定队的格式写入到日志文件中，这个格式 producer 和 consumer 是共享的，这使得 Kafka 可以一个很重要的点进行优化：消息在网络上的传递。现代的 unix 操作系统提供了高性能的将数据从页面缓存发送到 socket 的系统函数，在 linux 中，这个函数是 <code>sendfile</code></p>
<p>为了更好的理解 <code>sendfile</code> 的好处，我们先来看下一般将数据从文件发送到 socket 的数据流向：</p>
<ul>
<li>操作系统把数据从文件拷贝内核中的页缓存中</li>
<li>应用程序从页缓存从把数据拷贝自己的内存缓存中</li>
<li>应用程序将数据写入到内核中 socket 缓存中</li>
<li>操作系统把数据从 socket 缓存中拷贝到网卡接口缓存，从这里发送到网络上。</li>
</ul>
<p>这显然是低效率的，有 4 次拷贝和 2 次系统调用。<code>sendfile</code> 通过直接将数据从页面缓存发送网卡接口缓存，避免了重复拷贝，大大的优化了性能。</p>
<p>在一个多consumers的场景里，数据仅仅被拷贝到页面缓存一次而不是每次消费消息的时候都重复的进行拷贝。这使得消息以近乎网络带宽的速率发送出去。这样在磁盘层面你几乎看不到任何的读操作，因为数据都是从页面缓存中直接发送到网络上去了。</p>
<p><strong>数据压缩</strong></p>
<p>很多时候，性能的瓶颈并非CPU或者硬盘而是网络带宽，对于需要在数据中心之间传送大量数据的应用更是如此。当然用户可以在没有 Kafka 支持的情况下各自压缩自己的消息，但是这将导致较低的压缩率，因为相比于将消息单独压缩，将大量文件压缩在一起才能起到最好的压缩效果。</p>
<p>Kafka 采用了端到端的压缩：因为有『消息集』的概念，客户端的消息可以一起被压缩后送到服务端，并以压缩后的格式写入日志文件，以压缩的格式发送到 consumer，消息从 producer 发出到 consumer 拿到都被是压缩的，只有在 consumer 使用的时候才被解压缩，所以叫做『端到端的压缩』。Kafka支持GZIP和Snappy压缩协议。</p>
<h2 id="实例：把系统日志通过-Kafka-接入-Elasticsearch"><a href="#实例：把系统日志通过-Kafka-接入-Elasticsearch" class="headerlink" title="实例：把系统日志通过 Kafka 接入 Elasticsearch"></a>实例：把系统日志通过 Kafka 接入 Elasticsearch</h2><p>现在我们就把上一讲搭建好的架构中加入 Kakfa 作为缓冲区，具体分两步</p>
<h3 id="1-Logstash-gt-Kafka"><a href="#1-Logstash-gt-Kafka" class="headerlink" title="(1) Logstash -&gt; Kafka"></a>(1) Logstash -&gt; Kafka</h3><p>让我们回想一下之前的架构，Logstash 会直接把日志发送给 Elasticsearch，再由 Kibana 进行展示。因为 Logstash 是同步把日志发送给 Elasticsearch 的，所以等于这俩耦合在了一起，Elasticsearch 一旦挂掉，可能就会丢失数据。</p>
<p>于是，我们考虑利用 Kafka 作为缓冲区，让 Logstash 不受 Elasticsearch 的影响。所以第一步就是让 Logstash 把日志发送到 Kafka，这里 Logstash 相当于 producer。</p>
<p>不过在开始之前，我们先启动 Kafka</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 启动 Zookeeper</span></div><div class="line">bin/zookeeper-server-start.sh config/zookeeper.properties</div><div class="line"><span class="comment"># 启动 Kafka</span></div><div class="line">bin/kafka-server-start.sh config/server.properties</div></pre></td></tr></table></figure>
<p>我们之前的 Logstash 配置文件是把日志直接发送到 Elasticsearch 的，这里我们需要更新为发送到 Kafka</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># 我的习惯是把配置文件统一放到名为 confs 的文件夹中</div><div class="line"># 本配置文件名为 log-to-kafka.conf</div><div class="line">input &#123;</div><div class="line">  file &#123;</div><div class="line">    # 确定需要检测的文件</div><div class="line">    path =&gt; [ &quot;/var/log/*.log&quot;, &quot;/var/log/messages&quot;, &quot;/var/log/syslog&quot;, &quot;/var/log/apt&quot;, &quot;/var/log/fsck&quot;, &quot;/var/log/faillog&quot;]</div><div class="line">    # 日志类型</div><div class="line">    type =&gt; &quot;syslog&quot;</div><div class="line">    add_field =&gt; &#123; &quot;service&quot; =&gt; &quot;system-log&quot;&#125;</div><div class="line">    # stat_interval =&gt; 1800</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"> </div><div class="line">output &#123;</div><div class="line">  # 输出到命令行，一般用于调试</div><div class="line">  stdout &#123; </div><div class="line">    codec =&gt; rubydebug </div><div class="line">  &#125;</div><div class="line">  # 输出到 Kafka，topic 名称为 logs，地址为默认的端口号</div><div class="line">  kafka &#123;</div><div class="line">    topic_id =&gt; &quot;logs&quot;</div><div class="line">    bootstrap_servers =&gt; &quot;localhost:9092&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>file 插件其他一些配置设定原因</p>
<ul>
<li><code>add_field</code> 添加一个 topic 字段，用作之后导入 elasticsearch 的索引标识</li>
<li><code>stat_interval</code> 单位是秒，这里 30 分钟进行一次检测，不过测试的时候需要去掉这个配置</li>
</ul>
<p>kafka 插件其他一些需要注意的配置</p>
<ul>
<li><code>acks</code> 可以选的值为 <code>0</code>, <code>1</code>, <code>all</code>，这里解释一下，0 表示不需要 server 返回就认为请求已完成；1 表示需要 leader 返回才认为请求完成；all 表示需要所有的服务器返回才认为请求完成</li>
<li><code>batch_size</code> 单位是字节，如果是发送到同一分区，会攒够这个大小才发送一次请求</li>
<li><code>block_on_buffer_full</code> 这个设置在缓冲区慢了之后阻塞还是直接报错</li>
<li><code>buffer_memory</code> 发送给服务器之前的缓冲区大小，单位是字节</li>
<li><code>client_id</code> 可以在这里设定有意义的名字，就不一定要用 ip 和 端口来区分</li>
<li><code>compression_type</code> 压缩方式，默认是 <code>none</code>，其他可选的是 <code>gzip</code> 和 <code>snappy</code></li>
</ul>
<h3 id="2-Kafka-gt-Elasticsearch"><a href="#2-Kafka-gt-Elasticsearch" class="headerlink" title="(2) Kafka -&gt; Elasticsearch"></a>(2) Kafka -&gt; Elasticsearch</h3><p>利用 Logstash 从 Kafka 导出数据到 Elasticsearch。这一步就比较简单了，先从 Kafka 中读取，然后写入到 elasticsearch，这里 Logstash 作为 consumer。唯一需要注意的地方是要保证 topic 名称一致</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># 文件名 kafka-to-es.conf</div><div class="line">input &#123;</div><div class="line">  kafka &#123;</div><div class="line">    bootstrap_servers =&gt; &quot;localhost:9092&quot;</div><div class="line">    topics =&gt; [&quot;logs&quot;]</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">output &#123;</div><div class="line">  # for debugging</div><div class="line">  stdout &#123;</div><div class="line">     codec =&gt; rubydebug</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  elasticsearch &#123; </div><div class="line">    hosts =&gt; &quot;localhost:9200&quot;</div><div class="line">    index =&gt; &quot;system-log&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>至此，我们完成了从 Logstash 到 Kafka 再到 Elasticsearch 的连接，下一步就可以用 kibana 来展示日志的监控分析结果了。</p>
<p><img src="/images/14797818253620.jpg" alt=""></p>
<p>如上图所示，打开 Kibana，即可见到我们使用 Logstash 通过 Kafka 再发送到 Elasticsearch 的日志。至此，我们就成功把 Kafka 加入到日志分析平台的架构中了。</p>
<h2 id="试一试"><a href="#试一试" class="headerlink" title="试一试"></a>试一试</h2><ol>
<li>查阅 Logstash 的 Kafka 插件的文档，了解其他的配置选项</li>
<li>Logstash 能够处理 json 格式的日志，试着把系统日志转换成 json，并进行处理</li>
<li>更新 Logstash 配置，看看能不能多记录一些系统事件</li>
<li>随着日志的增多，使用 Kibana 多创建一些图表并添加到 Dashboard 中</li>
</ol>
<p>一个可能的例子如下：</p>
<p><img src="/images/14797829019725.jpg" alt=""></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这一讲我们主要学习了 Kafka 的相关内容，并在了解原理的基础上更新了日志分析平台的架构，这样我们的日志在发送到 Elasticsearch 之前。下一讲我们会在单机的状态下完成监控、安全、报警与通知的功能。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="http://kafka.apache.org/quickstart" target="_blank" rel="external">Kafka 快速入门</a></li>
<li><a href="https://www.apache.org/dyn/closer.cgi?path=/kafka/0.10.1.0/kafka_2.11-0.10.1.0.tgz" target="_blank" rel="external">Kafka 2.11-0.10.1.0 下载</a></li>
<li><a href="http://blog.csdn.net/LOUISLIAOXH/article/details/51567515" target="_blank" rel="external">Kafka学习整理六(server.properties配置实践)</a></li>
<li><a href="http://kafka.apache.org/" target="_blank" rel="external">Apache Kafka</a></li>
<li><a href="http://kafka.apache.org/documentation.html#quickstart" target="_blank" rel="external">Quick Start</a></li>
<li><a href="http://www.aboutyun.com/thread-12882-1-1.html" target="_blank" rel="external">Kafka入门经典教程</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-kafka/" target="_blank" rel="external">Apache kafka 工作原理介绍</a></li>
<li><a href="http://www.coderli.com/setup-kafka-cluster-step-by-step/" target="_blank" rel="external">事无巨细 Apache Kafka 0.9.0.1 集群环境搭建</a></li>
<li><a href="http://blog.csdn.net/dhtx_wzgl/article/details/46892231" target="_blank" rel="external">kafka集群搭建</a></li>
<li><a href="http://tech.meituan.com/kafka-fs-design-theory.html" target="_blank" rel="external">Kafka文件存储机制那些事</a></li>
<li><a href="http://kaimingwan.com/post/kafka/kafkayuan-li-yi-ji-she-ji-shi-xian-si-xiang" target="_blank" rel="external">kafka原理以及设计实现思想</a></li>
<li><a href="http://www.dexcoder.com/dexcoder/article/2194" target="_blank" rel="external">kafka设计原理介绍</a></li>
<li><a href="http://blog.jobbole.com/99195/" target="_blank" rel="external">Kafka集群操作指南</a></li>
<li><a href="https://www.quora.com/What-is-the-actual-role-of-ZooKeeper-in-Kafka" target="_blank" rel="external">What is the actual role of ZooKeeper in Kafka?</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前一讲我们已经搭建好了 ElasticStack 的核心组件，但是在日常使用中，一般会在 Logstash 和 Elasticsearch 之间加一层 Kafka 用来缓存和控制，这次我们就来看看如何实现这样的功能。&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="通天塔" scheme="http://wdxtub.com/tags/%E9%80%9A%E5%A4%A9%E5%A1%94/"/>
    
      <category term="日志" scheme="http://wdxtub.com/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="平台" scheme="http://wdxtub.com/tags/%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="Kafka" scheme="http://wdxtub.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>【通天塔之日志分析平台】叁 监控、安全、报警与通知</title>
    <link href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-3/"/>
    <id>http://wdxtub.com/2016/11/19/babel-log-analysis-platform-3/</id>
    <published>2016-11-19T03:11:08.000Z</published>
    <updated>2016-11-22T12:48:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>施工中：各个附加功能的应用</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><ul>
<li><a href="http://wdxtub.com/2016/11/19/babel-series-intro/">『通天塔』技术作品合集介绍</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-0/">零 系列简介与环境配置</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-1/">壹 ELK 环境搭建</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-2/">贰 Kafka 缓冲区</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-3/">叁 监控、安全、报警与通知</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-4/">肆 从单机到集群</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-5/">伍 Logstash 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-6/">陆 Elasticsearch 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-7/">柒 Kibana 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-8/">捌 实例：接入外部应用日志</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-9/">玖 业界：大厂实践</a></li>
</ul>
<h2 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h2><ol>
<li>完成 X-Pack 的安装</li>
<li>了解 Security, Alerting, Monitoring, Reporting 几大组件的功能</li>
<li>自己编写一个报警规则</li>
<li>自己生成一个数据报表</li>
</ol>
<h2 id="X-Pack-简介与安装"><a href="#X-Pack-简介与安装" class="headerlink" title="X-Pack 简介与安装"></a>X-Pack 简介与安装</h2><p>在 Elasticsearch 2.4 时代，如果想对其进行监控和管理，除了五花八门的开源解决方案外，还可以使用 elastic 官方的配套插件。但是从前的名字比较乱，从 Shield 到 Watcher 再到 Marvel，还要一个一个安装配置。</p>
<p>不过在 ElasticStack 5.0 时代，所有的功能得到了统一，统称为 X-Pack，包含：</p>
<ul>
<li>安全：用户权限管理</li>
<li>警报：自动报警</li>
<li>监控：监控 Elasticsearch 集群状态</li>
<li>报告：发送报表、导出数据</li>
<li>图表：可视化数据</li>
</ul>
<p>这些功能基本上涵盖了日常应用的方方面面，接下来我们就来简单了解一下各项功能。不过开始之前，我们先把 X-Pack 装好。</p>
<p>安装需要先停止 Kibana 和 Elasticsearch，这个时候就体现出 Kafka 的优势了：我们可以对 Elasticsearch 进行修改，因为缓存到了 Kafka<br>，所以不必担心日志服务停止。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 为 Elasticsearch 安装 X-Pack</span></div><div class="line">bin/elasticsearch-plugin install x-pack</div><div class="line"><span class="comment"># 启动 Elasticsearch</span></div><div class="line">bin/elasticsearch</div><div class="line"></div><div class="line"><span class="comment"># 为 Kibana 安装 X-Pack</span></div><div class="line">bin/kibana-plugin install x-pack</div><div class="line"><span class="comment"># 启动 Kibana</span></div><div class="line">bin/kibana</div></pre></td></tr></table></figure>
<p>命令完成之后，安装就算完成了。这里需要额外提一点，因为加上了安全认证，所以原先我们的 Logstash 脚本就不能用了，初始的用户名为 <code>user</code> 和密码为 <code>changeme</code>，对应的配置文件需要更新为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># 文件名：kafka-to-es.conf</div><div class="line">input &#123;</div><div class="line">  kafka &#123;</div><div class="line">    bootstrap_servers =&gt; &quot;localhost:9092&quot;</div><div class="line">    topics =&gt; [&quot;logs&quot;]</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">output &#123;</div><div class="line">  # for debugging</div><div class="line">  stdout &#123;</div><div class="line">     codec =&gt; rubydebug</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  elasticsearch &#123; </div><div class="line">    hosts =&gt; &quot;localhost:9200&quot;</div><div class="line">    index =&gt; &quot;system-log&quot;</div><div class="line">    # 用户名和密码如果变更需要更改</div><div class="line">    user =&gt; &quot;elastic&quot;</div><div class="line">    password =&gt; &quot;changeme&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="安全-Security"><a href="#安全-Security" class="headerlink" title="安全 Security"></a>安全 Security</h2><p>再次打开之前的 Kibana 页面，就会发现我们需要登录了：</p>
<p><img src="/images/14797879133833.jpg" alt=""></p>
<p>输入一开始预置的用户名与密码(elastic:changeme)，就可以进入 Kibana 了。然后我们在 Management 面板中可以看到一个新的 Elasticsearch 的栏目，可以在这里进行用户和角色的定制。</p>
<p><img src="/images/14797883023338.jpg" alt=""></p>
<p>这里我们暂时使用默认的帐号和角色进行操作，更多关于安全方面的问题可以参考下面的链接：</p>
<ul>
<li><a href="https://www.elastic.co/guide/en/x-pack/current/encrypting-communications.html" target="_blank" rel="external">通讯加密</a></li>
<li><a href="https://www.elastic.co/guide/en/x-pack/current/ip-filtering.html" target="_blank" rel="external">IP 过滤</a></li>
</ul>
<h2 id="监控-Monitoring"><a href="#监控-Monitoring" class="headerlink" title="监控 Monitoring"></a>监控 Monitoring</h2><p>点击左侧的 Monitoring 面板，便可以清楚查阅 Elasticsearch 和 Kibana 的状态。</p>
<p><img src="/images/14797888163112.jpg" alt=""></p>
<p>点击进入 Overview，便可以清晰了解整体的使用状况：</p>
<p><img src="/images/14797951637038.jpg" alt=""></p>
<p>而在 Indices 分页中点击具体的索引，便可以看到索引的详细：</p>
<p><img src="/images/14797952970767.jpg" alt=""></p>
<p>监控功能在遇到问题的时候进行问题查找和确定非常有用，也可以结合报警和报告功能实现自动化通知。</p>
<h2 id="报警-Alerting"><a href="#报警-Alerting" class="headerlink" title="报警 Alerting"></a>报警 Alerting</h2><p>Elasticsearch 中报警功能的实现目前还不算特别智能，这里我们只简单了解一下其工作机制，具体在需要的时候可以根据文档来进行设置。</p>
<p>简单来说，我们需要自己设定触发条件，并指定条件触发之后的动作。一个实际的例子就是，如果发现近十分钟内某个接口一直返回 503 错误，那么就发送邮件通知。分解一下，一个可能的逻辑是：</p>
<ol>
<li>Trigger: 每十分钟执行一次</li>
<li>Input: 对某个 index 进行检索，查询日志中状态为 error 的条目</li>
<li>Condition: 如果 error 的次数超过 5 次，则认为触发了条件</li>
<li>Transform: 触发之后会再次进行检索，检索的结果可以被之后的动作访问</li>
<li>Actions: 执行具体的操作，可以是通知第三方系统或发送邮件等</li>
</ol>
<p>上面的套路对应到配置文件就是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">PUT _xpack/watcher/watch/log_errors</div><div class="line">&#123;</div><div class="line">  &quot;metadata&quot; : &#123; </div><div class="line">    &quot;color&quot; : &quot;red&quot;</div><div class="line">  &#125;,</div><div class="line">  &quot;trigger&quot; : &#123; </div><div class="line">    &quot;schedule&quot; : &#123;</div><div class="line">      &quot;interval&quot; : &quot;5m&quot;</div><div class="line">    &#125;</div><div class="line">  &#125;,</div><div class="line">  &quot;input&quot; : &#123; </div><div class="line">    &quot;search&quot; : &#123;</div><div class="line">      &quot;request&quot; : &#123;</div><div class="line">        &quot;indices&quot; : &quot;log-events&quot;,</div><div class="line">        &quot;body&quot; : &#123;</div><div class="line">          &quot;size&quot; : 0,</div><div class="line">          &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;status&quot; : &quot;error&quot; &#125; &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;,</div><div class="line">  &quot;condition&quot; : &#123; </div><div class="line">    &quot;compare&quot; : &#123; &quot;ctx.payload.hits.total&quot; : &#123; &quot;gt&quot; : 5 &#125;&#125;</div><div class="line">  &#125;,</div><div class="line">  &quot;transform&quot; : &#123; </div><div class="line">    &quot;search&quot; : &#123;</div><div class="line">        &quot;request&quot; : &#123;</div><div class="line">          &quot;indices&quot; : &quot;log-events&quot;,</div><div class="line">          &quot;body&quot; : &#123;</div><div class="line">            &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;status&quot; : &quot;error&quot; &#125; &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;,</div><div class="line">  &quot;actions&quot; : &#123; </div><div class="line">    &quot;my_webhook&quot; : &#123;</div><div class="line">      &quot;webhook&quot; : &#123;</div><div class="line">        &quot;method&quot; : &quot;POST&quot;,</div><div class="line">        &quot;host&quot; : &quot;mylisteninghost&quot;,</div><div class="line">        &quot;port&quot; : 9200,</div><div class="line">        &quot;path&quot; : &quot;/&#123;&#123;watch_id&#125;&#125;&quot;,</div><div class="line">        &quot;body&quot; : &quot;Encountered &#123;&#123;ctx.payload.hits.total&#125;&#125; errors&quot;</div><div class="line">      &#125;</div><div class="line">    &#125;,</div><div class="line">    &quot;email_administrator&quot; : &#123;</div><div class="line">      &quot;email&quot; : &#123;</div><div class="line">        &quot;to&quot; : &quot;sys.admino@host.domain&quot;,</div><div class="line">        &quot;subject&quot; : &quot;Encountered &#123;&#123;ctx.payload.hits.total&#125;&#125; errors&quot;,</div><div class="line">        &quot;body&quot; : &quot;Too many error in the system, see attached data&quot;,</div><div class="line">        &quot;attachments&quot; : &#123;</div><div class="line">          &quot;attached_data&quot; : &#123;</div><div class="line">            &quot;data&quot; : &#123;</div><div class="line">              &quot;format&quot; : &quot;json&quot;</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;,</div><div class="line">        &quot;priority&quot; : &quot;high&quot;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>以上也可以在 Dev Tools 中的面板中执行试试看。</p>
<h2 id="报告-Reporting"><a href="#报告-Reporting" class="headerlink" title="报告 Reporting"></a>报告 Reporting</h2><p>简单来说，这个功能就是一个输出搜索结果和图表的按钮。我们进入 Dashboard 页面，保存当前的图表后，点击右上角的 Reporting 按钮，就会出现一个下载按钮：</p>
<p><img src="/images/14797974158340.jpg" alt=""></p>
<p>点击之后我们会发现并不能够直接下载，因为这个按钮只是给系统发送了一个生成报表的请求，具体的文件我们需要在 Management 面板的 Kibana/Reporting 部分查看：</p>
<p><img src="/images/14797975688905.jpg" alt=""></p>
<p>除了手动生成，我们也可以设置自动生成（使用上面图片中的 Generation URL）并通过给出的 api 来进行下载，具体可以参照 <a href="https://www.elastic.co/guide/en/x-pack/current/automating-report-generation.html" target="_blank" rel="external">Automating Report Generation</a></p>
<h2 id="试一试"><a href="#试一试" class="headerlink" title="试一试"></a>试一试</h2><ol>
<li>阅读 <a href="https://www.elastic.co/guide/en/x-pack/current/xpack-settings.html" target="_blank" rel="external">X-Pack Settings</a> 来了解各种设置</li>
<li>阅读 <a href="https://www.elastic.co/guide/en/x-pack/current/xpack-api.html" target="_blank" rel="external">X-Pack APIs</a> 来了解相关 API，以实现自动化设置</li>
<li>阅读 <a href="https://www.elastic.co/guide/en/x-pack/current/xpack-limitations.html" target="_blank" rel="external">Limitaions</a> 来了解 X-Pack 的限制</li>
<li>自己设定一个报警条件，并在触发之后自动发送邮件给自己</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>经历了前两节辛苦的环境搭建，本节内容还是比较轻松的，把环境基本搭建完成之后，就可以真刀真枪做一些实际的项目了。下一讲我们会学习从单机到集群的迁移操作和需要注意的地方，为扩展系统做好准备。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;施工中：各个附加功能的应用&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="通天塔" scheme="http://wdxtub.com/tags/%E9%80%9A%E5%A4%A9%E5%A1%94/"/>
    
      <category term="日志" scheme="http://wdxtub.com/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="平台" scheme="http://wdxtub.com/tags/%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="监控" scheme="http://wdxtub.com/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>【通天塔之日志分析平台】肆 从单机到集群</title>
    <link href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-4/"/>
    <id>http://wdxtub.com/2016/11/19/babel-log-analysis-platform-4/</id>
    <published>2016-11-19T03:11:07.000Z</published>
    <updated>2016-11-21T14:27:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>施工中：集群配置和全球部署可能带来的问题</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><ul>
<li><a href="http://wdxtub.com/2016/11/19/babel-series-intro/">『通天塔』技术作品合集介绍</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-0/">零 系列简介与环境配置</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-1/">壹 ELK 环境搭建</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-2/">贰 Kafka 缓冲区</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-3/">叁 监控、安全、报警与通知</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-4/">肆 从单机到集群</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-5/">伍 Logstash 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-6/">陆 Elasticsearch 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-7/">柒 Kibana 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-8/">捌 实例：接入外部应用日志</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-9/">玖 业界：大厂实践</a></li>
</ul>
<h2 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h2><h3 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h3><p>这里简单说一下 Elasticsearch 的分布式吧。开发人员花了很多心思，尽量让一台机上运行和集群上运行的体验一致，具体说，Elasticsearch 在底层主要做的工作有：</p>
<ul>
<li>根据配置进行数据分片(sharding)，并且保存在一个或者多个节点中</li>
<li>将分片均匀分配到各个节点，对索引和搜索做负载均衡</li>
<li>分片冗余，提高容错性</li>
<li>将集群中任意一个节点上的请求路由到相应数据所在的节点</li>
<li>增加或者移除节点时无缝迁移数据</li>
</ul>
<h2 id="老-ES-集群指南"><a href="#老-ES-集群指南" class="headerlink" title="老 ES 集群指南"></a>老 ES 集群指南</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>虽然 Elasticsearch 的安装比较简单，不过我还是写了一个安装脚本，可以在<a href="https://github.com/wdxtub/wdxtools/tree/master/linux-script" target="_blank" rel="external">这里</a>查看，具体来说其实就两步，下载和解压，如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.4.0/elasticsearch-2.4.0.tar.gz</div><div class="line">tar -xvzf elasticsearch-2.4.0.tar.gz</div></pre></td></tr></table></figure>
<p>分别在集群中每台机器中完成安装即可，具体的启动也非常简单，如果要在前台，直接 <code>./bin/elasticsearch</code> 即可，如果要放到后台，则使用 <code>nohup ./bin/elasticsearch &amp;</code>。</p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>配置文件位于 <code>config</code> 文件夹中，其中 <code>elasticsearch.yml</code> 是 elasticsearch 的配置，而 <code>logging.yml</code> 是输出日志相关的设置。配置文件的内容有很多，不过因为默认值基本都够用了，所以我们只需要配置很少的内容。假设现在有两个节点，内部 IP 地址分别为 <code>A: 10.1.1.0</code> 和 <code>B: 10.1.1.1</code>，那么配置为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># 节点 A</div><div class="line">cluster.name: wdxtubes</div><div class="line">node.name: &quot;es01&quot;</div><div class="line">bootstrap.mlockall: true</div><div class="line">network.host: 10.1.1.0</div><div class="line">network.publish_host: 10.1.1.0</div><div class="line">discovery.zen.ping.unicast.hosts: [&quot;10.1.1.1&quot;]</div><div class="line">discovery.zen.fd.ping_timeout: 120s</div><div class="line">discovery.zen.fd.ping_retries: 6</div><div class="line">discovery.zen.fd.ping_interval: 30s</div><div class="line"></div><div class="line"></div><div class="line"># 节点 B</div><div class="line">cluster.name: wdxtubes</div><div class="line">node.name: &quot;es02&quot;</div><div class="line">bootstrap.mlockall: true</div><div class="line">network.host: 10.1.1.1</div><div class="line">network.publish_host: 10.1.1.1</div><div class="line">discovery.zen.ping.unicast.hosts: [&quot;10.1.1.0&quot;]</div><div class="line">discovery.zen.fd.ping_timeout: 120s</div><div class="line">discovery.zen.fd.ping_retries: 6</div><div class="line">discovery.zen.fd.ping_interval: 30s</div></pre></td></tr></table></figure>
<p>这里需要注意的是我们采用单播的方式来进行集群中机器的查找，因为 elasticsearch 已经尽量帮我们做好了集群相关的工作，只要保证 <code>cluster.name</code> 一致，就可以自动发现。另外，我们调大了超时的间隔和互相 ping 发送的频率以及重试次数，防止某台机器在 Full GC 的时候因未能及时响应而造成的连锁反应（后面会详细说明）</p>
<p>多说一句，机器配置的时候，最好确保两台机器可以互相 ping 通，并开放所有端口的内部访问（如果是用云主机的话，尤其需要注意这一点）</p>
<p>如果需要扩展的话，只需要保证 <code>cluster.name</code> 一致即可，比如说现在新加入一台 <code>C: 10.1.1.2</code>，那么配置可以这么写</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># 节点 C</div><div class="line">cluster.name: wdxtubes</div><div class="line">node.name: &quot;es03&quot;</div><div class="line">bootstrap.mlockall: true</div><div class="line">network.host: 10.1.1.2</div><div class="line">network.publish_host: 10.1.1.2</div><div class="line">discovery.zen.ping.unicast.hosts: [&quot;10.1.1.0&quot;]</div><div class="line">discovery.zen.fd.ping_timeout: 120s</div><div class="line">discovery.zen.fd.ping_retries: 6</div><div class="line">discovery.zen.fd.ping_interval: 30s</div></pre></td></tr></table></figure>
<p>这里 <code>discovery.zen.ping.unicast.hosts</code> 中只需要填写原有集群中任意一台机器的地址即可。</p>
<p>然后我们可以在集群中的机器上使用 <code>curl http://10.1.1.0:9200/_cluster/health</code> 来查看集群状态。比如：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="attr">"cluster_name"</span>:<span class="string">"wdxtub-es"</span>,</div><div class="line">    <span class="attr">"status"</span>:<span class="string">"green"</span>,</div><div class="line">    <span class="attr">"timed_out"</span>:<span class="literal">false</span>,</div><div class="line">    <span class="attr">"number_of_nodes"</span>:<span class="number">2</span>,</div><div class="line">    <span class="attr">"number_of_data_nodes"</span>:<span class="number">2</span>,</div><div class="line">    <span class="attr">"active_primary_shards"</span>:<span class="number">821</span>,</div><div class="line">    <span class="attr">"active_shards"</span>:<span class="number">1642</span>,</div><div class="line">    <span class="attr">"relocating_shards"</span>:<span class="number">0</span>,</div><div class="line">    <span class="attr">"initializing_shards"</span>:<span class="number">0</span>,</div><div class="line">    <span class="attr">"unassigned_shards"</span>:<span class="number">0</span>,</div><div class="line">    <span class="attr">"delayed_unassigned_shards"</span>:<span class="number">0</span>,</div><div class="line">    <span class="attr">"number_of_pending_tasks"</span>:<span class="number">0</span>,</div><div class="line">    <span class="attr">"number_of_in_flight_fetch"</span>:<span class="number">0</span>,</div><div class="line">    <span class="attr">"task_max_waiting_in_queue_millis"</span>:<span class="number">0</span>,</div><div class="line">    <span class="attr">"active_shards_percent_as_number"</span>:<span class="number">100.0</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果状态是 green，那就没有问题啦。下面我们会结合不同的实例进行介绍</p>
<h3 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h3><p>Elasticsearch 的重启是一个非常需要按规矩操作的过程，否则会带来一系列的意想不到的问题，所以一定要按照官方建议的步骤来进行。</p>
<p>首先，因为 Elasticsearch 自带的高可用机制，一旦一个节点下线，就会在集群内部进行数据的重分配，会带来很多不必要的开销，所以需要先关闭，关闭方法是给集群发送一个请求，这个请求可以动态修改集群的设置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">PUT /_cluster/settings</div><div class="line">&#123;</div><div class="line">  &quot;persistent&quot;: &#123;</div><div class="line">    &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>而在重启之后需要进行数据恢复，如果停止索引并发送一个同步刷新请求，这个过程就会快很多，需要注意的是，如果此时有任何正在进行的索引操作，这个 flush 操作会失败，因此必要时我们可以重试多次，这是安全的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">POST /_flush/synced</div></pre></td></tr></table></figure>
<p>现在我们可以停止集群中的各个节点，完成重启或升级的操作。具体单台机器的操作可以看<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/rolling-upgrades.html#upgrade-node" target="_blank" rel="external">这里</a></p>
<p>完成之后，我们最好先启动那些 <code>node.master</code> 设置为 true 的节点（这也是默认设置），等到集群选举出了 master 节点，就可以继续添加数据节点了（即那些 <code>node.master</code> 为 false 且 <code>node.data</code> 为 true 的），这里我们可以用以下方式进行监控</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">GET _cat/health</div><div class="line"></div><div class="line">GET _cat/nodes</div></pre></td></tr></table></figure>
<p>每个节点加入集群之后，就会开始恢复本地保存的首要分片，一开始 <code>_cat/health</code> 查询的结果是 red，之后会变成 yellow，也就意味着所有的首要分片已经恢复了，但是其他的复制分片还没有恢复，因为我们一开始已经设置不恢复复制分片。</p>
<p>最后一步，我们需要重新开启集群的数据重分配，以保证集群的高可用性，操作也很简单：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">PUT /_cluster/settings</div><div class="line">&#123;</div><div class="line">  &quot;persistent&quot;: &#123;</div><div class="line">    &quot;cluster.routing.allocation.enable&quot;: &quot;all&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>当使用 <code>_cat/health</code> 的结果为 green 时，则重启和恢复顺利完成。</p>
<h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><p>无论是 Elasticsearch 官方还是社区，有很多插件可以完成监控的任务，但是本文只介绍默认的 API，主要是 <code>_cat</code> 和 <code>_cluster</code> 这两个接口，具体的文档可以在 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/cat.html" target="_blank" rel="external">cat API</a> 和 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster.html" target="_blank" rel="external">cluster API</a> 中查看，这里简要介绍一下。</p>
<p>对于 <code>_cat</code> 接口，在请求后面加上 <code>?v</code> 就会输出详细信息，例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ curl 10.1.1.10:9200/_cat/master?v</div><div class="line">id                     host      ip        node   </div><div class="line">AoVFmiU4Q2SAHNVcMGPsWQ 10.1.1.11 10.1.1.11 node-2</div></pre></td></tr></table></figure>
<p>如果对于字段的名字有疑问，可以使用 <code>?help</code>，例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ curl 10.1.1.10:9200/_cat/master?<span class="built_in">help</span></div><div class="line">id   |   | node id    </div><div class="line">host | h | host name  </div><div class="line">ip   |   | ip address </div><div class="line">node | n | node name</div></pre></td></tr></table></figure>
<p>如果只想要查看指定字段，可以利用 <code>?h=</code> 来进行指定，例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ curl 10.1.1.10:9200/_cat/nodes?h=ip,port,heapPercent,name</div><div class="line">10.1.1.11 9300 64 node-2 </div><div class="line">10.1.1.10 9300 71 node-1</div></pre></td></tr></table></figure>
<p>对于带数字的输出，可以利用管道来进行排序，比如下面的命令就可以按照索引大小来进行排序（这里的 <code>-rnk8</code> 指的是按照第八列排序）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ curl 10.1.1.10:9200/_cat/indices?bytes=b | sort -rnk8</div><div class="line">green open slog-2016-09-11   5 1 9729152      0 11128793222 5564396611 </div><div class="line">green open slog-2016-09-12   5 1 8355880      0  9539380440 4769690220 </div><div class="line">green open slog-2016-09-25   5 1 6720954      0  7415719218 3707859609 </div><div class="line">green open slog-2016-09-19   5 1 5840177      0  6575155002 3287577501 </div><div class="line">green open slog-2016-09-10   5 1 5858916      0  6504251544 3252125772</div></pre></td></tr></table></figure>
<p>其他比较常用的命令如下所示，具体的可以参阅文档，这里不再赘述：</p>
<ul>
<li><code>_cat/count</code> 文档总数</li>
<li><code>_cat/count/[index_name]</code> 某个索引的文档总数</li>
<li><code>_cat/fielddata?v</code> 显示每个节点的字段的堆内存使用量</li>
<li><code>_cat/health?v</code> 节点的健康状况<ul>
<li>可以使用下面的命令来自动检查集群状况</li>
<li><code>while true; do curl localhost:9200/_cat/health; sleep 120; done</code></li>
</ul>
</li>
<li><code>_cat/indices?v</code> 查看每个索引的详细信息，配合管道命令可以有很多应用，比如<ul>
<li>找出所有状态为 yellow 的索引 <code>curl localhost:9200/_cat/indices | grep ^yell</code></li>
<li>排序 <code>curl &#39;localhost:9200/_cat/indices?bytes=b&#39; | sort -rnk8</code></li>
<li>指定列及内存使用状况 <code>curl &#39;localhost:9200/_cat/indices?v&amp;h=i,tm&#39;</code></li>
</ul>
</li>
<li><code>_cat/nodes</code> 展示集群的拓扑结构</li>
<li><code>_cat/pending_tasks?v</code> 显示正在排队的任务</li>
<li><code>_cat/recovery?v</code> 显示分片恢复的过程</li>
<li><code>_cat/thread_pool?v</code> 显示线程池相关信息，有很多信息，可以根据需要进行查询</li>
<li><code>_cat/shards?v</code> 显示分片的相关信息</li>
<li><code>_cat/shards/[index-name]</code> 显示指定索引的分片信息  </li>
</ul>
<p><code>_cluster</code> 的接口的用法和 <code>_cat</code> 类似，这里就不再赘述了。</p>
<h3 id="合理计划服务器"><a href="#合理计划服务器" class="headerlink" title="合理计划服务器"></a>合理计划服务器</h3><p>在 Elasticsearch 的配置文件中，可以根据两个配置(<code>node.master</code> 和 <code>node.data</code>)选项来分配不同节点的角色，以达到提高服务器性能的目的。</p>
<ul>
<li><code>node.master: false; node.data: true</code> - 该节点只作为数据节点，用于存储和查询，资源消耗会较低</li>
<li><code>node.master: true; node.data: false</code> - 该节点只作为 master 节点，不存储数据，主要负责协调索引请求和查询请求</li>
<li><code>node.master: false; node.data: falst</code> - 该节点不作为 master 节点，也不存储数据，主要用于查询时的负载均衡（做结果汇总等工作）</li>
</ul>
<p>另外，一台服务器最好只部署一个节点以维持服务器稳定，毕竟资源是有限的，多开也没啥</p>
<h3 id="数据节点就是数据节点"><a href="#数据节点就是数据节点" class="headerlink" title="数据节点就是数据节点"></a>数据节点就是数据节点</h3><p>如果有配置数据节点，那么可以关闭其 http 功能，让它专注于索引的操作。插件之类的也最好安装到非数据节点服务器上，这样是一个兼顾数据安全和服务器性能的考虑。具体的配置项是 <code>http.enabled: false</code></p>
<h3 id="线程池配置"><a href="#线程池配置" class="headerlink" title="线程池配置"></a>线程池配置</h3><p>针对 Elasticsearch 的不同操作，可以配置不同大小的线程池，这个需要根据业务需求确定最佳值，场景的操作有：index, search, suggest, get, bulk, percolate, snapshot, snapshot_data, warmer, refresh。</p>
<p>这里以 index(创建/更新/删除索引数据)和 search(搜索操作)为例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">threadpool:</div><div class="line">     index:</div><div class="line">         type: fixed</div><div class="line">         size: 24（逻辑核心数*3）</div><div class="line">         queue_ size: 1000</div><div class="line"> </div><div class="line">     search:</div><div class="line">         type: fixed</div><div class="line">         size: 24（逻辑核心数*3）</div><div class="line">         queue_ size: 1000</div></pre></td></tr></table></figure>
<h3 id="分片与副本"><a href="#分片与副本" class="headerlink" title="分片与副本"></a>分片与副本</h3><p>默认的参数是 5 个分片(shard)和 1 个副本(replica)，碎片数目越多，索引速度越快；副本数目越多，搜索能力及可用性更高。分片的数目是在一开始就设定好的，但是副本的数目是可以后期修改的。</p>
<p>而在恢复数据的时候，可以先减少分片刷新索引的时间间隔，如</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">curl -XPUT <span class="string">'http://10.1.1.0:9200/_settings'</span> <span class="_">-d</span> <span class="string">'&#123; </span></div><div class="line">    "index" : &#123; </div><div class="line">        "refresh_interval" : "-1" </div><div class="line">    &#125; </div><div class="line">&#125;'</div></pre></td></tr></table></figure>
<p>完成插入之后再恢复</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">curl -XPUT <span class="string">'http://10.1.1.0:9200/_settings'</span> <span class="_">-d</span> <span class="string">'&#123; </span></div><div class="line">    "index" : &#123; </div><div class="line">        "refresh_interval" : "1s" </div><div class="line">    &#125; </div><div class="line">&#125;'</div></pre></td></tr></table></figure>
<h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><p>查询中最重要的思路就是 routing，尽量减少慢查询的次数。而当索引越来越大的时候，每个分片也会增大，查询速度就会变慢。一个可行的解决思路就是分索引，比方说不同类型的数据利用不同的 routing 进行分离。</p>
<p>还有一个从业务出发的思路，就是不索引不需要的字段，这样就可以减小集群所需资源的量。</p>
<h3 id="JVM-设置"><a href="#JVM-设置" class="headerlink" title="JVM 设置"></a>JVM 设置</h3><p>关于 JVM 的设置我还在摸索中，不过有几个技巧：</p>
<ul>
<li>JVM 的堆大小不要超过 32G，来源 <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html#compressed_oops" target="_blank" rel="external">Don’t Cross 32 GB!</a></li>
<li>使用 <code>bootstrap.mlockall: true</code>，启动时就锁定内存</li>
<li>用较小的 heapsize 配合 SSD</li>
</ul>
<h3 id="Full-GC-问题"><a href="#Full-GC-问题" class="headerlink" title="Full GC 问题"></a>Full GC 问题</h3><p>这里以一个实例来介绍我是如何在生产环境中排查和修复 Elasticsearch 集群忽然响应时间剧增的问题的。</p>
<p>情况是这样的，随着接入 Elasticsearch 的数据量增大，忽然有一个周末出问题了 - ES 集群的查询和插入都变得巨慢无比。监控报警都把邮箱和手机发爆炸了。</p>
<p>那么问题来了，究竟是哪里出了乱子？</p>
<p>因为发送数据的客户端和服务器近期并没有特别大的改动，我检查了 Kafka 队列也一切正常，于是可以锁定问题出在 Elasticsearch 身上。</p>
<p>第一反应就是先去看 Elasticsearch 的日志，发现根据日志显示，一致在不停的垃圾回收。因此对症下药，把 JVM 的堆内存改大。但是在集群重启之后仍然会出现性能急剧下降的状况，于是继续检查日志，发现是因为 JVM 进行 Full GC 的时间过长，导致 ES 集群认为拓扑结构改变，开始迁移数据所导致。而迁移数据本身又会导致 Full GC，让情况更糟的是，在 Full GC 结束之后，集群的拓扑结构又再次改变，于是就陷入了这样的死循环。</p>
<p>破局的方法其实非常简单粗暴，把检测集群拓扑的时间间隔和超时次数加大一点，留足够的时间给 JVM 进行 Full GC 即可。</p>
<h3 id="导入数据过慢问题"><a href="#导入数据过慢问题" class="headerlink" title="导入数据过慢问题"></a>导入数据过慢问题</h3><p>最近在从 MySQL 数据库中导入大量数据到 Elasticsearch 的时候，出现写入极其缓慢，甚至在使用了 bulk（批量）接口之后也没有改善的问题。奇怪的是，从 MySQL 的表 A 和表 B 中导入甚至会有几十倍的速度差距，这是为什么呢？</p>
<p>经过一步一步排查，基本上 ES 的文档和可以配置的参数都调整过之后并没有改善，于是开始从数据源入手，最后发现表 A 和 表 B 的数据顺序是不太一样的。表 A 中基本是顺序递增的数据，主键（自增长 ID）基本对应于时间顺序；而表 B 中则基本是随机插入的，所以按照数据库中的 ID 进行顺序导出，就会发现相邻记录对应的日期可能相差很大，而正好我们在 ES 中又是根据日期来进行索引的切割的，导致每次都需要在不同的索引中进行切换，速度自然上不去。</p>
<p>所以我们把从 MySQL 数据库中选择数据的语句利用 timestamp 作为 order by 的标准，导入速度就很快了。</p>
<p>这里有一点需要注意每次除了 ID 之外，还需要记录 timestamp 的值，这样才能保证是顺序导入的 <code>where id &gt; xxx and timestamp &gt; xxx</code>，其中 timestamp 每次需要归 0。</p>
<h2 id="试一试"><a href="#试一试" class="headerlink" title="试一试"></a>试一试</h2><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;施工中：集群配置和全球部署可能带来的问题&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="通天塔" scheme="http://wdxtub.com/tags/%E9%80%9A%E5%A4%A9%E5%A1%94/"/>
    
      <category term="日志" scheme="http://wdxtub.com/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="平台" scheme="http://wdxtub.com/tags/%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="集群" scheme="http://wdxtub.com/tags/%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>【通天塔之日志分析平台】伍 Logstash 技巧指南</title>
    <link href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-5/"/>
    <id>http://wdxtub.com/2016/11/19/babel-log-analysis-platform-5/</id>
    <published>2016-11-19T03:11:06.000Z</published>
    <updated>2016-11-21T14:27:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>施工中：如题</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><ul>
<li><a href="http://wdxtub.com/2016/11/19/babel-series-intro/">『通天塔』技术作品合集介绍</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-0/">零 系列简介与环境配置</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-1/">壹 ELK 环境搭建</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-2/">贰 Kafka 缓冲区</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-3/">叁 监控、安全、报警与通知</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-4/">肆 从单机到集群</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-5/">伍 Logstash 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-6/">陆 Elasticsearch 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-7/">柒 Kibana 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-8/">捌 实例：接入外部应用日志</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-9/">玖 业界：大厂实践</a></li>
</ul>
<h2 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h2><h2 id="老介绍"><a href="#老介绍" class="headerlink" title="老介绍"></a>老介绍</h2><p>Logstash 最打动我的是整个社区的风格，而这个风格和作者 Jordan Sissel 本人分不开，虽然现在最初的 Google groups 已经搬迁到 elastic 官方的论坛，但是还是能看到这么一句话：</p>
<blockquote>
<p>Remember: if a new user has a bad time, it’s a bug in logstash</p>
</blockquote>
<p>这是什么精神，这是白求恩精神，做一个高尚的人，一个纯粹的人，一个有道德的人，一个脱离了低级趣味的人，一个有益于人民的人。嗯，就是这样。</p>
<p>简单的入门可以参考我的 <a href="./2016/07/24/logstash-guide/">Logstash 入门指南</a>，这里重点介绍一些中高级用法。</p>
<p>Logstash 支持的数据值类型有 bool, string, number, array 和 hash，和 Redis 一样，支持得不多，但是完全够用。支持的条件判断和表达式则比较丰富，如：</p>
<ul>
<li>基本条件判断 <code>==</code>, <code>!=</code>, <code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code></li>
<li><code>=~</code> 匹配正则, <code>!~</code> 不匹配正则</li>
<li><code>in</code> 包含, <code>not in</code> 不包含</li>
<li><code>and</code> 与, <code>or</code> 或, <code>nand</code> 非与, <code>xor</code> 非或</li>
<li><code>()</code> 复合表达式, <code>!()</code> 表达式结果取反</li>
</ul>
<p>比方说我们有一个字段是 <code>type</code>，我们想要过滤一下做指定操作的话，可以</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">if &quot;good&quot; in [type] &#123;</div><div class="line">    // do something</div><div class="line">&#125; else &#123;</div><div class="line">    // do something</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从 Logstash 5.0 开始，可以在 <code>$LS_HOME/config/logstash.yml</code> 文件进行所有的命令行参数配置，例如</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><div class="line"><span class="attr">pipeline:</span></div><div class="line"><span class="attr">    workers:</span> <span class="number">24</span></div><div class="line"><span class="attr">    batch:</span></div><div class="line"><span class="attr">        size:</span> <span class="number">125</span></div><div class="line"><span class="attr">        delay:</span> <span class="number">5</span></div></pre></td></tr></table></figure>
<h3 id="Plugin"><a href="#Plugin" class="headerlink" title="Plugin"></a>Plugin</h3><p>使用之前我们先要安装一下 ruby，命令为 <code>sudo apt install ruby</code>，然后我们可以运行 <code>logstash-plugin list</code> 来看看本机中目前有多少插件可以用，这里会有一个警告，不过查阅 github issue 中说没有问题，那就暂时忽略。插件很多，这里就不一一介绍，简单贴一下 help 文档应该就一目了然了：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">dawang@dawang-Parallels-Virtual-Platform:~$ logstash-plugin -hUsage:    bin/logstash-plugin [OPTIONS] SUBCOMMAND [ARG] ...Parameters:    SUBCOMMAND                    subcommand    [ARG] ...                     subcommand argumentsSubcommands:    install                       Install a plugin    uninstall                     Uninstall a plugin    update                        Update a plugin    pack                          Package currently installed plugins    unpack                        Unpack packaged plugins    list                          List all installed pluginsOptions:    -h, --help                    <span class="built_in">print</span> <span class="built_in">help</span></div></pre></td></tr></table></figure>
<h3 id="自动运行"><a href="#自动运行" class="headerlink" title="自动运行"></a>自动运行</h3><p>通常来说，我们需要 logstash 在后台长期运行，否则每次需要去各台机器上手动操作，会很麻烦。</p>
<p>有两种方法，一种是配合 <code>crontab</code>，定期执行指定命令，另一种是让 logstash 以服务或者守护进程的形式运行，配合配置文件中的 schedule 即可。其中 <code>crontab</code> 的方法可以参阅 <a href="./2016/07/26/crontab-guide/">Crontab 指南</a>，这里主要介绍另外四种方法。</p>
<p><strong>方法一：标准的 service 方式</strong></p>
<p>在 <code>/etc/init.d/logstash</code> 脚本中，会加载 <code>/etc/init.d/functions</code> 库文件，利用其中的 daemon 函数，将 logstash 进程作为后台程序运行。</p>
<p>我们要做的是把配置文件都放到 <code>/etc/logstsh/</code> 目录下，必须以 <code>.conf</code> 结尾，然后我们执行 <code>service logstash start</code> 即可（注意要在配置文件中设定好 schedule，这样就可以按照要求自动执行了）</p>
<p><strong>方法二：nohup 方式</strong></p>
<p>简单来说，一句话就可以搞定，如果想让某命令在后台长期运行，需要在命令前加 <code>nohup</code>，后面加 <code>&amp;</code></p>
<p><strong>方法三：用 tmux/screen</strong></p>
<p>一般来说，如果我需要让服务器跑一堆命令又不想挂着 ssh 连接的话，直接用 tmux/screen 运行命令即可，这样即使退出，命令也依然在执行，具体的使用可以参考 <a href="./2016/03/30/tmux-guide/">tmux 指南</a></p>
<p><strong>方法四：daemontools 方式</strong></p>
<p>如果需要长期在后台运行大量程序，建议使用 daemontools 工具，可以通过配置文件来管理操作程序，类似于自动化的 tmux，比方说 python 实现的 <code>supervisord</code>，perl 实现的 <code>ubic</code> 或者 ruby 实现的 <code>god</code>，具体的用法之后会写日志进行说明</p>
<h3 id="Input"><a href="#Input" class="headerlink" title="Input"></a>Input</h3><p>我们的配置文件中一定需要有一个 input，如果没有的话，就会默认使用 <code>input/stdin</code>。这里只记录一些最常用和最基本的插件，更多的插件可以参考官方文档或参考链接中的教程。</p>
<ul>
<li>读取文件 File</li>
<li>读取 Syslog 数据</li>
<li>编码插件 Codec: JSON</li>
</ul>
<h3 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h3><p>这部分是 Logstash 最具特色和扩展性的部分（但并不一定是必须的），这里只记录一些最常用和最基本的插件，更多的插件可以参考官方文档或参考链接中的教程。</p>
<ul>
<li>时间处理 Date，包括 <code>ISO8601</code>, <code>UNIX</code>, <code>UNIX_MS</code>, <code>TAI64N</code> 和 <code>Joda-Time</code></li>
<li>正则捕获 Grok，这个插件可以摆弄出非常多的黑魔法，可以考虑重点应用，记得使用 Grok Debugger 来调试 grok 表达式</li>
<li>GeoIP 地址查询，用于统计区域活着可视化地图</li>
<li>Mutate 数据修改，可以用来转换类型、处理字符串以及处理字段（重命名、更新、替换等）</li>
<li>split 拆分事件</li>
</ul>
<h3 id="Output"><a href="#Output" class="headerlink" title="Output"></a>Output</h3><p>我们的配置文件中一定需要有一个 input，如果没有的话，就会默认使用 <code>output/stdout</code>。这里只记录一些最常用和最基本的插件，更多的插件可以参考官方文档或参考链接中的教程。</p>
<ul>
<li>保存到 Elasticsearch 中，注意几个参数： <code>flush_size</code> 是攒够这个大小才写入，<code>idle_flush_time</code> 是隔这么多时间写入一次，这俩都会影响 ES 的写入性能</li>
<li>发邮件 Email</li>
<li>调用命令执行 exec，比方说可以发短信，最好只用于少量的信息处理场景</li>
<li>保存成文件 file</li>
<li>发送到 HDFS 可以使用 <code>hadoop_webhdfs</code> 插件</li>
</ul>
<h3 id="监控-API"><a href="#监控-API" class="headerlink" title="监控 API"></a>监控 API</h3><p>从 Logstash 5.0 开始提供了监控 API，就不再像以前那样比较黑盒了，具体有</p>
<ul>
<li>events <code>curl -s localhost:9600/_node/stats/events?pretty=true</code></li>
<li>jvm <code>curl -s localhost:9600/_node/stats/jvm?pretty=true</code></li>
<li>process <code>curl -s localhost:9600/_node/stats/process?pretty=true</code></li>
<li>热线程统计 <code>curl -s localhost:9600/_node/stats/hot_threads?human=true</code></li>
</ul>
<h2 id="疑难杂症"><a href="#疑难杂症" class="headerlink" title="疑难杂症"></a>疑难杂症</h2><p>Logstash 的字段中不能出现 <code>.</code> 这个问题，可以通过 <code>de_dot</code> 这个插件解决，安装命令 <code>bin/logstash-plugin install logstash-filter-de_dot</code>，然后在 logstash 的配置文件中添加如下一段代码即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">filter &#123;</div><div class="line">  de_dot &#123; &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="试一试"><a href="#试一试" class="headerlink" title="试一试"></a>试一试</h2><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;施工中：如题&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="通天塔" scheme="http://wdxtub.com/tags/%E9%80%9A%E5%A4%A9%E5%A1%94/"/>
    
      <category term="日志" scheme="http://wdxtub.com/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="平台" scheme="http://wdxtub.com/tags/%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="Logstash" scheme="http://wdxtub.com/tags/Logstash/"/>
    
  </entry>
  
  <entry>
    <title>【通天塔之日志分析平台】陆 Elasticsearch 技巧指南</title>
    <link href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-6/"/>
    <id>http://wdxtub.com/2016/11/19/babel-log-analysis-platform-6/</id>
    <published>2016-11-19T03:11:05.000Z</published>
    <updated>2016-11-21T14:27:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>施工中：如题</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><ul>
<li><a href="http://wdxtub.com/2016/11/19/babel-series-intro/">『通天塔』技术作品合集介绍</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-0/">零 系列简介与环境配置</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-1/">壹 ELK 环境搭建</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-2/">贰 Kafka 缓冲区</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-3/">叁 监控、安全、报警与通知</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-4/">肆 从单机到集群</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-5/">伍 Logstash 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-6/">陆 Elasticsearch 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-7/">柒 Kibana 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-8/">捌 实例：接入外部应用日志</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-9/">玖 业界：大厂实践</a></li>
</ul>
<h2 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h2><h2 id="老介绍"><a href="#老介绍" class="headerlink" title="老介绍"></a>老介绍</h2><p>配置文件在 <code>/etc/elasticsearch/elasticsearch.yml</code>，重启命令 <code>sudo service elasticsearch restart</code></p>
<h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>这部分内容虽然不一定对工程有立竿见影的帮助，但是知其然还知其所以然，才是高手的做事风格。那么问题来了</p>
<blockquote>
<p>写入的数据是如何变成 Elasticsearch 里可以被检索和聚合的索引内容的？</p>
</blockquote>
<p>关键在于『倒排索引』，新收到的数据会被写入到内存的 buffer 中，然后在一定的时间间隔后刷到磁盘中，成为一个新的 segment，然后另外使用一个 commit 文件来记录所有的 segment，数据只有在成为 segment 之后才能被检索。默认的从 buffer 到 segment 的时间间隔是 1 秒，基本已经是『实时』了，如果需要更改，也可以调用 <code>/_refresh</code> 接口。不过很多时候我们不需要这么『实时』，所以可以加大这个时间间隔，以获得更快的写入性能。导入历史数据时甚至可以关闭，导入完成再重新开启。</p>
<p>为了保证数据从 buffer 到 segment 的一致性，Elasticsearch 还会有一个名为 Translog 的记录，至于  Translog 的一致性则是通过定期保存到磁盘中来实现的</p>
<p>前面说过 Lucene 会不断开新文件，这样磁盘上就会有一堆小文件，所以 ES 会在后台把这些零散的 segment 做数据归并，归并完成后就可以把小的 segment 删掉，也就减少了 segment 的数量了。为了不影响 IO 和 CPU，会对归并线程做一定的限制，我们可以根据硬件的不同来调整 <code>indices.store.throttle.max_bytes_per_sec</code> 来提高性能。与此同时，我们也有不同的归并策略，不过总体来说就是让我们加大 flush 的间隔，尽量让每次新生成的 segment 本身就比较大。</p>
<p>ES 的分布式处理主要是通过 sharding 机制，也会保留副本进行冗余备份，具体采用的是 gossip 协议，配置也不算复杂，这里就不赘述，如果有机会专门写一篇实例教程。</p>
<h3 id="增删改查"><a href="#增删改查" class="headerlink" title="增删改查"></a>增删改查</h3><p>ES 虽然不是数据库，不过其特性决定了，这就是一个很好的 NoSQL 数据库嘛，因为 ELK stack 的缘故，写入由 Logstash 负责，查询由 Kibana 负责，不过修改和删除就有些无能为力了（毕竟为什么要简单修改和删除日志？），可是修改和删除是数据库必须的功能，好在 ES 提供了 RESTful 接口来处理 JSON 请求，最简单的用 <code>curl</code> 就可以完成各类操作。这里推荐一个 Chrome 的插件 Postman，可以很方便进行各类测试。具体如何发送请求请参考文档，这里不赘述了。</p>
<h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3><p>前面的增删改查针对的是单条记录，ES 中更重要的是搜索。这里回顾一下：刚写入的数据，可以通过 translog 立刻获取；但是直到其成为一个 segment 之后，才能被搜索到</p>
<p>可以利用 <code>/_search?q=</code> 这种 querystring 的简单语法，或者发送完整的 json 来进行查询。具体可以依据版本查阅文档，这里不赘述。</p>
<p>另外，聚合、管道聚合</p>
<h3 id="其他功能"><a href="#其他功能" class="headerlink" title="其他功能"></a>其他功能</h3><p>Elasticsearch 目前已经可以和 Hadoop, HDFS, Spark Streaming 等大数据工具连接使用。如果需要配置权限，可以使用 Elastic 官方的 Shield，如果想用开源的话，可以使用 <a href="https://github.com/floragunncom/search-guard" target="_blank" rel="external">search-guard</a>，这样不同的用户可以访问不同的索引，达到权限控制。</p>
<p>监控集群健康状态也可以通过接口访问，比如 <code>curl -XGET 127.0.0.1:9200/_cluster/health?pretty</code>，更多监控信息请参阅文档，这里不赘述。</p>
<p>需要提的一点就是 GC 是非常影响性能的，所以我们来简单介绍一下 JVM 的机制。启动 JVM 虚拟机的时候，会分配固定大小的内存块，也就是堆 heap。堆又分成两组，Young 组是为新实例化的对象所分配的空间，比较小，一般来说几百 MB，Young 组内又分为两个 survivor 空间。Young 空间满了后，就垃圾回收一次，还存活的对象放到幸存空间中，失效的就被移除。Old 组就是保存那些重启存活且一段时间不会变化的内容，对于 ES 来说可能有 30 GB 内存是 Old 组，同样，满了之后就垃圾回收。</p>
<p>垃圾回收的时候，JVM 采用的是 STW(Stop The World) 机制，Young 组比较小还好，但是 Old 组可能需要几秒十几秒，那就是服务器无响应啊！所以我们必须非常关注 GC 性能。</p>
<p>如果 ES 集群中经常有很耗时的 GC，说明内存不足，如果影响集群之间 ping 的话，就会退出集群，然后因为分片缘故导致更大的影响。我们可以在节点状态中的 <code>jvm</code> 部分查看对应的数值，最重要是 <code>heap_used_percent</code>，如果大于 75，那么就要垃圾回收了，如果长期在 75 以上，那就是内存不足。</p>
<p>注：节点状态可以通过 <code>curl -XGET http://127.0.0.1:9200/_nodes/stats</code> 查看，下面是一个例子（省略了部分内容）：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><div class="line">&#123;</div><div class="line">  <span class="attr">"cluster_name"</span> : <span class="string">"wdxtub"</span>,</div><div class="line">  <span class="attr">"nodes"</span> : &#123;</div><div class="line">    <span class="attr">"M-OzSwFBTc6uU8ndWU1SFw"</span> : &#123;</div><div class="line">      <span class="attr">"timestamp"</span> : <span class="number">1470310258934</span>,</div><div class="line">      <span class="attr">"name"</span> : <span class="string">"Kleinstocks"</span>,</div><div class="line">      <span class="attr">"transport_address"</span> : <span class="string">"127.0.0.1:9302"</span>,</div><div class="line">      <span class="attr">"host"</span> : <span class="string">"127.0.0.1"</span>,</div><div class="line">      <span class="attr">"ip"</span> : [ <span class="string">"127.0.0.1:9302"</span>, <span class="string">"NONE"</span> ],</div><div class="line">      <span class="attr">"indices"</span> : &#123;</div><div class="line">        <span class="attr">"docs"</span> : &#123;</div><div class="line">          <span class="attr">"count"</span> : <span class="number">7240861</span>,</div><div class="line">          <span class="attr">"deleted"</span> : <span class="number">257</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"store"</span> : &#123;</div><div class="line">          <span class="attr">"size_in_bytes"</span> : <span class="number">1836976476</span>,</div><div class="line">          <span class="attr">"throttle_time_in_millis"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"indexing"</span> : &#123;</div><div class="line">          <span class="attr">"index_total"</span> : <span class="number">17746868</span>,</div><div class="line">          <span class="attr">"index_time_in_millis"</span> : <span class="number">5340065</span>,</div><div class="line">          <span class="attr">"index_current"</span> : <span class="number">2</span>,</div><div class="line">          <span class="attr">"index_failed"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"delete_total"</span> : <span class="number">418</span>,</div><div class="line">          <span class="attr">"delete_time_in_millis"</span> : <span class="number">70</span>,</div><div class="line">          <span class="attr">"delete_current"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"noop_update_total"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"is_throttled"</span> : <span class="literal">false</span>,</div><div class="line">          <span class="attr">"throttle_time_in_millis"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"get"</span> : &#123;</div><div class="line">          <span class="attr">"total"</span> : <span class="number">351</span>,</div><div class="line">          <span class="attr">"time_in_millis"</span> : <span class="number">146</span>,</div><div class="line">          <span class="attr">"exists_total"</span> : <span class="number">240</span>,</div><div class="line">          <span class="attr">"exists_time_in_millis"</span> : <span class="number">104</span>,</div><div class="line">          <span class="attr">"missing_total"</span> : <span class="number">111</span>,</div><div class="line">          <span class="attr">"missing_time_in_millis"</span> : <span class="number">42</span>,</div><div class="line">          <span class="attr">"current"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"search"</span> : &#123;</div><div class="line">          <span class="attr">"open_contexts"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"query_total"</span> : <span class="number">2408275</span>,</div><div class="line">          <span class="attr">"query_time_in_millis"</span> : <span class="number">5930419</span>,</div><div class="line">          <span class="attr">"query_current"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"fetch_total"</span> : <span class="number">474268</span>,</div><div class="line">          <span class="attr">"fetch_time_in_millis"</span> : <span class="number">2706552</span>,</div><div class="line">          <span class="attr">"fetch_current"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"scroll_total"</span> : <span class="number">80</span>,</div><div class="line">          <span class="attr">"scroll_time_in_millis"</span> : <span class="number">158449847</span>,</div><div class="line">          <span class="attr">"scroll_current"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"merges"</span> : &#123;</div><div class="line">          <span class="attr">"current"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"current_docs"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"current_size_in_bytes"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"total"</span> : <span class="number">85947</span>,</div><div class="line">          <span class="attr">"total_time_in_millis"</span> : <span class="number">30458385</span>,</div><div class="line">          <span class="attr">"total_docs"</span> : <span class="number">876375857</span>,</div><div class="line">          <span class="attr">"total_size_in_bytes"</span> : <span class="number">256573193466</span>,</div><div class="line">          <span class="attr">"total_stopped_time_in_millis"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"total_throttled_time_in_millis"</span> : <span class="number">348966</span>,</div><div class="line">          <span class="attr">"total_auto_throttle_in_bytes"</span> : <span class="number">65901809302</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"refresh"</span> : &#123;</div><div class="line">          <span class="attr">"total"</span> : <span class="number">833546</span>,</div><div class="line">          <span class="attr">"total_time_in_millis"</span> : <span class="number">7243577</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"flush"</span> : &#123;</div><div class="line">          <span class="attr">"total"</span> : <span class="number">4038</span>,</div><div class="line">          <span class="attr">"total_time_in_millis"</span> : <span class="number">58670</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"warmer"</span> : &#123;</div><div class="line">          <span class="attr">"current"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"total"</span> : <span class="number">309738</span>,</div><div class="line">          <span class="attr">"total_time_in_millis"</span> : <span class="number">102270</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"query_cache"</span> : &#123;</div><div class="line">          <span class="attr">"memory_size_in_bytes"</span> : <span class="number">588080</span>,</div><div class="line">          <span class="attr">"total_count"</span> : <span class="number">47737532</span>,</div><div class="line">          <span class="attr">"hit_count"</span> : <span class="number">66843</span>,</div><div class="line">          <span class="attr">"miss_count"</span> : <span class="number">47670689</span>,</div><div class="line">          <span class="attr">"cache_size"</span> : <span class="number">408</span>,</div><div class="line">          <span class="attr">"cache_count"</span> : <span class="number">1687</span>,</div><div class="line">          <span class="attr">"evictions"</span> : <span class="number">1279</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"fielddata"</span> : &#123;</div><div class="line">          <span class="attr">"memory_size_in_bytes"</span> : <span class="number">16791680</span>,</div><div class="line">          <span class="attr">"evictions"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"percolate"</span> : &#123;</div><div class="line">          <span class="attr">"total"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"time_in_millis"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"current"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"memory_size_in_bytes"</span> : <span class="number">-1</span>,</div><div class="line">          <span class="attr">"memory_size"</span> : <span class="string">"-1b"</span>,</div><div class="line">          <span class="attr">"queries"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"completion"</span> : &#123;</div><div class="line">          <span class="attr">"size_in_bytes"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"segments"</span> : &#123;</div><div class="line">          <span class="attr">"count"</span> : <span class="number">14771</span>,</div><div class="line">          <span class="attr">"memory_in_bytes"</span> : <span class="number">162052342</span>,</div><div class="line">          <span class="attr">"terms_memory_in_bytes"</span> : <span class="number">101949950</span>,</div><div class="line">          <span class="attr">"stored_fields_memory_in_bytes"</span> : <span class="number">4785984</span>,</div><div class="line">          <span class="attr">"term_vectors_memory_in_bytes"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"norms_memory_in_bytes"</span> : <span class="number">77376</span>,</div><div class="line">          <span class="attr">"doc_values_memory_in_bytes"</span> : <span class="number">55239032</span>,</div><div class="line">          <span class="attr">"index_writer_memory_in_bytes"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"index_writer_max_memory_in_bytes"</span> : <span class="number">1583616000</span>,</div><div class="line">          <span class="attr">"version_map_memory_in_bytes"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"fixed_bit_set_memory_in_bytes"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"translog"</span> : &#123;</div><div class="line">          <span class="attr">"operations"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"size_in_bytes"</span> : <span class="number">132999</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"suggest"</span> : &#123;</div><div class="line">          <span class="attr">"total"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"time_in_millis"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"current"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"request_cache"</span> : &#123;</div><div class="line">          <span class="attr">"memory_size_in_bytes"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"evictions"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"hit_count"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"miss_count"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"recovery"</span> : &#123;</div><div class="line">          <span class="attr">"current_as_source"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"current_as_target"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"throttle_time_in_millis"</span> : <span class="number">0</span></div><div class="line">        &#125;</div><div class="line">      &#125;,</div><div class="line">      <span class="attr">"os"</span> : &#123;</div><div class="line">        <span class="attr">"timestamp"</span> : <span class="number">1470310262865</span>,</div><div class="line">        <span class="attr">"cpu_percent"</span> : <span class="number">56</span>,</div><div class="line">        <span class="attr">"load_average"</span> : <span class="number">2.04</span>,</div><div class="line">        <span class="attr">"mem"</span> : &#123;</div><div class="line">          <span class="attr">"total_in_bytes"</span> : <span class="number">16827527168</span>,</div><div class="line">          <span class="attr">"free_in_bytes"</span> : <span class="number">761749504</span>,</div><div class="line">          <span class="attr">"used_in_bytes"</span> : <span class="number">16065777664</span>,</div><div class="line">          <span class="attr">"free_percent"</span> : <span class="number">5</span>,</div><div class="line">          <span class="attr">"used_percent"</span> : <span class="number">95</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"swap"</span> : &#123;</div><div class="line">          <span class="attr">"total_in_bytes"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"free_in_bytes"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"used_in_bytes"</span> : <span class="number">0</span></div><div class="line">        &#125;</div><div class="line">      &#125;,</div><div class="line">      <span class="attr">"process"</span> : &#123;</div><div class="line">        <span class="attr">"timestamp"</span> : <span class="number">1470310262865</span>,</div><div class="line">        <span class="attr">"open_file_descriptors"</span> : <span class="number">26370</span>,</div><div class="line">        <span class="attr">"max_file_descriptors"</span> : <span class="number">65535</span>,</div><div class="line">        <span class="attr">"cpu"</span> : &#123;</div><div class="line">          <span class="attr">"percent"</span> : <span class="number">30</span>,</div><div class="line">          <span class="attr">"total_in_millis"</span> : <span class="number">1508401460</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"mem"</span> : &#123;</div><div class="line">          <span class="attr">"total_virtual_in_bytes"</span> : <span class="number">7386607616</span></div><div class="line">        &#125;</div><div class="line">      &#125;,</div><div class="line">      <span class="attr">"jvm"</span> : &#123;</div><div class="line">        <span class="attr">"timestamp"</span> : <span class="number">1470310262874</span>,</div><div class="line">        <span class="attr">"uptime_in_millis"</span> : <span class="number">1237196806</span>,</div><div class="line">        <span class="attr">"mem"</span> : &#123;</div><div class="line">          <span class="attr">"heap_used_in_bytes"</span> : <span class="number">2868003728</span>,</div><div class="line">          <span class="attr">"heap_used_percent"</span> : <span class="number">67</span>,</div><div class="line">          <span class="attr">"heap_committed_in_bytes"</span> : <span class="number">4260102144</span>,</div><div class="line">          <span class="attr">"heap_max_in_bytes"</span> : <span class="number">4260102144</span>,</div><div class="line">          <span class="attr">"non_heap_used_in_bytes"</span> : <span class="number">75855480</span>,</div><div class="line">          <span class="attr">"non_heap_committed_in_bytes"</span> : <span class="number">109502464</span>,</div><div class="line">          <span class="attr">"pools"</span> : &#123;</div><div class="line">            <span class="attr">"young"</span> : &#123;</div><div class="line">              <span class="attr">"used_in_bytes"</span> : <span class="number">193899664</span>,</div><div class="line">              <span class="attr">"max_in_bytes"</span> : <span class="number">279183360</span>,</div><div class="line">              <span class="attr">"peak_used_in_bytes"</span> : <span class="number">279183360</span>,</div><div class="line">              <span class="attr">"peak_max_in_bytes"</span> : <span class="number">279183360</span></div><div class="line">            &#125;,</div><div class="line">            <span class="attr">"survivor"</span> : &#123;</div><div class="line">              <span class="attr">"used_in_bytes"</span> : <span class="number">29947264</span>,</div><div class="line">              <span class="attr">"max_in_bytes"</span> : <span class="number">34865152</span>,</div><div class="line">              <span class="attr">"peak_used_in_bytes"</span> : <span class="number">34865152</span>,</div><div class="line">              <span class="attr">"peak_max_in_bytes"</span> : <span class="number">34865152</span></div><div class="line">            &#125;,</div><div class="line">            <span class="attr">"old"</span> : &#123;</div><div class="line">              <span class="attr">"used_in_bytes"</span> : <span class="number">2644156800</span>,</div><div class="line">              <span class="attr">"max_in_bytes"</span> : <span class="number">3946053632</span>,</div><div class="line">              <span class="attr">"peak_used_in_bytes"</span> : <span class="number">3916390728</span>,</div><div class="line">              <span class="attr">"peak_max_in_bytes"</span> : <span class="number">3946053632</span></div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"threads"</span> : &#123;</div><div class="line">          <span class="attr">"count"</span> : <span class="number">78</span>,</div><div class="line">          <span class="attr">"peak_count"</span> : <span class="number">88</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"gc"</span> : &#123;</div><div class="line">          <span class="attr">"collectors"</span> : &#123;</div><div class="line">            <span class="attr">"young"</span> : &#123;</div><div class="line">              <span class="attr">"collection_count"</span> : <span class="number">764634</span>,</div><div class="line">              <span class="attr">"collection_time_in_millis"</span> : <span class="number">25826848</span></div><div class="line">            &#125;,</div><div class="line">            <span class="attr">"old"</span> : &#123;</div><div class="line">              <span class="attr">"collection_count"</span> : <span class="number">500</span>,</div><div class="line">              <span class="attr">"collection_time_in_millis"</span> : <span class="number">56557</span></div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;,</div><div class="line">      <span class="attr">"thread_pool"</span> : &#123;</div><div class="line">        <span class="attr">"bulk"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">4</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">4</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">877671</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"fetch_shard_started"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">8</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">8</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">17037949</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"fetch_shard_store"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"flush"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">1</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">2</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">10416</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"force_merge"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"generic"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">4</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">5</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">17161902</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"get"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">4</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">4</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">351</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"index"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">4</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">4</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">302497</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"listener"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">2</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">2</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">457516</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"management"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">5</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">1</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">5</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">838887</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"percolate"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"refresh"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">1</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">2</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">833549</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"search"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">7</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">105785</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">7</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">2930414</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"snapshot"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"suggest"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">0</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"warmer"</span> : &#123;</div><div class="line">          <span class="attr">"threads"</span> : <span class="number">1</span>,</div><div class="line">          <span class="attr">"queue"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"active"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"rejected"</span> : <span class="number">0</span>,</div><div class="line">          <span class="attr">"largest"</span> : <span class="number">2</span>,</div><div class="line">          <span class="attr">"completed"</span> : <span class="number">864039</span></div><div class="line">        &#125;</div><div class="line">      &#125;,</div><div class="line">      <span class="attr">"fs"</span> : &#123;</div><div class="line">        <span class="attr">"timestamp"</span> : <span class="number">1470310262388</span>,</div><div class="line">        <span class="attr">"total"</span> : &#123;</div><div class="line">          <span class="attr">"total_in_bytes"</span> : <span class="number">316934193152</span>,</div><div class="line">          <span class="attr">"free_in_bytes"</span> : <span class="number">32878755840</span>,</div><div class="line">          <span class="attr">"available_in_bytes"</span> : <span class="number">16755851264</span></div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"data"</span> : [ &#123;</div><div class="line">          <span class="attr">"path"</span> : <span class="string">"/data2/active2/dji-active/nodes/0"</span>,</div><div class="line">          <span class="attr">"mount"</span> : <span class="string">"/data2 (/dev/xvdf)"</span>,</div><div class="line">          <span class="attr">"type"</span> : <span class="string">"ext4"</span>,</div><div class="line">          <span class="attr">"total_in_bytes"</span> : <span class="number">316934193152</span>,</div><div class="line">          <span class="attr">"free_in_bytes"</span> : <span class="number">32878755840</span>,</div><div class="line">          <span class="attr">"available_in_bytes"</span> : <span class="number">16755851264</span>,</div><div class="line">          <span class="attr">"spins"</span> : <span class="string">"false"</span></div><div class="line">        &#125; ]</div><div class="line">      &#125;,</div><div class="line">      <span class="attr">"transport"</span> : &#123;</div><div class="line">        <span class="attr">"server_open"</span> : <span class="number">0</span>,</div><div class="line">        <span class="attr">"rx_count"</span> : <span class="number">30</span>,</div><div class="line">        <span class="attr">"rx_size_in_bytes"</span> : <span class="number">8193</span>,</div><div class="line">        <span class="attr">"tx_count"</span> : <span class="number">36</span>,</div><div class="line">        <span class="attr">"tx_size_in_bytes"</span> : <span class="number">13202</span></div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>状态比较多，这里挑几个说一下，首先是 <code>gc</code> 部分，显示的是 young 和 old gc 的耗时，一般来说 young 会比较大，这是正常的。一次 young gc 大概在 1-2ms，old gc 在 100 ms 左右，如果有量级上的差距，建议打开 slow-gc 日志，具体研究原因。</p>
<p><code>thread_pool</code> 是线程池信息，我们主要看 <code>rejected</code> 的数据，如果这个数值很大，就说明 ES 忙不过来了。</p>
<p>其他的基本就是系统和文件系统的数据如果 <code>fielddata_breaker.tripped</code> 数值太高，那么就需要优化了。</p>
<p>其他一些监控接口</p>
<ul>
<li><code>hot_threads</code> 状态 <code>curl -XGET &#39;http://127.0.0.1:9200/_nodes/_local/hot_threads?interval=60s&#39;</code></li>
<li>等待执行的任务列表 <code>curl -XGET http://127.0.0.1:9200/_cluster/pending_tasks{ &quot;tasks&quot;: [] }</code></li>
<li>可以用 <code>/_cat</code> 接口，具体参考文档<ul>
<li>集群状态 <code>curl -XGET http://127.0.0.1:9200/_cat/health?v</code></li>
<li>节点状态 <code>curl -XGET http://127.0.0.1:9200/_cat/nodes?v</code> </li>
</ul>
</li>
</ul>
<p>Elasticsearch 的日志在 <code>$ES_HOME/logs/</code> 中，或者可以使用 官方自己的监控工具 - marvel。如果在生产环境中，最好使用 nagios, zabbix, ganglia, collectd 这类监控系统。</p>
<h2 id="试一试"><a href="#试一试" class="headerlink" title="试一试"></a>试一试</h2><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;施工中：如题&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="通天塔" scheme="http://wdxtub.com/tags/%E9%80%9A%E5%A4%A9%E5%A1%94/"/>
    
      <category term="日志" scheme="http://wdxtub.com/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="平台" scheme="http://wdxtub.com/tags/%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="Elasticsearch" scheme="http://wdxtub.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>【通天塔之日志分析平台】柒 Kibana 技巧指南</title>
    <link href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-7/"/>
    <id>http://wdxtub.com/2016/11/19/babel-log-analysis-platform-7/</id>
    <published>2016-11-19T03:11:04.000Z</published>
    <updated>2016-11-21T14:27:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>施工中：如题</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><ul>
<li><a href="http://wdxtub.com/2016/11/19/babel-series-intro/">『通天塔』技术作品合集介绍</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-0/">零 系列简介与环境配置</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-1/">壹 ELK 环境搭建</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-2/">贰 Kafka 缓冲区</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-3/">叁 监控、安全、报警与通知</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-4/">肆 从单机到集群</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-5/">伍 Logstash 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-6/">陆 Elasticsearch 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-7/">柒 Kibana 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-8/">捌 实例：接入外部应用日志</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-9/">玖 业界：大厂实践</a></li>
</ul>
<h2 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h2><h2 id="老介绍"><a href="#老介绍" class="headerlink" title="老介绍"></a>老介绍</h2><p>Kibana3 和 Kibana4 基本还处于并行的状态（想到了 Python），这里主要介绍 Kibana4（因为主要在用这个版本）</p>
<p>任何需要展示的数据都需要现在 Settings 中进行索引配置，注意可以选择配置时间索引，这样在 Discover 页面会多出来时间的选项。默认情况下，Discover 页面会显示匹配搜索条件的前 500 个文档。Visualization 用来为搜索结果做可视化。每个可视化都是跟一个搜索关联着的。Dashboard 可以创建定值自己的仪表盘。</p>
<p>要应用到生产环境的话，具体对于 Nginx, shield 和 SSL 的配置请参考官方文档。使用 Shield 的话，可以做到索引级别的访问控制，这对多团队管理很有帮助。</p>
<h3 id="Discover"><a href="#Discover" class="headerlink" title="Discover"></a>Discover</h3><p>Discover 标签用于交互式探索数据。基本上常用的功能应有尽有，具体就要自己慢慢摸索。</p>
<ul>
<li>右上角的时间过滤器、中间的直方图都可以选择时间范围</li>
<li>搜索的时候可以使用 Lucene 查询语法，可以用完整的基于 JSON 的 Elasticsearch 查询 DSL</li>
<li>按字段过滤包含正反两种过滤器，尝试一下即可</li>
<li>JSON 中可以灵活应用 bool query 组合中各种 <code>should</code>, <code>must</code>, <code>must not</code> 条件</li>
<li>可以使用任何已建立索引的字段排序文档表哥中的数据。如果当前索引模式配置了时间字段，默认会使用该字段倒序排列文档</li>
</ul>
<h3 id="Visualize"><a href="#Visualize" class="headerlink" title="Visualize"></a>Visualize</h3><p>几个不同的大类</p>
<ul>
<li>Area chart: 用区块图来可视化多个不同序列的总体共享</li>
<li>Data table: 用数据表来显示聚合的原始数据。其他可视化可以通过点击底部的方式显示数据表</li>
<li>Line char: 用折线图来比较不同序列</li>
<li>Markdown widget: 用 Markdown 显示自定义格式的信息或和仪表盘有关的用法说明</li>
<li>Metric: 用指标在仪表盘上显示单个数字</li>
<li>Pie char: 用饼图来显示每个来源对总体的贡献</li>
<li>Tile map: 用瓦片地图将聚合结果和经纬度联系起来</li>
<li>Vertical bar chart: 用垂直条形图作为一个通用图形</li>
</ul>
<p>Y 轴的数值维度有以下聚合：</p>
<ul>
<li>Count 原始计数</li>
<li>Average 平均值</li>
<li>Sum 总和</li>
<li>Min 最小值</li>
<li>Max 最大值</li>
<li>Unique Count 不重复的值</li>
<li>Standard Deviation 标准差</li>
<li>Percentile 百分比</li>
<li>Percentile Rank 百分比排名</li>
</ul>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>Kibana 服务器在启动的时候会从 <code>kibana.yml</code> 文件读取属性。常见的属性有</p>
<ul>
<li><code>port</code></li>
<li><code>host</code></li>
<li><code>elasticsearch_url</code></li>
<li><code>kibana_index</code></li>
<li><code>default_app_id</code></li>
<li><code>request_timeout</code></li>
<li><code>shard_timeout</code></li>
<li><code>verify_ssl</code></li>
<li><code>ca</code></li>
<li><code>ssl_key_file</code></li>
<li><code>ssl_cert_file</code></li>
<li><code>pid_file</code></li>
</ul>
<h2 id="试一试"><a href="#试一试" class="headerlink" title="试一试"></a>试一试</h2><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;施工中：如题&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="通天塔" scheme="http://wdxtub.com/tags/%E9%80%9A%E5%A4%A9%E5%A1%94/"/>
    
      <category term="日志" scheme="http://wdxtub.com/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="平台" scheme="http://wdxtub.com/tags/%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="Kibana" scheme="http://wdxtub.com/tags/Kibana/"/>
    
  </entry>
  
  <entry>
    <title>【通天塔之日志分析平台】捌 实例：接入外部应用日志</title>
    <link href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-8/"/>
    <id>http://wdxtub.com/2016/11/19/babel-log-analysis-platform-8/</id>
    <published>2016-11-19T03:11:03.000Z</published>
    <updated>2016-11-20T15:34:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>施工中：简单的接口访问次数统计和 IP 统计</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><ul>
<li><a href="http://wdxtub.com/2016/11/19/babel-series-intro/">『通天塔』技术作品合集介绍</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-0/">零 系列简介与环境配置</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-1/">壹 ELK 环境搭建</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-2/">贰 Kafka 缓冲区</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-3/">叁 监控、安全、报警与通知</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-4/">肆 从单机到集群</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-5/">伍 Logstash 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-6/">陆 Elasticsearch 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-7/">柒 Kibana 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-8/">捌 实例：接入外部应用日志</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-9/">玖 业界：大厂实践</a></li>
</ul>
<h2 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h2><h2 id="试一试"><a href="#试一试" class="headerlink" title="试一试"></a>试一试</h2><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;施工中：简单的接口访问次数统计和 IP 统计&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="通天塔" scheme="http://wdxtub.com/tags/%E9%80%9A%E5%A4%A9%E5%A1%94/"/>
    
      <category term="日志" scheme="http://wdxtub.com/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="平台" scheme="http://wdxtub.com/tags/%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="实例" scheme="http://wdxtub.com/tags/%E5%AE%9E%E4%BE%8B/"/>
    
  </entry>
  
  <entry>
    <title>【通天塔之日志分析平台】玖 业界：大厂实践</title>
    <link href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-9/"/>
    <id>http://wdxtub.com/2016/11/19/babel-log-analysis-platform-9/</id>
    <published>2016-11-19T03:11:02.000Z</published>
    <updated>2016-11-20T15:34:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>施工中：看各个大厂是如何做这个事情的</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<h2 id="系列文章"><a href="#系列文章" class="headerlink" title="系列文章"></a>系列文章</h2><ul>
<li><a href="http://wdxtub.com/2016/11/19/babel-series-intro/">『通天塔』技术作品合集介绍</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-0/">零 系列简介与环境配置</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-1/">壹 ELK 环境搭建</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-2/">贰 Kafka 缓冲区</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-3/">叁 监控、安全、报警与通知</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-4/">肆 从单机到集群</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-5/">伍 Logstash 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-6/">陆 Elasticsearch 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-7/">柒 Kibana 技巧指南</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-8/">捌 实例：接入外部应用日志</a></li>
<li><a href="http://wdxtub.com/2016/11/19/babel-log-analysis-platform-9/">玖 业界：大厂实践</a></li>
</ul>
<h2 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h2><h2 id="试一试"><a href="#试一试" class="headerlink" title="试一试"></a>试一试</h2><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;施工中：看各个大厂是如何做这个事情的&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="通天塔" scheme="http://wdxtub.com/tags/%E9%80%9A%E5%A4%A9%E5%A1%94/"/>
    
      <category term="日志" scheme="http://wdxtub.com/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="平台" scheme="http://wdxtub.com/tags/%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="业界" scheme="http://wdxtub.com/tags/%E4%B8%9A%E7%95%8C/"/>
    
  </entry>
  
  <entry>
    <title>第二十三周 - 少年壮志不言愁</title>
    <link href="http://wdxtub.com/2016/11/18/youth-dream/"/>
    <id>http://wdxtub.com/2016/11/18/youth-dream/</id>
    <published>2016-11-18T11:20:51.000Z</published>
    <updated>2016-11-18T15:15:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>几度风雨几度春秋，风霜雪雨博激流。历尽苦难痴心不改，少年壮志不言愁。</p>
<a id="more"></a>
<hr>
<p>这周发生的事情有点多，多到我已经有点记不太清楚顺序。在回家的动车上写周记，就写到哪儿是哪儿吧。如果要一句话总结的话就是：我很满意，我已经使出了洪荒之力!!!</p>
<p>周一去看了传说中的『超级月亮』，虽然兴致勃勃带着新买的相机，但是发现镜头吃紧并没有办法拍出像样的月亮，于是『赏月』之旅变成了『自拍』练习。遗憾的是在暗光场景下我对相机的使用简直直逼『智障』，只能恬不知耻地说一句：技术不够颜值来凑。</p>
<p>周二迎来了公司篮球赛小组赛的最后一场，带着两战皆负提前出局的心态，我们部门的六个人迎来了最后一场的荣誉之战。大家没有看错，就是六个人的球队要打全场。前三节比分紧紧咬住甚至还略微有些领先，最后一节我们深陷犯规泥潭。早早领到第四次犯规的我（五次就罚下场）防守基本靠眼神和吼叫，最后一次快攻后我的得分定格在 12 分，最终我们以 19 比 23 败北。但是这已经是我们得分最多且失分最少的一场了，大家能一起在场上奔跑，本身就是很美好的事情，只是希望以后部门的活动大家都能参与进来，不能聚餐积极打球就当逃兵啊。</p>
<p>写到这儿忽然想起来周末沿着海边跑了 13 公里时候的感觉，不轻松但是特别畅快。生活中的很多感悟，其实都能在一次跑步中一次兑现。从一开始的斗志满满到临近极限的艰难再到突破自己的喜悦，不由得想，原地踏步的人看不到新的风景，眼里只有终点的人无暇欣赏一路的风景，只有方向坚定但是又不拘泥于此的人才能真正享受探索和发现的旅程。</p>
<p>前两天博客的访问量突破 20 万了，因为是在 10 万的时候才记下了日子，所以只知道第二个十万花了 74 天，希望第三个十万能少花几天（慢慢进步，我不贪心）。这个周末终于腾出了一点时间来打理一下博客，把几个系列都开了出来：</p>
<ul>
<li>小土刀玩摄影：用来记录我学习摄影的经历</li>
<li>小土刀的剪报本：用来取代之前的『一周读报』系列，收集我平时看到的比较有价值的信息</li>
</ul>
<p>周末应该会把最近构造日志系统的各种经验汇总成一个新的系列，把之前若干分散的文章整合成一个可操作易上手的系列，争取让读者看完这个系列之后也能快速搭建起这样一套集中化日志监控系统。</p>
<p>之所以想要把之前的技术文章系列化作品化，其实也是受机械工业出版社华章分社（学计算机的应该非常熟悉了）温姚二位老师的启发和影响。回想半年前因创作《读厚/读薄 CSAPP》系列结缘，到今天拿到还未上市的 CSAPP 第三版中文版，能和二位奋斗在计算机教育第一线的先锋聊聊人生聊聊理想，真的倍感荣幸，也确实的感受到，自己能为这片我深爱的土地和在这之上生活着的人们做些什么。期间聊到计算机基础教育的现状，不由得提到了母校中山大学。作为和 CMU 联合办学的第一批走向社会的学生，真的是非常幸运，赶上了『好时候』。曾经软件学院的李文军院长其实一直非常注重培养学生的软硬结合能力，尤其在 CMU 进行了深入学习之后，才更能够理解院长的一片苦心。可惜的是最近因为各种架构和人员的调整，风雨飘摇，原先计划的若干合作也不得不转为其他的形式。</p>
<p><img src="/images/14794821052176.jpg" alt=""></p>
<p>深入理解计算机系统（即 CSAPP）是一本非常值得每个计算机软硬件的同学学习的教材，二位老师和我都希望能尽自己的努力，想各种办法弥补暂时和国外一流大学师资上的差距，让更多想要迈入计算机学科大门的同学，能有一个更好的起跑。这里先偷偷剧透一下，之后可能会联合北大清华复旦大学的教授以在线公开课或者学习社区的形式来和大家一起学习 CSAPP，我也会以『助教』的角色陪大家一起成长。欢迎更多对此感兴趣的同学能够参与进来，毕竟少年强则国强嘛。</p>
<p>最后说说工作，近一个月来一直在开发的保密项目终于完成了核心系统的开发，一个人把产品经理项目经理架构师前端后端运维的事儿都做了个遍（后来有了小伙伴轻松了不少），算是强行把前端的基本技能给点亮了。临下班前跟二老板说了一下自己之后的想法，因为保密项目的开发接近尾声，后面会空出来一些时间，会继续把 UTM 和数据平台的事情做起来。不过对我来说最大的收获反而算是第一次真正跟二老板沟通自己的想法，让老大知道自己在做什么，还是很重要滴。</p>
<p>在一个飞速发展的公司，能够参与到最前沿的工作，这种没有任何攻略的挑战，其实是非常刺激的。我可能不是一个愿意在轨道上安安稳稳前进的人，我不想要有这样一条轨道，我想要尝试各种可能。在老板眼皮底下干活，逼着自己完成工作的同时，眼界要更宽，思维要更严密。虽然谈不上轻松，但是被逼迫着快速成长，也是很有意思的经历。再说了，我也相信自己一定能搞定。</p>
<p>峥嵘岁月，何惧风流，危难之处显身手。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;几度风雨几度春秋，风霜雪雨博激流。历尽苦难痴心不改，少年壮志不言愁。&lt;/p&gt;
    
    </summary>
    
      <category term="Gossip" scheme="http://wdxtub.com/categories/Gossip/"/>
    
    
      <category term="工作" scheme="http://wdxtub.com/tags/%E5%B7%A5%E4%BD%9C/"/>
    
      <category term="周记" scheme="http://wdxtub.com/tags/%E5%91%A8%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>【小土刀的剪报本】缘起</title>
    <link href="http://wdxtub.com/2016/11/18/information-clippings-overview/"/>
    <id>http://wdxtub.com/2016/11/18/information-clippings-overview/</id>
    <published>2016-11-18T00:33:25.000Z</published>
    <updated>2016-11-17T23:15:33.000Z</updated>
    
    <content type="html"><![CDATA[<p>当我迷茫且不知所措的时候，回想起小时候的自己，才发现原来答案其实早就在那里。小时候剪报用剪刀胶水本子，现在剪报则是用 Kindle、键盘和电脑，但其实核心一点没变。</p>
<a id="more"></a>
<hr>
<p>几个月之前我做了一次尝试，想每周做一次总结，把七天的阅读梳理一次并加上自己的思考，以在线杂志的形式分享给大家。当时起的名字现在都不太满意，叫做《一周读报》，后来因为做不到每周更新，改成了《几周读报》，可是最终难逃<a href="http://wdxtub.com/2016/06/19/weekly-reading-report-1/">《第一期-创刊号》</a>就是最后一期的悲惨命运。</p>
<p>第一期出来之后，大家普遍反应太零散，看看就过了。因为一直没有找到合适的改版方式，所以就这么搁置了下来。昨天忽然想到了可以以从前我喜欢的『剪报』的形式来展现这些内容，于是决定整个系列推倒重来，并改名为『小土刀的剪报本』。</p>
<p>为了解决内容混杂不方便积累和查看的问题，我会把不同的内容进行分类，放到不同的分册中（也就是不同的日志中），这样在同一个分册中的内容都会属于同一个领域，也更能看出整体的变化。现在的分类有：</p>
<ul>
<li><a href="http://wdxtub.com/2016/11/18/information-clippings-tech/">技术分册</a></li>
<li><a href="http://wdxtub.com/2016/11/18/information-clippings-society/">社会分册</a></li>
<li><a href="http://wdxtub.com/2016/11/18/information-clippings-perspective/">视角分册</a></li>
</ul>
<p>介绍完了系列本身，就来说说我和剪报的故事吧。</p>
<p>小时候家里主要订的报纸是《羊城晚报》和《广州日报》，后来取消了前者，大约是因为后者有一个很有趣的版面，叫做『每日闲情』，是我们全家都爱看的。里面的内容现在看来就和各种泛娱乐阅读应用差不多，有笑话鸡汤故事讽刺警句。光看不过瘾，后来就开始把喜欢的内容剪下来，根据不同的大小组合一下粘到本子上，就成了最初的剪报本。</p>
<p>剪报其实是一个很有意思的过程，虽然看起来比较花时间，但整个过程中得到的快乐，尤其是和爸爸妈妈一起剪剪贴贴的经历，现在想起来都觉得很开心。</p>
<p>随着时间的增长，剪报本也越来越多越来越大。但除了偶尔翻一翻，剪报本逐渐成了一种回忆的仪式。后来到了高中，我课业忙起来之后，再也没有那么多闲情逸致的时间，剪报这个活动便停了下来。</p>
<p>『小土刀的剪报本』系列，算是以数字化形式重新回归自己的初心，尤其在这个信息化时代，如何把信息收集好利用好，才是最重要的。</p>
<p>希望这个系列能坚持下去！</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;当我迷茫且不知所措的时候，回想起小时候的自己，才发现原来答案其实早就在那里。小时候剪报用剪刀胶水本子，现在剪报则是用 Kindle、键盘和电脑，但其实核心一点没变。&lt;/p&gt;
    
    </summary>
    
      <category term="Reading" scheme="http://wdxtub.com/categories/Reading/"/>
    
    
      <category term="剪报" scheme="http://wdxtub.com/tags/%E5%89%AA%E6%8A%A5/"/>
    
      <category term="收集" scheme="http://wdxtub.com/tags/%E6%94%B6%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>【小土刀的剪报本】视角分册</title>
    <link href="http://wdxtub.com/2016/11/18/information-clippings-perspective/"/>
    <id>http://wdxtub.com/2016/11/18/information-clippings-perspective/</id>
    <published>2016-11-17T22:34:12.000Z</published>
    <updated>2016-11-17T23:26:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>这里是【小土刀的剪报本】的视角分册，主要是开拓视野与思维方式文章的节选和点评。</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<ul>
<li>2016.11.18: 第一次更新</li>
</ul>
<h2 id="格局"><a href="#格局" class="headerlink" title="格局"></a>格局</h2><blockquote>
<p>社会在变化，但是有一个不变的本质，就是差异和秩序。为什么在最自由的社会里财富的分布都是幂律的，因为这是一种有效的分配社会财富的方法，能够产生最高的效率。其实如果给信息一个质量评级，画出来的也一定是个幂律函数，最优的信息一定质量稀少，而正常人大部分时间接触到的都是超高量的垃圾信息。</p>
<p>第一，向上走，因为表层wikipedia的那些信息，说到头是人人都可以获取的，而你要能够上升到一个领域掌门人在的圈子里，才能获取真正的信息。名校，还是好的工作团队，无他，都是为这点。即使是辍学创业，也最好是从斯坦福辍。</p>
<p>第二，不要相信凭借自学你可以拥有一且，凭借情怀你可以拥有一切。 你这样觉得的时候都是因为你离它不够近或根本没做。</p>
<p>第三，苦练沟通技巧，沟通也是要练的，就像开头说的，无论你是要追到Lucy还是获取核心信息，沟通都是硬功。</p>
<p>第四，你做了一个选择正确与否，往往看你能够接触到的人和信息的变化，如果你的视野变开阔了，你接触到了一些之前无法发掘的对你重要的信息，通常是一个不错的兆头，反之，你要反思和即时调整。记住，在low的环境里努力再聪明的人都不能保证不low，无它，信息也。</p>
<p>第五，地点决定论，你选择全球一线大都市不是因为工资高，而是能接触的人还有信息，信息，信息。就像纸牌屋里的Frank说的：Everything is about location, location,location. The closer you are to the source, the higher your property value 五道口宇宙中心不是吹的。</p>
<p>第六，不遗余力的挖掘身边的信息不对称性，你所在的地点，还有哪些核心信息你没有接触到，你可以挖掘，不要考虑他们此时此刻的作用，而是想想它们在另一个时空里可能产生的价值。</p>
<p>第七，也是最重要的，做好自己的事，静下心来把自己的事情做到出类拔萃。 真正的高手不会随便和你交换重要的信息，除非你的出类拔萃被他欣赏，这就如同某种社交货币 - 你以一个领域的顶级信息换取另一个领域的顶级信息。</p>
<p>来自《信息格局论》</p>
</blockquote>
<p>这篇文章说得很好，我没有什么补充的，在生活中践行这七点吧。</p>
<blockquote>
<p>我一向坚持的观点是，所谓的「信息过载」「信息过剩」都是伪概念，如同过去流行过的「信息爆炸」一样，都是不能接受新变化的人给自己的安慰剂，他们不但这样在心里安慰自己，还试图想去说服别人。 人们不知道自己接受信息的能力有多强，而总用过去的眼光去评估自己，从而他们得到的结论就是：信息太多了，有点接受不了。很多年轻人这样说，一些年长者甚至也这样说。 但是，自从人类进入互联网时代，每一个网络接入者，获取到的信息量都出现了前所未有的剧增。这是一次不折不扣的信息革命，所有人都在不知不觉的获益，是这一代人的红利，然而却有人不断的拒绝。</p>
<p>类似的另一种人是看书只看英文版，说翻译版不是原汁原味。说实话，过去我也觉得这样有道理，但很快发现，如果不是文学作品，对于我们这个行业，一本专业技术类的图书翻译的好与坏没那么重要，对付能快速看完，吸收书中的有价值的部分就足够了。没必要去看所谓的英文版，除非你阅读中文速度不如阅读英文快。阅读原版并不意味着你的思维更高级，也不意味着你获取到更多信息。</p>
<p>来自《关于「阅读」和「信息获取」的错误认知》</p>
</blockquote>
<p>看得多了了解得多了就会发现其实太阳底下新鲜事是不多的，所以不用太担心错过看起来很重要的『信息』，反正有价值的东西，总是会被翻来覆去说的</p>
<h2 id="互联网"><a href="#互联网" class="headerlink" title="互联网"></a>互联网</h2><blockquote>
<p>有人问我，中国互联网公司最突出、最强大的能力是什么？我的回答是：运营能力。或者说，中国人对互联网最杰出最具创造性的汉化，就是为互联网添加了强大的中国式运营能力。</p>
<p>中华文化最讲究含蓄，空灵，留白，若有若无，意境深远，怎么到了互联网时代，变得这么密集、迫切、露骨、不容喘息？反倒是美国那些网站，好像传承了更多中华神韵，比如Google的极简首页。</p>
<p>有时候，我怀疑我们的文化中或许存在某种推崇低智甚至反智的传统，这种传统以讥讽、诋毁知识和智力为乐，这种传统将某种自以为是的小聪明当成智慧，这种传统崇尚以低智的方式解决问题，即使在高智商的人群中，所以那些低智甚至反智的传言总能得到广泛传播。</p>
<p>微信对秩序、纯净、可控的偏执，近乎走火入魔。我觉得，这还是一种「汉化」。</p>
<p>来自《「汉化」互联网》</p>
</blockquote>
<p>其实我是蛮支持在一定阶段内利用威权主义建立基本的底线的，哪怕有些矫枉过正都没有问题。不然那么多人连烟都戒不了，真的能够指望通过温和的方式让大家改变？</p>
<blockquote>
<p>知乎上其实牛人还是很多，有些内容也是让人印象深刻，如果我说知乎上没有好的知识，没有出色的人，这是不公平的，也是不客观的，但是必须实事求是的说，不论是知乎，或者其他任何知识社区，都会存在一个先天性问题，就是，曲高和寡，高质量的内容往往不受待见，而迎合大众口味的才是容易脱颖而出的，在这个前提下，你可以想象，知乎的点赞机制真正鼓励的，依然是媚俗，而不是内容价值。 我通过知乎还是认识了不少牛人，但这些人大部分都是只有几百个赞，放在那里几乎无人问津的。 而某些大V的基本知识水准，其实只能用呵呵来形容了。 简单一句就是，从我熟悉的几个领域来看，知乎上有价值的答案，非常稀缺，而很多高票答案，虽然观点符合大众口味，但纯属胡扯。</p>
<p>人们总是倾向于为自己一些很low的欲望或者行为标注一个高大上的标签，实现心理自我安慰。这是我们每个人可能都避免不了的一种自我欺骗，自我麻醉，而成功的市场行为，则完美的诠释了这样的心理诉求。 这就是今天跟读者们分享的观点，也是值得学习的地方。 </p>
<p>他们都是很好很好的啊，然而我并不喜欢。</p>
<p>来自《以知识分享为幌子》</p>
</blockquote>
<p>在我看来，以目前的民智程度，广泛分享知识是一个伪命题，要多努力才能让别人接受那些本来他们都不想要的东西呢？即使很努力很努力成功了，又有什么意义呢？所以对待知识分享的态度，我从来都是姜太公钓鱼，只有愿者，上钩才有意义。</p>
<blockquote>
<p>互联网教育缺乏强制性。教育是无法完全摆脱强制性的，如果老师布置的作业学生有权不做，教育的效果当然无法保证。但是互联网的“请求-响应”模型天然缺乏强制性色彩：你没有打开浏览器访问对应的网页，对方服务器是不能强制你浏览的。不过好在，这只是PC互联网时代的问题，移动互联网时代，App已经大幅度提升了对用户的触达，这对教育的效果是一个重要保障。</p>
<p>互联网教育的交互性比较弱。根据历史积累的经验我们知道，完整的学习离不开“教、学、练、测”四个环节。各个环节都需要教育者和学习者之间的密集互动——老师单纯讲解、学生死读书、练习没批改、不做测试了解自己的进步，学习的效果都要大打折扣。在传统教育中，老师和学生的密集互动贯穿在这四个环节。但是在互联网的形式下，师生之间交流的形式还非常简陋。比如“老师随堂出一道题，2分钟后收作业看大家结果”这种传统教育中常见的交互，在互联网上并没有很好的实现方式。</p>
<p>互联网教育往往只能利用碎片时间。传统教育往往要求专门集中精力一段时间才有收效，但是在互联网尤其是移动互联网时代，人类已经习惯了碎片化的行为方式。以前上一节课40分钟，但其内容未必需要连续的40分钟才能完成，比如单词、句子的学习，完全可以打散到上下电梯、乘坐地铁的时间中进行。但不是所有知识都适应碎片化学习的，集中学习和碎片化学习的判断标准是什么，现在并不清楚，很多人并没有考虑过这个问题。</p>
</blockquote>
<p>人真的是挺贱的动物，一边说要自由，很多事情不强制又做不好，感觉老师和学生的观念根深蒂固得换个说法什么的会好点。 </p>
<h2 id="时代趋势"><a href="#时代趋势" class="headerlink" title="时代趋势"></a>时代趋势</h2><blockquote>
<p>春节是中国人口流动最广泛的时间，大量的务工，在大城市工作的人回老家，和亲人团聚，那么，也就是口碑传播效果最好的时刻。 春节是一线城市的热门互联网应用向二三线城市普及的时刻。 春节也是很多人购买新手机，采购新电脑，第一次接触互联网，了解新事物的时刻！特别是从城市回来的人，会给家乡的亲戚朋友，父母，带来这样的一些产品，并教会他们上网，教会他们用智能手机。 春节后，又是一次新的人群融合的机会，很多人在春节后去新的城市，寻找新的机会，以及认识新的伙伴，口碑效应继续发酵。</p>
<p>在春节期间，就会产生一个替代效应。一群人在一起谈论一些互联网产品，或者在一起玩游戏或者刷资讯的时候，他们就会产生一些趋同效应，好口碑的产品就会替代坏口碑的产品。 所以，如果你的产品在春节具有好的口碑，好的传播效应，即便你的产品特性并不符合春节期间的用户上网习惯，但是，你春节后依然会看到数据的一个爆发。</p>
<p>如果你的产品经过一个春节没有增长，甚至下跌，说明用户在抛弃你，你的产品属于被替代的那一类。</p>
<p>总结一下<br>1、春节意味着大量的人口流动，意味着口碑宣传最佳时机。<br>2、春节意味着一线城市的应用，热点产品开始向二三线城市及乡村普及。<br>3、春节存在趋同效应和替代效应，一些好口碑产品会通过春节蚕食竞争产品市场。<br>4、春节期间大量人开始拥有新的上网终端，开始学习上网。<br>5、春节后存在大量的人口流动和各种新的社会关系组合，存在口碑发酵的进一步空间。<br>6、春节营销做到位，全年增长不用愁。</p>
<p>来自《一年之计在于春》</p>
</blockquote>
<p>这篇文章非常有意思！之前不怎么会根据『国情』思考，经过这么一点拨，好像开启了新的大门，很多时候技术人员思考问题往往局限于技术，没有在更大的角度上结合更多不同的方面来思考问题，这是我以后需要注意的</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这里是【小土刀的剪报本】的视角分册，主要是开拓视野与思维方式文章的节选和点评。&lt;/p&gt;
    
    </summary>
    
      <category term="Reading" scheme="http://wdxtub.com/categories/Reading/"/>
    
    
      <category term="收集" scheme="http://wdxtub.com/tags/%E6%94%B6%E9%9B%86/"/>
    
      <category term="视角" scheme="http://wdxtub.com/tags/%E8%A7%86%E8%A7%92/"/>
    
  </entry>
  
  <entry>
    <title>【小土刀的剪报本】社会分册</title>
    <link href="http://wdxtub.com/2016/11/18/information-clippings-society/"/>
    <id>http://wdxtub.com/2016/11/18/information-clippings-society/</id>
    <published>2016-11-17T22:33:37.000Z</published>
    <updated>2016-11-17T23:22:44.000Z</updated>
    
    <content type="html"><![CDATA[<p>这里是【小土刀的剪报本】的社会分册，主要是描写社会百态文章的节选和点评。</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<ul>
<li>2016.11.18: 第一次更新</li>
</ul>
<h2 id="为人处世"><a href="#为人处世" class="headerlink" title="为人处世"></a>为人处世</h2><blockquote>
<p>如果是个初出茅庐、没什么社会阅历的年轻人，指路型朋友适合他；如果是想合伙做一番事业的，默契型朋友肯定是他首选；如果是想找个分担痛苦失意的人或有强烈表达欲望的人，他们需要倾听型朋友；如果是个价值观已经成熟、事业稳定的人，则会选择互助型朋友。这跟年龄和经历有关。 我现在更倾向互助型朋友，在互助中彼此切磋找到方向，我觉得自己身边这种类型的朋友是最多的。20 多岁，指路型朋友很重要，四、五十岁时互助型朋友更多。在我工作与生活中，与不同年龄层次的人打交道都很多，但互助型朋友变得更多些。在一块讨论，一块做事，共同寻找一些解决方式，也不存在谁给谁指路，也不存在心心相印那么重要。</p>
<p>我们这个圈子的规则：第一，要真诚，要坦率，要赤裸裸。 你不能装，你在这个小范围内再装，那更不是玩意儿！你说人多没办法，你不装一下会影响别人情绪，你装一下可以，但如果就三、五个人你还装，那纯粹是侮辱别人的智商；第二，是不要有功利目的，无所求是最高境界；还有一个游戏规则，就是要谦虚。 水为什么越积越多，因为地势低，低的东西才能吸纳更多资本，在朋友圈子里也一样。你不够谦虚，你总是希望教导别人，加上你再装，基本上很快就被人踢出去了。 所以说，这样小范围地交朋友，真实、谦虚、没有功利色彩，大家都会舒服。坦诚、守规矩、尊重别人、谦虚是很多成功人的共同特点，包括柳传志，包括王石。有些人偶然成功，但他不够尊重人，不够坦诚，不够谦虚，可能对于我们小人物，被玩弄一下也就认了，如果用这种态度待朋友、政府、合作伙伴、大事，恰好是导致他失败的原因。所以我们叫作“谦逊就是遗训”，一定要注意谦虚！</p>
<p>来自《冯仑：上流圈子的交友之道》</p>
</blockquote>
<p>说得足够清楚了，关键还是做大写的人，走正道，永远谦虚。</p>
<blockquote>
<p>“公众知名度会对政治晋升有一定的帮助”，这一点并不出人意料。毕竟，提拔民众熟悉和喜爱的官员，会提升执政集团的形象和公众认可程度。但是，为什么过高的公众知名度反而可能成为一名官员继续晋升的负担呢？ 这其中的关键在于，良好的公众知名度很大程度上可以体现为官员的大规模动员能力，而这种动员能力很可能成为给体制的平稳运行带来潜在威胁。这种威胁具体体现在两方面。</p>
<p>一方面，广为人知的官员可能对同僚产生威胁，使同僚产生 “自身利益可能受到侵蚀” 的担忧，这种担忧往往会转化为对高支持率官员晋升的阻碍。 而更为重要的一方面是，公众知名度过高的官员可能会对整个执政体制的统一性和完整性造成损害，特别是他们利用自身的动员能力对体制内部的分歧进行公开质疑的时候。纵观历史，这种备受公众欢迎的 “魅力型” 领袖利用其影响力导致执政者分裂的例子也并不少见。因此，出于维护政权平稳的角度考虑，过于受到关注的官员也可能不被提拔。</p>
<p>来自《“闷声发大财”：东方国家的升官之道 | 政见 CNPolitics》</p>
</blockquote>
<p>政治真的是非常让人头疼的问题，但是有人的地方就有江湖，无论是在课室还是在办公室，不了解些基本的道理，是要吃亏的啊。</p>
<h2 id="策略选择"><a href="#策略选择" class="headerlink" title="策略选择"></a>策略选择</h2><blockquote>
<p>避免策略性填报志愿给考生和大学带来的双输风险，Lloyd S. Shapley和Alvin E. Roth有好办法。这个办法为他们带来了诺贝尔经济学奖。 第一步，考生填报志愿时，将心仪的大学按顺序列表，类似于过往的第一志愿、第二志愿、第三志愿，不同之处是现在这个列表越长越好，至少要有十几家大学，理论上，如果有这个精力，把所有大学都排出序来也行，虽然没必要做得这么绝。 考生需要做的就这一件事，接下来的事交给延迟接受算法。 第二步，每家大学按其招生人数计划向看中的考生发出对应数量的录取通知。优秀考生获得很多通知怎么办？算法为考生自动接受在他的优先列表上排在最前面的大学，并拒掉其他大学。注意，这里是关键，接受是暂时的（tentative），并未最终生效，这也是算法之所以得名“延迟接受”的原因。 第三步，必然有一些大学发出的部分录取通知被考生拒掉，于是，这些大学向不在其第一轮通知名单上的其他考生，发出新一轮录取通知，数量等同于被拒的录取通知数。如果这些考生收到了不止一个通知，已“暂时接受”其他大学的录取通知，则系统再度自动“暂时接受”在其列表上靠前的大学录取通知，拒掉其他。</p>
<p>自由市场概念，与物理学中无外力作用则匀速运动中的物体永远保持匀速运动的概念类似，而现实中多是匹配市场（matching market），即双向选择、并非完全由价格决定而有时完全不由价格决定的市场。这种市场比比皆是：大学招生，宿舍分配，器官分配。Roth的研究，揭示如何激发参与者如实披露其偏好信息，增加市场厚度（thick），减少拥塞（congestion），使市场安全、简便。这些不是象牙塔学问，确能济世。</p>
<p>来自《一个算法解决高考填报志愿难题｜BetterRead》</p>
</blockquote>
<p>看完这个算法的介绍，感觉非常有趣，通过策略来减少人们选择的恐惧以达到资源的最佳配置，初衷看起来挺好的，但是问题在于，很多时候我们对目前的选择不过是基于不完全的信息做出的，理论上最合理的甚至是自己选择的都不一定是最适合自己的。这样的例子一出，恐怕学生们走入社会会更加不习惯，毕竟很多时候我们心中默认的模式就是零和博弈。</p>
<h2 id="他山之石"><a href="#他山之石" class="headerlink" title="他山之石"></a>他山之石</h2><blockquote>
<p>1975 年 6 月 25 日，在总理英迪拉•甘地的要求下，印度总统法赫鲁丁•阿里•艾哈迈德（Fakhruddin Ali Ahmed）宣布全国进入 “紧急状态”（Emergency）。印度共和国翻开了它 “民主历史上最黑暗的一页”。 对印度人来说，紧急状态的 21 个月，在共和国历史上留下了一个黑洞。它饱含了深不见底的恐怖，让人不忍直视、不愿提起、不想再现。在这 21 个月里，中央政府扩展控制，警察权力膨胀，新闻自由遭到打压，反对党领袖被逮捕入狱，大城市的贫民窟遭到强力清除，上百万男人被送入生育控制营——实施输精管切除绝育术。</p>
<p>基本史实是：1970 年到 1975 年间，印度的经济状况、就业问题和通货膨胀，在古吉拉特（Gujarat）和比哈尔 （Bihar）邦引发了一连串的抗议活动，学生、中产、中上层农民都卷入到了抗议中。与此同时，总理英迪拉•甘地挟第三次印巴战争（1971）胜利后民望高企之势，尝试把自己的社会主义路线大加推广：银行国有化、控制资本和外汇、提高国有企业比例。为了实现这一目标，英迪拉甚至不惜将建国以来一直执政的国大党分裂成左右两派，把对手（辛迪加派、右派）从党内驱逐出去。 1974 年，社会活动家斋普拉卡什•纳拉扬（Jayaprakash Narayan，简称JP）在比哈尔升级社运，矛头直指英迪拉政府。借助阿拉哈巴德（Allahabad）高等法院给出的英迪拉选举违规判决，反对力量希望一举夺权。 而英迪拉没有坐以待毙，随即宣布国家进入 “紧急状态”，驱散运动、巩固权力、修改法律，以避免政治危机。与此同时，以高度集权为依托的社会改造（“二十点计划”——包括土地改革，妇女平权， 生育控制等等），也在全国范围内得以推行。 直到 1977 年 3 月，甘地夫人举行大选，本以为胜券在握，但却以失利告终。政府更迭，紧急状态宣告结束，英迪拉也随之下狱。紧急状态的一页，就此在印度历史上翻过。</p>
<p>来自《人们对政治悲剧的记忆靠谱吗？| 政见CNPolitics》</p>
</blockquote>
<p>不走弯路大概是不可能的，不同国家和地区的情况都不一样，发展的阶段不同其实没有太多可比性，我能理解大家迫切的心情，但是最好的方法就是把自己的工作完成好，而不是在网上撒泼。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这里是【小土刀的剪报本】的社会分册，主要是描写社会百态文章的节选和点评。&lt;/p&gt;
    
    </summary>
    
      <category term="Reading" scheme="http://wdxtub.com/categories/Reading/"/>
    
    
      <category term="收集" scheme="http://wdxtub.com/tags/%E6%94%B6%E9%9B%86/"/>
    
      <category term="社会" scheme="http://wdxtub.com/tags/%E7%A4%BE%E4%BC%9A/"/>
    
  </entry>
  
  <entry>
    <title>【小土刀的剪报本】技术分册</title>
    <link href="http://wdxtub.com/2016/11/18/information-clippings-tech/"/>
    <id>http://wdxtub.com/2016/11/18/information-clippings-tech/</id>
    <published>2016-11-17T22:33:31.000Z</published>
    <updated>2016-11-18T00:58:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>这里是【小土刀的剪报本】的技术分册，主要是各类技术文章的节选和点评。</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<ul>
<li>2016.11.18: 第一次更新</li>
</ul>
<h2 id="高屋建瓴"><a href="#高屋建瓴" class="headerlink" title="高屋建瓴"></a>高屋建瓴</h2><blockquote>
<p>今天中国有一次机会，今天可能世界上第一台计算机不是发明在中国，今天可能最好的CPU也不是在中国，但是中国有可能变成世界上第一个国家，能够真正把计算变成一个公共服务，它对于将来二十年、三十年中国及世界的影响是巨大的。</p>
<p>好时代的三个宝贝：互联网、数据、计算</p>
<p>为什么要感谢互联网，大家千万不要在互联网前面加一个字，不要再互联网后面加一个字，不要有人在前面加一个移动互联网，互联网还是互联网，互联网对我们的影响太大了，大到一百年以后，大家还离不开它，还会受它的影响，这是我讲的第一个感谢，因为今天有互联网，它变成了基础设施。 第二件事情，大家要感谢因为互联网出来，有一个东西出来，叫做数据，数据是人类在发现土地、石油以后的另一类巨大的资源，这个资源的发现可以跟人类第一次利用好土地，人类第一次利用好事有，人类第一次知道怎么使用煤相提并论，人类完完全全用了一个新的资源，而这个资源是人本身创造的，不是上帝赐给我们的。 第三个，人类从此从计算机时代走进了计算时代，这个话怎么讲，你要想用计算的好处，再也不用抱着一台计算机回去了，今天一个学生，哪怕你不在实验室，不会因为实验室的老师给你多一百台机器而多干一点，你只是因为是学生而没有资源了，计算给你巨大的可能性让你去发挥创造才能。</p>
<p>来自《中国，是时候为世界技术做出贡献了》</p>
</blockquote>
<p>这也是我的态度，所以我想要做开放的云计算课程，因为技术的竞赛实际上就是人才的竞赛，我们需要更多的人，来冲上这一次时代改变的浪。</p>
<h2 id="团队建设"><a href="#团队建设" class="headerlink" title="团队建设"></a>团队建设</h2><blockquote>
<p>对于技术团队来说，“管理”当然必不可少，但“领导”显然更加重要。对优秀的技术团队来说，虽然它解决的不是重复的问题，但工作效率一定是越来越高的，不可能也不应该原地踏步，做到这一点离不开个人和团队的成长。</p>
<p>个人对于技术有不同的习惯和看法，这很正常。但是如果大家在一个团队内工作，这个团队就必须有共同的工作习惯、方式、价值观，身为技术领导，必须有能力、有动力去及时解决这些问题，保证团队从代码规范到架构设计等等问题都有明确决策，帮助大家树立共识并督促执行，同时化解个体的反感——这份工作很不好做，但不得不做。</p>
<p>来自《“技术领导”不等于“技术管理”》</p>
</blockquote>
<p>团队的风格建设其实非常重要，正如文中所说的那样，一致且清晰的观念是非常强的上下文，能够极大降低沟通与合作成本。另外就是如何在死的制度和活的人之间找到平衡，很不简单。</p>
<h2 id="个人发展"><a href="#个人发展" class="headerlink" title="个人发展"></a>个人发展</h2><blockquote>
<p>所谓“行业”，通常是就公司而言的，指的是公司业务所在的领域。比如“运输”、“零售”、“电商”等等。 所谓“职业”，通常是就个人而言的，指的是个人所从事的具体工作。比如“货车司机”、“营业员”、“平面设计”等等。</p>
<p>通常我们说的“向专家学习”，其实是没有明确方向的，因为专家既有行业专家，也有职业专家。假设你在一家在线商店做程序开发，那么你的行业是电子商务，职业是程序员。选择行业作为发展方向，就应当侧重了解以下问题：电商的应用有哪些特点，在系统的选型和使用上有哪些讲究，哪些问题适合使用什么框架和中间件解决…… 选择职业作为发展方向，就需要侧重了解以下问题：现有的编程语言和框架有什么功能，什么特性，系统有哪些技术指标各表示什么意思，系统大概会出什么问题应当怎么解决…… 注意上面我说的是“侧重”，极度“偏科”的组合是没有市场的。</p>
<p>在这种情况下，行业知识的价值更高也就不难理解了。如果有两个程序员，甲的职业技能更强，用一个月时间把仓储管理系统的响应速度提高了100%，乙的行业知识更多，用一个月时间把仓储管理系统的准确率提高了40%，出货速度提高了20%。对如今电商行业的大多数公司来说，谁的价值更高，恐怕是不言而喻的。</p>
<p>来自《“职业程序员”不必那么“职业”》</p>
</blockquote>
<p>这篇文章的思路非常有意思，给我很大的启发，行业和职业之分，确实是值得提前考虑的问题，毕竟『两手都要抓，两手都要硬』，很多时候技术的改进再大，远不如对业务深入了解之后所做出的调整。总体来说，关键是做事情，要挑最有效率的方式来把事情做好。</p>
<blockquote>
<p>实力型的活动中，刻意的训练能很有效地提高实力。 在运气型的活动中，我们要记得短期内实力的作用不大，实力再高也不会有立竿见影的反馈。</p>
<p>如果事情充满变数，就关注过程，尽量减少人为的失误 用少量的赌注预防意外的发生，或者投资更高风险的活动。 运气左右的活动，应该避免最优化的策略，因为最优化的策略，灵活性是最低的</p>
<p>当你在竞争中处于优势，你要简化比赛，以压倒性优势战胜对手。 当你在竞争中处于弱势，你要制造各种意外或开辟新的战场，将比赛复杂化。</p>
<p>来自《一个商业院教授给出提高运气或实力的科学建议》</p>
</blockquote>
<p>这些有意思的结论其实都可以从概率中这样那样推导出来，或者哪怕是英雄联盟联赛中不同队伍的策略也能看出一二，这也是为什么人人都需要重新学一下概率，尤其是理论结合实际的概率。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这里是【小土刀的剪报本】的技术分册，主要是各类技术文章的节选和点评。&lt;/p&gt;
    
    </summary>
    
      <category term="Reading" scheme="http://wdxtub.com/categories/Reading/"/>
    
    
      <category term="技术" scheme="http://wdxtub.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="收集" scheme="http://wdxtub.com/tags/%E6%94%B6%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>【度心术全解】读书笔记</title>
    <link href="http://wdxtub.com/2016/11/17/read-heart-clip/"/>
    <id>http://wdxtub.com/2016/11/17/read-heart-clip/</id>
    <published>2016-11-17T13:18:02.000Z</published>
    <updated>2016-11-17T13:57:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>在一读书公众号的推荐下陆陆续续看完了这本『奇书』，里面的套路不难，但怎么灵活掌握，就需要时间了。当然，还是少一点套路，多一些真诚</p>
<a id="more"></a>
<hr>
<h2 id="度心第一"><a href="#度心第一" class="headerlink" title="度心第一"></a>度心第一</h2><ul>
<li>揣摩第一，行为第二。</li>
<li>过分信任与一味姑息从来都是弊大利小的下策。</li>
<li>制约下属的权力，是避免他们滥用权力而违法的诀窍。</li>
<li>当谋划攻心得不偿失，强硬手段便立刻生效。</li>
<li>对能干的部属只要不吝啬褒奖，他便有知遇之感，便能卖命。</li>
<li>小人曲欲望，永远是伤人的利器。</li>
</ul>
<blockquote>
<p>仁者，鲜也，却之弗厚焉。</p>
</blockquote>
<p>品德高尚的人，是很少的，治理官吏不能宽厚。</p>
<blockquote>
<p>志大不朝，欲寡眷野。</p>
</blockquote>
<p>志向大的人不会入朝为官，欲望少的会留恋民间。</p>
<p>缺乏对官吏的本质认识，就难免活吏乏术。在封建官场的特定环境下，正人君子是难有作为的，一般人也抗拒不了钱权的诱惑，这就决定了为官者的价值取向和君子所求势必格格不入，是以真君子自不愿舍弃操守而混迹其中了。由此观之，官场中人不管唱何高调、做何辩解，他们的志向终是有限的，他们的欲望终是不衰的，这也是他们的共同弱点。</p>
<blockquote>
<p>才高不羁，德薄善诈。</p>
</blockquote>
<p>才能突出的人不受拘束，品德低下的人善于欺诈。</p>
<blockquote>
<p>民之所畏，吏无惧矣。 </p>
</blockquote>
<p>百姓不敢做的事，官吏不会惧怕。</p>
<blockquote>
<p>狡吏恃智，其勇必缺，迫之可也。</p>
</blockquote>
<p>狡猾的官吏倚仗他的智慧，他的勇气一定是缺乏的，强迫他可以将他制住。</p>
<blockquote>
<p>悍吏少谋，其行多疏，挟之可也。</p>
</blockquote>
<p>凶狠的官吏往往智谋不足，他的行为多有疏忽之处，挟制他可以令他屈服。</p>
<p>嚣张难制的官吏，看似不好驾驭，其实这正是他们拙于心计的表现。没有了智谋，他的短处自然会过多地暴露出来，当权者只要抓住这些把柄来挟制他，这些人却足最易收服。任何官吏都有他的短处，如何利用他们的短处为己所用，这也正是封建官场的腐朽所在：在不损当权者私利的前提下，官吏即使干了再多的坏事，只要对主子表示归顺，他们就未必会得到应有的惩罚。</p>
<blockquote>
<p>廉吏固傲，其心系名，誉之可也。</p>
</blockquote>
<p>正直的官吏会很孤傲，他的身心为名声所累，赞誉他就可以役使他。</p>
<p>有正义感的官吏，由于他们不贪不占、心存仁义，在封建官场中显得十分另类。他们以圣贤为榜样，自瞧不起官场中的那些势利小人，他们的孤傲也就不难理解了。聪明的当权者并不会计较廉吏的这个特性，相反，他们会利用廉吏爱惜名声这一点入手，表面上多加夸奖，满足他们在这方面的嗜求。廉吏在自以为知遇之时，他们便会不道余力地为当权者卖命了</p>
<blockquote>
<p>治吏治心，明主不弃背己之人也。</p>
</blockquote>
<p>管理官吏要研究他们的内心，明智的君主不会抛弃曾背叛自己的人。</p>
<p>人都是有私心的，官场上的人更是如此。如果当权者不了解人的这一本性，一味求全责备，斤斤计较，那么就无人为他所用了。背叛自己其实并不是太大的罪恶，可怕的是他不知悔改，屡屡背叛。只要不是天生的反骨，明智的当权者若能敞开心胸，容忍别人的一次不忠，他的美名和收益远过于杀之泄愤。</p>
<blockquote>
<p>知人知欲，智者善使败德之人焉。</p>
</blockquote>
<p>识别人要了解他的欲望，有智慧的人善于驱使德行有亏的人。</p>
<p>品德不好的人在封建官场大有人在，要想把他们彻底清除是难以做到的事。这一点当权者心知肚明，他们尽力做的只是如何让他们为已致命罢了。德行有亏自然欲望多多，在此谤使他们，当权者就可以驱使他们干任何事了。这些人只要满足了他们的欲望，是无不敢为的，做为当权者整人弄权的工具，他们往往是最合适的人选。</p>
<h2 id="御心第二"><a href="#御心第二" class="headerlink" title="御心第二"></a>御心第二</h2><ul>
<li>比惩罚更有力的是仁慈。</li>
<li>上智御心，下智御力。</li>
<li>先谋后事者昌，先事后谋者亡</li>
</ul>
<blockquote>
<p>民所求者，生也；君所畏者，乱也。</p>
</blockquote>
<p>百姓所追求的，是生存，君主所畏惧的，是叛乱。</p>
<blockquote>
<p>无生则乱，仁厚则安。</p>
</blockquote>
<p>百姓无法生存就会产生叛乱，君主仁爱宽厚就能使天下安定。</p>
<blockquote>
<p>民心所向，善用者王也。</p>
</blockquote>
<p>老百姓都向往的事，善于利用这一点的人可以成就王霸之业。</p>
<p>老百姓像水，君王像舟船。水能载舟也能覆舟。如果老百姓一致认定的事，不是靠行政手段和武力镇压所能阻止、改变得了的。而善于利用这一点的人，就可以成就王霸之业。</p>
<blockquote>
<p>不礼于士，国之害也，治国固厚士焉。</p>
</blockquote>
<p>对读书人不尊敬，是国家的灾害，治理国家 定要优待读书人。</p>
<p>读书人作为民众中的精英人物，他们的态度和立场对民众有很大的影响力。一旦征服了他们，让他们俯首帖耳，统治者御民的阻力就消减了许多，也消除了御民中的最大难题。读书人向来是难以驾驭的，礼待他们作为一种手段，在历朝历代都被证明颇有功效。读书人虽不怕社会的不公和环境的残酷，但他们脆弱的感恩心理却往往会使自己陷入“知遇”的迷团，面对突如其来的好处而不知所措了。</p>
<blockquote>
<p>士子骄纵，非民之福，有国者患之。</p>
</blockquote>
<p>读书人的骄傲和放荡，对老百姓没有好处，治理国家的人对这些人应该警惕。</p>
<p>读书人有许多缺点，骄傲和放荡不羁，虽不是他们的致命伤，但在一味让人顺从的君主眼里，就是大毛病了。百姓往往出于愚昧无知，所以极好愚弄哄骗，而读书人知书明理，统治者要欺骗他们就不是件易事。对此，统治者在无法利用收买读书人的时候，对他们的戒备自是无疑：一旦恼羞成怒，读书人的霉运就避无可避了，</p>
<blockquote>
<p>士不怨上，民心堪定矣。</p>
</blockquote>
<p>读书人不怨恨朝廷，百姓的心意就可以稳定了。</p>
<p>封建统治者轻视民意，他们往往白作聪明地笼络读书人，认为这样就握住了御民的窍要。尽管读书人的变节和屈从会对百姓产生强烈的震撼和负面影响，但民众的觉醒和识见是不可低估的；老百姓虽可受欺于一时的蒙骗，却终舍放弃对任何人的幻想，用自己的力量说话。如果统治者不顺应民意，无论他的手法多么“高明”，最后终归破产.</p>
<blockquote>
<p>严刑峻法，秦之亡也，三代盛典，德之化也。</p>
</blockquote>
<p>秦朝施行的是严酷的刑法，结果很快就灭亡了，夏禹、商汤、周文、武实现了长治久安，就是因为施行了仁德的政治。</p>
<p>愚蠢残暴的统治者为了维护自己的统治，常把严刑重法作为御民的利器，频频祭出。他们幻想百姓在严酷的打压之下，便会乖乖顺从了，永不反叛了。历史的事实反复证明这只是统治者的梦呓，官逼民反的铁律只能让残暴者自作自受。其实，刑与法都是人定的，再好的刑与法如果无好人执行，也一无所用。只有施行德政，让百姓仁爱知礼，天下才会大治。</p>
<blockquote>
<p>权重勿恃，名高勿寄，树威以信也。</p>
</blockquote>
<p>权力大不可以倚仗，名望高不可以托付，树立威严要讲究信用。</p>
<p>信用是最能让人诚服的法宝，无信则是所有失败的原因之一。统治者往往自恃位高权重，朝令夕改，言行不一，这就从根本上失去了民众对他的信赖之情，自不会诚心服从他的号令了。如此，上下离心，令不能行，凡事只能向坏的方向发展，一旦危难来临，便无药可救。高明的统治者总是在取信于民上树立自己的威望，利用一切机会彰显他的诚意。</p>
<h2 id="擒心第三"><a href="#擒心第三" class="headerlink" title="擒心第三"></a>擒心第三</h2><ul>
<li>擒心术为统治者手中的王牌。</li>
<li>用情感打动，这是最好的操纵术。</li>
<li>上位者凭好恶而澶用人，小则必失，大则必乱。</li>
<li>使用人才看是否忠心，才能应属第二。</li>
<li>大才大用，小才小用，不可因其才微而不用。</li>
<li>用人所长，亦为笼络之道，长久之计也。</li>
<li>屈人之心用大赏</li>
</ul>
<blockquote>
<p>德不悦上，上赏其才也。</p>
</blockquote>
<p>品德好不能让君主高兴，君主尊重的是人的才能。</p>
<blockquote>
<p>才不服下，下敬其恕也。</p>
</blockquote>
<p>才能大不能让属下诚服，属下敬畏的是君主的宽恕。</p>
<p>本领越大的统治者就越容易犯下苛求于人的错误，不能宽恕别人。这样，人们就会对他敬而远之，有才能的人更不会为他效力了。原谅别人的过失，为他人着想，是收纳人才的常胜之道；在情感上和别人拉近距离，别人才会抛弃利益和世俗，真正做到生死与共。有才能者都是自尊心极强的，他们也最易被感情所打动，对他们不</p>
<blockquote>
<p>才不服下，下敬其恕也。</p>
</blockquote>
<p>才能大不能让属下诚服，属下敬畏的是君主的宽恕。</p>
<p>本领越大的统治者就越容易犯下苛求于人的错误，不能宽恕别人。这样，人们就会对他敬而远之，有才能的人更不会为他效力了。原谅别人的过失，为他人着想，是收纳人才的常胜之道；在情感上和别人拉近距离，别人才会抛弃利益和世俗，真正做到生死与共。有才能者都是自尊心极强的，他们也最易被感情所打动，对他们不斤斤计较，大度宽容，就是最有力的操纵。</p>
<blockquote>
<p>才高不堪贱用，贱则失之。</p>
</blockquote>
<p>才能高的人不可以让他们担任低贱的职务，轻视他们就会失去他们。</p>
<p>对人才的尊重不能停留在口头上的夸赞，不把人才放到关键的位置上大胆使用，不仅不能让人才发挥作用，而且只能让自己的苦心付之东流。大才之人志大能力强，非高位不能让他们安心效命，这就要求统治者要放开眼光，破格使用他们。如果遵循常理，对他们不特殊优待，大才之人只会感到有志难伸，弃而别走了。</p>
<blockquote>
<p>能微莫付贵权，贵则毁己。</p>
</blockquote>
<p>本领低微的人不要让他们掌握显要的权力，重用他们就会毁灭自己。</p>
<p>对人才的误判和误用，其致命的后果总会显现出来。把不是人才的小人引为知己，授以重权，常常是自毁的开始。没有真本事的人从来不承认自己的无能，他们擅用卑劣的手段打击有才能者，而置国家危难于不顾。统治者没有一个是自愿毁灭的，可他们的极端自私和喜听媚言却少有改变，这样就决定了他们在用人上必有缺失，是无力自拔的。</p>
<blockquote>
<p>才大无忠者，用之祸烈也。</p>
</blockquote>
<p>有大才但无忠心的人，重用他们会招致很大的祸患。</p>
<p>招纳人才的目的，不外乎要使用他们，为自己谋利。如果人才并不忠于自己，那么他的才能就不可能贡献出来：一旦他们倒戈相向，其危险性就远比常人为最了。因此，在招纳使用人才时，只把目光盯在其才能的大小上是愚蠢的，片面强调才能的高低也是不妥的，如果不考察其是否忠心</p>
<blockquote>
<p>人不乏其能，贤者不拒小智。</p>
</blockquote>
<p>人们都有一定的才能，德行好的人不会疏远本领低的人。</p>
<p>不绝对排斥本领低的人，有时会有意外的收获。其实，不同的人都是可以不同使用的，只要善于利用每个人的长处，就会增加自己的胜算，多了一份力量。在非常时期，看似微不足道的本领，却是别有大用的；看似平凡无奇的人，却可救人于危难。审视人才不仅要有大的眼光，吏要改变对人才的狭隘认识，不好高骛远。</p>
<blockquote>
<p>智或存其失，明者或弃大谋。</p>
</blockquote>
<p>智计有时会存有失误，明智的人有时会不用大的谋划。</p>
<p>人才多是善使智计的，智计多寡、优劣，往往是判定人才高低的重要标准。同时，人才又不是完美无缺的，再突出的人才也有智计有失的时候。正因如此，明智的统治者在招纳人才之时，并不会对人才的智计一味听从，并不会对人才盲目地依赖，在重大问题上，他们总有自己的观点和立场，甚至完全不用一切智计。凡事都讲究智计是人才的缺点，只有了解他们，才能更好地驾驭和用好他们。</p>
<blockquote>
<p>不患无才，患无用焉。</p>
</blockquote>
<p>不要担忧没有人才，担忧的是不会使用他们。</p>
<p>抱怨找不到人才的人，无疑是不真心爱才敬才的人。在求才若渴者的眼里，他们总能在芸芸众生中发掘出人的长处，看到人的闪光的东西。觅到人才而不用，或是用而不当，也是许多人的缺失之一，他们空有爱才的名声，却无形中把人才贬值，直至把人才拱手让人，使本身固有的仇势一下消减。把人才真正地使用起来，才能真正地笼络住他们。</p>
<blockquote>
<p>技显莫敌禄厚，堕志也。</p>
</blockquote>
<p>才技突出不能抵挡报酬的丰厚，金钱销蚀人的志向。</p>
<p>用全钱来招纳和收买人才，是从古到今十分有效的方法。才能再高也要穿衣吃饭，志向再高也要养家糊口，在金钱和物质上诱惑他们，满足他们，就不怕人才不乖乖就范。其实，人才和平常人一样，他们不会天生地仇视金钱，他们中的有志者，只不过鄙视不义之财罢了。只要给予的方法适当，赏赐的借口好听，不侵犯他们的自尊心，人才就会心安理得地接受了。</p>
<blockquote>
<p>情坚无及义重，败心矣。</p>
</blockquote>
<p>情感深厚比不上节义重要，节义改变人的思想。</p>
<p>人才是要争取的，人才坐等不来。对人才晓以大义，能使他们放下情感的包袱，转投到自己的门下。和其他方法相比，用大义来感召人才，可促人猛醒，令最固执的人放弃成见。情感的培养非一日之功，免不了夹杂着私利，要把这个关节打通，有时一般的方法是全然无用的。唤起人才的良知和正义感，一切就迎刃而解了。</p>
<p>对愚人用欺骗，对智者用柔诚。 尊敬智者，作为一种策略，虽不出于真心但有效。 游说者夸夸其谈或言过其实，必会引起别人警惕，故说者必慎其辞。 不为外物左右，这是不受欺诈的根本之道，受骗的机会就少。 上当受骗，不愠不怒，沉着冷静才能反击有力。</p>
<blockquote>
<p>愚人难教，欺而有功也。 </p>
</blockquote>
<p>愚蠢的人不能教导他，欺骗他却有成效。</p>
<p>说服别人一定要明确对象，区别对待。愚蠢的人由于不明事理，白以为是，要想说服他们就不能一味依靠说教。骗人的把戏是不光彩的行为，总有人为达目的屡屡施之，而上当最多的又恰是愚音，这从反面也印证了对付愚人是有效方法。喜听谎言的人总是对自己缺乏真正的认识，也蔑视他人的能量，他们不辨是非，孤陋寡闻，不可避免地要吞吃苦果了。</p>
<blockquote>
<p>智者亦俗，敬而增益也。</p>
</blockquote>
<p>有智慧的人也会庸俗，尊敬他可增加收益。</p>
<p>对智者的敬爱，就是对自己的最大负责。反之，对智者也有心愚弄，着意蒙骗，最后蒙受损失的一定是自己。所以有头脑的人是不会处处撒谎的，因为在真人智者面前，谎言全然无用。尊敬智者，这是说服智者的高明手段；尊敬作为一种策略，尽管有时并不是出于真心，但智者还是乐于接受的。这是智者的一个“弱点”，是征服他们的突破口。</p>
<blockquote>
<p>身危者骇，人勿责之。</p>
</blockquote>
<p>身处险境的人恐惧，人们不要指责他。</p>
<p>人在难处之时，极易走向极端，做出大逆不道之事。这个时候，为了避免不测的事件发生，还是要顾全大局，控制自己的情绪，以安抚他们为佳。让人无法察觉自己的真实心境，是高明者掌控局势和他人的要件之一，如果不分青红皂白地直抒胸臆，只能把人推向敌方的阵营，削弱自己的力量。在此，不给落难之人雪上加霜，甚至假作慰勉，都是不促其变节的良方，</p>
<blockquote>
<p>无信者疑，人休蔽之。</p>
</blockquote>
<p>没有信义的人多疑，人们不必蒙蔽他。</p>
<p>用智重在收取功效，其形式固不能拘于定式。把别人蒙在鼓里，使其中我之计，在外表上只讲欺骗是单一的，也不是对所有人都有效的。不讲信义的人从来是多疑的，也是极为敏感的，如果就此故作声张，不加掩饰，以他们的性格定会妄加猜测，疑虑重重。在本该隐蔽处大反其道，需要对目标对象的准确把握；堂而皇之的行为，有时更能让人们产生错觉。</p>
<blockquote>
<p>诡不惑圣，其心静焉。</p>
</blockquote>
<p>欺诈之术不能迷惑圣人，圣人内心安详。</p>
<p>欺诈之术之所以能够得逞，并不见得是欺诈之术有多么高明，而是人们内心躁动贪念的结果。和圣人相比，人们都是世俗的，他们贪心旺盛，心怀侥幸，欺人者便利用人们的这一弱点，投其所好，巧设骗局。对世间万物万事不存偏执，不为外物左右，这是不受欺诈的根本之道，只有向圣人的境界靠拢，骗子的机会才会越来越少。</p>
<blockquote>
<p>正不屈敌，其意谲焉。</p>
</blockquote>
<p>正义不能让敌人自动屈服，因为敌人本性奸诈。</p>
<p>在对敌斗争中，欺诈之术是非使不可的。任何时候都讲究光明正大的人，无疑是天真和幼稚的。奸诈是敌人的本性，和他们讲正义之道，并不能战胜他们；以其人之道还治其人之身，这是最好的选择。诈术是智慧的一个重要内容，智慧不足的人无击发挥诈术的作用，使用不当更会反遭其殃。</p>
<blockquote>
<p>诚不悦人，其神媚焉。</p>
</blockquote>
<p>诚实不能讨人欢心，人们在骨子里都喜欢谄媚。</p>
<p>人都有虚伪的一面，认清这个本质，就不能一味指责别人的欺诈了。欺诈成风往往是由人们自身的好恶和人性弱点所造成的，人们在责怨自己为人欺诈的同时，总免不了也要欺诈别人。事实上，如果诚实无欺的人不屡屡碰壁，如果欺诈之人得不到半点好处，谁会偏好欺诈呢？不反省自己和没有奖赏诚实的社会机制，欺诈就难以根绝。</p>
<blockquote>
<p>自欺少忧，醒而愁剧也。</p>
</blockquote>
<p>自我欺骗能减少忧虑，清醒却使愁苦加剧。</p>
<p>俗话说，难得糊涂，让自己糊涂起来，不欺骗自己是不行的。欺骗自己并不全是“罪恶”，它是把自己从困境和迷惑中解脱出来的可行之法；有了这种善意的欺骗，人们才会不事事较真，不执迷不悟。清醒的人是痛苦的，看透世相与人生，却无力摆脱，这种痛苦会更加剧烈。在理想与现实之间，自欺不失为一种调和剂，为了更大意义上的生存和发展，就该对自己和别人多些“宽容”与“曲解”。</p>
<blockquote>
<p>人欺不怒，忿而再失矣。</p>
</blockquote>
<p>被人欺骗不要发怒，愤怒只能让人失去的更多。</p>
<p>在受骗上当面前，保持理智和良好的心态，就不会意气用事，从而可以避免更大的损失，也就可能了。受骗上当并不是特别难堪的事，难堪的是一再被人欺骗而不觉。愤怒是对自己的惩罚，它对改变现状毫无用处。一旦因为愤怒让自己思雉混乱，行为偏激，这第二次伤害就只能算在自己的头上。不愠不怒，才能沉着冷静，反击有力。</p>
<p>让强敌自我削弱，膨胀其野心是一妙着。 想弃之便放纵他，想使用就收拢他。 砍擒故纵，可以获得更大的胜果。 控制小人要利用他的欲望，如皮影戏艺人手中的线。 在别人的怂恿诱骗下畅所欲言，就要招致大祸。</p>
<blockquote>
<p>国盛势衰，纵其强损焉。</p>
</blockquote>
<p>强国的势头是走向衰落，放任它的强大会损伤它。</p>
<p>物极必反的道理是人所共知的，而让强者更强，进而达到有损它的思想，却不是人人都知晓的：强国少不了自大的雄心，若能推波逐澜，使其野心加剧，它势必要不惜国力，盲目扩张，在各方面都耗费巨大，由此造成的恶果便是国力削损，强大也只是虚张声势的表面了。不正面和强敌相抗，让强敌自我削弱，能从根本上改变敌我的态势，</p>
<blockquote>
<p>人贵势弱，骄其志折焉。</p>
</blockquote>
<p>贵人的势头是转向弱小，促使他志趣骄横能折损它。</p>
<p>有权势有地位的人，免不了心存骄傲，自以为是。位低职微的人和这些人直接对抗，胜算是不多的。反其道而行之，在他们的骄傲处极力吹捧，放言狂赞，这些人在得意之时，只能助长他们的骄横之心，也就免不了干下种种不法之事；一旦积怨甚多，他们的好日子便小多了。故意使人在错误的道路上越走越远，就不能指出前路的暗淡。</p>
<blockquote>
<p>功高者抑其权，不抑其位。</p>
</blockquote>
<p>对功劳大的人要限制他们的实权，而不降低他们的地位。 </p>
<p>放纵是有条件的，在某些方面，该放的就要放；而在另一些方面，该收的也一定要收。收放结合，才能把人牢牢制住。功臣在历史上所起的作用是巨大的，可功臣若走向反面，他们的影响力和破坏力也是惊人的。对待他们，社会地位不能降低，以示荣宠，但不给其实权，就可防患于未然了。在要害处只收不放，这是放纵的首要前提。</p>
<blockquote>
<p>名显者重其德，不重其名。</p>
</blockquote>
<p>对名声显赫的人要看重他们的品德，而不看重他们的名望。</p>
<p>名声大的人并不见得有什么真才实学；名望高的人也不见得都是品德优良之士。由此，对待名人不能一概轻信，放纵他们无拘无束；也不能为他们的名望所系，不识别他们为人的优劣。名人都是不好驾驭的，也是难以收服的，如果重其德而不重其名，真正的名人才会深服你的知人，而不再倨傲了。在品德上倡导推崇，奸滑的小人方能无机可乘。</p>
<blockquote>
<p>败寇者纵之远，不纵之近。</p>
</blockquote>
<p>失败的敌人可以放纵他们逃向远处，不可以放纵他们留在身边。</p>
<p>任何事情都不是绝对的，纵敌远逃表面上与歼敌务尽相违，实际上它只是欲擒故纵的缓招，是应变的灵活措施。给敌人留一条生路，他们便没有了顽抗拼死的决心，逃之愈远，他们的军心就会愈加涣散，他日歼灭他们也就愈加容易。不把敌人留在身边，眼前的危险就消除了；最直接的威胁一旦不在，方能从容不迫地安排未来。</p>
<blockquote>
<p>君子勿拘，其心无拘也。</p>
</blockquote>
<p>君子不要束缚他们，他们的心志是不受束缚的。</p>
<p>对他人无知，就不可能与人相处融洽，更谈不上征服和制服他人了。人都是不会轻易爱制于人的，让君子屈服就更难。君子的心志无拘无束，这是他们的显著特点，也是他们内心最坚韧的东西，不在这方面尊重他们，成全他们，他们会认为受了最大的侵犯，抗拒之心自然强烈。给君子广阔的空间，他们才能心情舒畅，尽心做事。</p>
<blockquote>
<p>小人纵欲，其心惟欲也。</p>
</blockquote>
<p>小人不节制欲望，他们的心思全在满足欲望上。</p>
<p>利欲熏心的小人随处即有，要想彻底排斥他们既无可能，有时也无必要。善于利用小人为自己做事谋利。是封建统治者的一大特色，他们为了自己的私利，常常是放纵小人的贪欲而不管，借以笼络和驱使他们。为欲望笼罩牵绊的人，不给他们好处是难以使用的；让他们欲望满足，他们就是一条疯狗，随时听从主人的号令。</p>
<blockquote>
<p>利己纵之，利人束之，莫以情易耳。</p>
</blockquote>
<p>有利于自己的就放纵它，有利于他人的就约束它，不要因为情感的好恶而改变。</p>
<p>情感的好恶，常能让人改变原则，把标准扭曲。这是成大事者最忌讳的，也是人们常犯的错误。在收放之间，对自已有利无利，往往是人们判定取舍的首要问题，可以说，这是人性自私的正常表现。人都不愿干对自己无利的事，关心别人总不像关心自己，这就决定了放纵什么是不能以危害自己为前提的，一旦失去了这个保证，任何人的承诺都不可相信。</p>
<blockquote>
<p>心可纵，言勿滥也。</p>
</blockquote>
<p>想法可以有很多，但言语不能随便。</p>
<p>社会对人的制约是不能漠视的，人际关系的复杂也决定了一个人不可能真正地放纵自己，随心所欲。人有思想的自由，但言语的随便无忌却可带来灾害，因言成祸的事总在警醒人们在此谨慎为好。自己不能束缚自己的心灵，压抑自己只能趋向保守和僵化；言语不能信口开河，它暴露出的东西会让别有用心的人利用。许多人往往在别人的鼓励下畅所欲言而致祸，这方面的教训是深刻的。</p>
<blockquote>
<p>行可偏，名固正也。</p>
</blockquote>
<p>行为可以有偏失，但名义一定要守正。</p>
<p>保持名义的正当性，是任何人都不敢掉以轻心的事。那些、说一套、做一套的人，虽然他们胆大心黑，言行绝不一致，但他们仍是不忘欺骗世人，用正当的名义掩饰卑劣的丑行。名义有很大的欺骗性，许许多多见不得人的事，都是在堂而皇之的名义下进行的。如果不从根本上制约人的错误行为，不着眼于实际解决问题，再好的名义和措施也只能是一纸空文了。</p>
<p>构心第六 本卷精要 不要轻易向对手发动攻击，看全局的人笑在最后， 打击政敌，又不暴露自己。躲在暗处达到目的，是最高明者。 吹捧小人，让他得意忘形，落入君子的陷阱。 捧杀小人远比棒杀更有效，虽是小人伎俩，但君子的这种做法无可指责。</p>
<blockquote>
<p>富贵乃争，人相构也。</p>
</blockquote>
<p>富贵是争取来的，所以人们互相构陷。</p>
<p>富贵荣华从来不会凭空得到，人们为了它向来是争夺不休的：各种手段和位俩应运而生，人与人之间的互相攻击和陷害也愈演愈烈了。为富贵而争，常是掩饰无耻行为的借口：智计谋划，有时只为了赚取富贵更加快捷。在貌似高尚的征伐中，有许多是为富贵而战的；人们绞尽脑汁，无数人至死也无法实现富贵之梦。</p>
<blockquote>
<p>生死乃命，心相忌也。</p>
</blockquote>
<p>生死是天命造成的，所以人们心里互相忌恨。</p>
<p>生死命运的不同，是人们心有忌恨的原因之一，也是人们互相伤害的潜动力。没有人甘心平庸与失败，在逆境中的人们最易产生怨天尤人的情绪，把愤怒和无奈友泄到无端的人身上。对生活和命运的抱怨，许多人在无击自拔中，只能陷入更深的误区；对天命的指责和反抗，没有人能保持平和的心态。如果目光充满仇视，任何人都可以成为他攻击的对象。</p>
<blockquote>
<p>构人以短，莫毁其长。</p>
</blockquote>
<p>用他人的短处来构陷他，不要抵毁他的长处。</p>
<p>在构陷者看来，找准对象是第一位的；谁都可以找出构陷的理由，除非他不在构陷者的目标之内。人都有他的长处和短处，真正的完人是不存在的，这就为构陷者行使阴谋手段提供了契机与空间。把他人的短处、缺点无限夸大，上纲上线，罪名的成立也就有了“坚实”的基础；对他人的长处无端攻击，只能暴露自己的不良居心。</p>
<blockquote>
<p>伤人于窘，勿击其强。</p>
</blockquote>
<p>在他人窘迫的时候中伤他，他人强势之时不要攻击。</p>
<p>向对手发起冲击，把握恰当的时机是致胜的关键。落水绚打来容易，而得势者却难以损伤了。对风头正劲的人物，不要轻易发动责难，这固是避免失败的良策，亦是保存自己的无奈之举，只有自己不首先倒下，才有战胜对手的可能。不顾现实和背景而一味冲锋的人，常是他人的靶子和垫脚石；注重策略与着眼大局的人，总能笑到最后。</p>
<blockquote>
<p>敌之不觉，吾必隐真矣。</p>
</blockquote>
<p>若让敌人无所察觉，自己就一定要隐藏真实。</p>
<p>打击他人，把自己完全暴露是愚蠢的；把自己的真实状况和意图隐藏起来，才能迷惑他人，占据主动，出其不意。不露真客的人最为可怕，他将自己置身暗处，在对手分不清敌友的状态下，他的所有防范也就形同虚设了。不会掩饰自己的人缺乏智慧，而处处戴着假面具的人却是智慧走偏了：对所有人都隐藏真实，他的真实一定是见不得人的。</p>
<blockquote>
<p>贬之非贬，君子之谋也。</p>
</blockquote>
<p>贬损的目的不是贬损，这是君子的谋略。</p>
<p>贬损他，是为了重用和解脱他，作为一种谋略，贬损只是一种假象而已，这是人们不该忽略的。在特定时期，特别在小人当政之时，君子的这种技能远比正面抗争有效。小人是幸灾乐祸的，让他们这种阴暗心理有了满足，他们便会丧失警惕，而钻进君子所布下的陷阱。只要对事业和他人有利，说法并不重要，关键还在实效</p>
<blockquote>
<p>誉之非誉，小人之术也。</p>
</blockquote>
<p>赞誉的目的不是赞誉，这是小人的手段。</p>
<p>陷害他人并不一定要用卑劣的言词，言不由衷的赞誉同样可以将人置于死地。不识别人的用心，过分的颂词绝不可轻信。对自高自大的愚顽之辈，捧杀他远比棒杀他更直接有效。违心地赞誉别人，虽是小人常用的伎俩，但君子拿来对付小人，也是无可指责的。事实上，由于小人的本性使然，死于捧杀的小人是最多的，他们更容易在赞誉面前飘飘然了。</p>
<blockquote>
<p>主臣相疑，其后谤成焉。</p>
</blockquote>
<p>君主和臣子互相猜疑，这之后诽谤的事才能有咸。</p>
<p>宠臣是难以中伤的，因为他们和君主关系亲密，君主自会护着他，不肯轻易相信他人之言。如此缘故，历史上那些搞阴谋的人对君主关爱的宠臣的伤害，总是从离间宠臣和君主的关系入手，设法让他们产生矛盾，产生猜疑，有了这个铺垫，接下来的馋言才会发生作用。宠臣少不了自视过高的毛病，如果能让君主感受到这一点，猜疑之心便油然而起。</p>
<blockquote>
<p>人害者众，弃利者免患也。</p>
</blockquote>
<p>被人陷害的人很多，能舍弃利益的人可免除祸患。</p>
<p>无端的陷害随处即来，没有人能够永远躲避。在陷害面前，如果无法解脱，就应该舍弃既得的利益而保住自己的根本了。这是明智者的聪明抉择，也是以退求进的处世之法。把利益抛出，损失虽然惨重，但不足以致命；有了利益的牺牲，害人者才会有所满足，或可罢手。俗话说，留得青山在，不怕没柴烧，只要保全根本，就不是最坏的结果。</p>
<blockquote>
<p>无妒者稀，容人者释忿哉。</p>
</blockquote>
<p>没有忌妒心的人很少，能宽容他人的人可消融愤恨。</p>
<p>宽容心虽不能根绝人们的互相攻击，但它至少能使攻击减弱，化解仇恨。在充满竞争和争斗的社会，如果只知攻击和反攻击，斗争就会愈演愈烈，到头来只会两败俱伤，仇恨加剧。要求别人大多是一厢情愿，首先使自己静下心来，原谅他人，才是解决问题的可行之道。如果抛开私心，那么就没有不可原谅的人与事；自己主动解除武装，再野蛮的对手也会失去攻击的对象了。</p>
<h2 id="逆心第七"><a href="#逆心第七" class="headerlink" title="逆心第七"></a>逆心第七</h2><ul>
<li>大忠者善于权变，愚忠者作茧自缚。</li>
<li>征服人心是治乱之本，以德服人重枉付诸行动，不怕慢，而怕不为。</li>
<li>身居高位，不能在奉承中忘却隐藏的杀机。</li>
<li>甘于“平庸”无欲无求最让对手放心，这是大智者的远虑。</li>
</ul>
<blockquote>
<p>利厚生逆，善者亦为也。</p>
</blockquote>
<p>利益丰厚让人发生背叛，善良的人也会这样做。</p>
<p>在巨大的利益面前，本性良善的人，也会禁不住诱惑而蜕变，这不是利益的罪过，而是良善的本身有时并不足以信赖。善良是相对的，它不是一成不变的。在复杂的社会和多变的环境下，在利益至上的氛围中，单纯的善良是十分脆弱的；在扭曲的世界里，人的尴尬处境和不幸遭遇，也促使人们信念动摇，进而滑向泥潭，向罪恶屈服。在时代的大背景下，能够坚守善良实属不易了。</p>
<blockquote>
<p>势大起异，慎者亦趋焉。</p>
</blockquote>
<p>势力大的人容易产生异心，谨慎的人也有这种趋向。</p>
<p>地位的变化可以让人干出许多看似不可思议的事来。这是人心不满足使然，也是权势让人盲目自大的结果。富贵已极保持平和是很难的，谨慎的人在迷信自己的权势之时，也能做出不理智的判断，虚荣心一旦有增无减，人的行为就绝非他人可以控制了。不甘驯服的人总是自以为有力量的人，尽管这种力量纯属虚幻，他们也会冒险一搏。</p>
<blockquote>
<p>主暴而臣诤，逆之为忠。</p>
</blockquote>
<p>君主残暴臣子诤谏，臣子违背君主是忠心。</p>
<p>忠逆的判定因人而异，但真正的忠心是不以君主的好恶为好恶的。君主虽有绝对的权力，任意定人罪名，但事情的本来面目却非人力所能改变。大忠和愚忠是截然不同的，满足君子的心愿只是个人行为，不违正义和大道却合天地人心。所以明智的君主勇于否定自己，而昏庸的君主只知否定他人，在违逆和顺从之间，仁君总能放下自尊和偏见，超越情感的爱憎而客观待人的。</p>
<blockquote>
<p>主昏而臣媚，顺之为逆。 </p>
</blockquote>
<p>君主昏庸臣子谄媚，臣子顺从君主是背逆。</p>
<p>历史上的奸人小人，在当时多是以“忠臣”面目出现的。他们不问是非，惟君命是从，即使助纣为虐，也无一丝犹豫，他们实质上把君主推向不可回头的深渊，无疑是典型的背叛。没有公德心和正义感的人，只能沦为罪恶的帮凶；在权势和权威面前低头的人，绝不是真正可信赖的人。有了顾虑和阴谋，不背叛别人是不可能的：对这种人不欣赏迁就， 自己才不舍被出卖愚弄。</p>
<blockquote>
<p>忠奸莫以言辨，善恶无以智分。</p>
</blockquote>
<p>忠臣奸臣不能用他们的言语来分辨，善人恶人不能用他们的智慧来区分。</p>
<p>言语的表白、智慧的高低，都不足以让人识别和判定一个人的真伪，心怀异志的人不会高喊谋逆，智慧不足的人也不一定没有野心。考察一个人的忠贞是要剔除假象的，而要揭穿一十人的奸计就必须直指其心，从他的本质行为上寻找蛛丝马迹。没有人是天生的叛逆者，他们的人生轨迹便是最好的说明。在小事上印证，在细节处研析，对人的认识就不会有大的差错。</p>
<blockquote>
<p>谋逆先谋信也，信成则逆就。</p>
</blockquote>
<p>谋划反叛的事首先要谋取对手的信任，有了信任事情才能成功。</p>
<p>谋划对手重要的是不暴露自己，以其亲信的面目施展手段，再强的对手也不堪一击了。把自己的真实用心掩藏起来，有时要付出血的代价；不做必要的牺牲，狡猾的对手就难以消除疑虑。在对手意想不到之处打动他，用最忠心的个也难以做到的事触动他，任何人都会失去理智。潜伏在对手的身边，最致命的攻击才可一举完成。</p>
<blockquote>
<p>制逆先制心也，心服则逆止。</p>
</blockquote>
<p>制止背叛首先要制服人的心灵，心灵畏服背叛才会停止。</p>
<p>征服人心是治乱的根本之道，强权和高压无法消除叛乱之原。让人从心里畏服是最难的，也是短视者与强硬派不愿施行的，这是他们智慧不足的表现，也是他们德望低下、自信心不强的体现，其实，在正逆之间，有时界限并不分明，如果盲目以正义自居，监施淫威，在道义上便失去了正义的力量。以德服人重在付诸行动，不能因噎废食。</p>
<blockquote>
<p>主明奸匿，上莫怠焉。</p>
</blockquote>
<p>君主英明奸臣才会隐藏，君主不能松懈。</p>
<p>一切的阴谋和背叛，时刻都在孕育中，统治者如果疏于防范，过度自信，终要自食其果，对英明的统治者而言，他们的英明和睿智，奸臣的伎俩不能欺骗他们，奸臣的收敛是迫不得已；一旦他们有所松懈，奸臣便会按捺不住了。盛世潜伏着危机，明君环侍着奸小；不给奸人行奸的机会，统治者不仅需要保持清醒，更要有制约奸人的机制。</p>
<blockquote>
<p>成不足喜，尊者人的也。</p>
</blockquote>
<p>成功不值得欢喜，地位高的人是人们攻击的对象。</p>
<p>高高在上的人，很难让人们和他保持一心，永不背叛，他们处在人们忌羡的位置上，他们的特权和地位，时刻让人觊觎，这是任何人都无法阻止的。所谓树大招风，只要身处高位，便有被人颠覆的危险。正因如此，看透世事的人在成功面前不舍得意忘形，更不会在人们的奉承声中忘却隐忧。有得必有失，成功也不例外。</p>
<blockquote>
<p>败不足虞，庸者人恕耳。</p>
</blockquote>
<p>失败不值得忧虑，平庸的人是人们宽恕的目标。</p>
<p>野心会成就大事，也会招来大祸。在失败之时，仍野心勃勃的人是最危险的，对手是不容许不甘于失败之人存在的。承认失败只是承认事实，由不得人死不认账，但在无力改变局面下，甘于平庸，彻底抛弃不臣之心，却是有智者才能做到的。从高处跌落容易让人同情怜悯，无欲无求也最让对手放心，乐于高抬贵手。在胜利者面前，曾违逆他可以原谅，反心不死就绝无宽恕了。</p>
<h2 id="夺心第八"><a href="#夺心第八" class="headerlink" title="夺心第八"></a>夺心第八</h2><ul>
<li>以一人之心，制万人之心，短时有效，长久必败。</li>
<li>君子为名而不为利，知恩而图报，夺心易也；小人为利而不计名誉，忘恩负义，不易夺心。</li>
<li>把敌人制服在未动之时，把恶人的歹意直指出来，是赢取主动和胜利的智者谋略。</li>
<li>用温和手段征服人心，这是智者首选之术。</li>
<li>让人屈服不如让人敬服。</li>
<li>任何人都有他的低谷，然而保待内心的沉静，在屈辱中乐观向上，就不是真正的屈辱了。</li>
</ul>
<blockquote>
<p>众心异，王者一。</p>
</blockquote>
<p>众人的思想是不相同的，君王要把它们统一起来。</p>
<p>统一人们的思想，把个人的意念加诸于人，是封建统治者不道余力要做的头等大事。夺人心志，让民顺从，是统冶的根基；在思想上剥夺民众的自由，封建统治者才好兜售其奸。只要不利于封建统治的思想，都可被斥为异端邪说；思想上的殉难者，所受的迫害和摧残也是最重的。封建专制让人们不能自由思考和提出质疑，这是社会发展的一大阻力。</p>
<blockquote>
<p>慑其魄，神鬼服。</p>
</blockquote>
<p>让人的精神恐惧，任何人都会屈服。</p>
<p>人的精神一倒，其意志和雄心便会土崩瓦解。再刚强和难制的人，也抵御不了精神的打击；抓住了这一攻击点，也就是掌握了人的最薄弱环节。制造精神紧张首先要制造恐怖气氛，在人人自危的环境下，人们总是本能地加倍小心。了解别人的内心想法，也是必不可少的，如果把别人的潜在意图都一一点明，谁都会心惊肉跳，不敢妄动了。</p>
<blockquote>
<p>君子难不丧志，释其难改之。</p>
</blockquote>
<p>君子受难不会丧失志向，帮助他解除苦难却能改变他。</p>
<p>君子的志向不会因环境的残酷而动摇，这是令人崇敬的。打击和迫害只能成全君子的美名，这也是君子甘心承受的。君子最难消受他人之恩，在他们难时伸出援助之手，君子就摆脱不掉报恩的“阴影”了，这是征服他们的上上之策，不管出于什么用心，君子在情感的亏欠中总会有所改变、不琢磨人的心理，就不能征服人心</p>
<blockquote>
<p>小人贵则气盛，举其污泄之。</p>
</blockquote>
<p>小人得势就气焰嚣张，检举他的罪行就会使他泄气。</p>
<p>小人身上的污迹肯定是很多的，没有劣行也就称不上小人了。收冶小人不是件易事，但只要握住他的罪行铁证，色厉内荏的小人还是会惧怕的。小人的能量不可轻视，他们的狡辩和抵赖之术，化黑为白之功，常让人反遭暗算，打虎不成。这就揭示人们不要过于相信铁证，更要配以智慧和时机，这也许才是最重要的。</p>
<blockquote>
<p>穷堪固守，凶危不待也。</p>
</blockquote>
<p>贫穷可以让人坚守节操，而凶险和危难之时就不容等待了。</p>
<p>陷于贫穷境地的人们，只要不贪图富贵，甘于清贫，保持本色仍是不难；可在凶险来临之际，面对危难之时，要化解这一切，就绝非单凭骨气便能做到。人被逼到身不由己的时候，他的选择往往是违心的；尽管他是多么的不情愿，但已是非情感和对间所能决定的了。人的改变有时是不可预知的，在重压下，改变往往是注定的</p>
<blockquote>
<p>察伪言真，恶不敢为。</p>
</blockquote>
<p>察觉出伪装说出真意，恶人也不敢做恶了。</p>
<p>识敌在先，才能防范在后，打压敌人的心志。任何人只要他的真实用心被人识破，他就构不成大大的威胁。做坏事的人不会轻易暴露自己，他们把希望大多寄托在出其不意之上，如果能让这个幻想破灭，他们的斗志便大为削减。把敌人制服在未动之时，把恶人的歹心直指出来，是赢取主动和胜利的智者谋略，付出的代价是最少的。</p>
<blockquote>
<p>神褫之伤，愈明愈痛。</p>
</blockquote>
<p>心神被剥夺的创伤，越聪明的人就越会感到痛苦。</p>
<p>受制于人有时不仅是行为上的，也是精神上的，后者的痛苦尤为巨大，对聪明者更是如此。把自己变成行尸走肉，多是出于无知和无奈，而成为他人的玩偶，任其摆弄，且自知甚深，这才是最难忍受的。作为驭人和惩罚的手段，这个招法无疑是狠辣和残酷的，同样，作为人生中的一段经历，它给人的记忆和教训也是难忘和深刻的。</p>
<blockquote>
<p>苛法无功，情柔堪毕焉。</p>
</blockquote>
<p>严苛的刑法不能达到目的，情感安抚可以完成此事。</p>
<p>夺人心志离不开严刑峻法，但一味依赖它，也是无法让所有人都服帖的。同时，它的负作用十分强烈，表面上的安静终会被深处的愤恨所冲破。动之以情，用温和的手段征服人心，这是智者的首选之术，它能化解最因执者的戾气，而让所有人都乐于接受。只要能达到心愿，不讲方法可以，但这却决不是远虑者所为了</p>
<blockquote>
<p>治人者必人治也，治非善哉。</p>
</blockquote>
<p>惩处他人的人一定会为他人所惩处，惩处并不是好的方法。</p>
<p>一味整治别人的人，自食其果的事屡见不鲜；和天下人结怨，自己便没有了退路。让人屈服不如让人敬服，用大棒建立的威严一日便可崩塌。真正的智者不会把心思和精力全用在征服别人之上，他们更不会相信“征服”这回事。他们看似毫无用心的平淡交接，毫无所指，却能使任何人都心生感动，向之靠拢。这种凝聚力是无形的，也是最牢固的，它使所用的机巧都不攻白破。</p>
<blockquote>
<p>屈人者亦人屈也，屈弗耻矣。</p>
</blockquote>
<p>屈服于他人的人也会让他人屈服，屈服并不是耻辱的事。</p>
<p>任何人都有他的低谷，一时的屈服决定不了他的终生。不把屈服于人为耻，才可重振雄心，打好翻身仗：不在低谷中沉沦，才能接受教训，不以彻底的失败收场。最高尚的人也阻止不了他人做卑鄙的事，这是不以人的意志为转移的，只要保持自己内心的纯净，任何屈辱都无法让人失去对未来的信心。在屈服中乐观向上，就不是真正的屈服了。</p>
<blockquote>
<p>知世而后存焉。</p>
</blockquote>
<p>了解社会之后才能生存。</p>
<p>在社会上立足，认识不到社会的本质是不可想象的。社会是复杂的，也是残酷的，如果为其表面的现象所迷惑，就会处处受制，时时碰壁，其结果自是生存维艰，无以为继。对社会抱有警醒之心是生存的前提，对人世间怀有警戒之心是生存的根基，若要发展，就更离不开趋利避害，警觉当先了。对社会的人和事需有深刻的认识，对生存环境的无知和陌生，就无法适应和防范各种灾难</p>
<blockquote>
<p>识人而后幸焉。</p>
</blockquote>
<p>能鉴别人的优劣之后才有幸运。</p>
<p>人的善恶无法从外表上看出，也不可能由人当面告知，不能分辨好人坏人，所有的防线便形同虚设，注定要倒霉的。生活在人的世界上，人有时是最危险的“动物”，对人失去观察力和鉴别力，是最可怕的失败，它的后患是无穷的。细节是判定人优劣的可靠依据，关键时候是验证人的品质的最佳时期，把人性吃透，恶事便会远去。</p>
<blockquote>
<p>天警人者，示以灾也。</p>
</blockquote>
<p>苍天对人的警告，表现为天灾。</p>
<p>古人“天人感应”的学说，把自然灾害视为苍天的告警，从这个意义上说，人们也不该忽视警告的作用，在事情恶化之前，多做自我反思，吸取教训，以免错上加错，执迷不悟。事情都有它的内在联系，孤立地看人对事就会失之片面，存有误差：如果把矛盾消化在初始阶段，解决在萌芽状态，大的灾难就可避免了。</p>
<blockquote>
<p>神警人者，示以祸也。</p>
</blockquote>
<p>神灵对人的警告，表现为人祸。</p>
<p>面对突来的祸事，人们在应对的同时，最该深刻反省自己的行为。事情总有它的因果，不找出祸事发生的轨迹，更大的灾难便在后头。做恶事的人轻视“神灵”，迷信权势和暴力，这不仅与人民为敌，也违背了天理，是不会善终的。对“神灵”的敬畏，不是智者的软弱，而是他们最富有智慧之处；保有足够的谨慎之心，才会事事如意。</p>
<blockquote>
<p>人警人者，示以怨也。</p>
</blockquote>
<p>人们对他人的警告，表现为怨恨。</p>
<p>受到人们的怨恨，这个人就危机重重了，置人们的责难而不理不眯，怨恨只能增长；在仇视的目光下，调整自己的心态和行止是必须的。人没有无缘无故的恨意，认识到事态的严重性，才可弥补裂痕，防止事情进一步恶化。即使是坚持正义，一切缘于误会，及时疏导人们的怨气也不是可有可无。人的激行为，积怨大多是其一大主因。</p>
<blockquote>
<p>畏惩勿诫，语不足矣。</p>
</blockquote>
<p>害怕惩处的人不要告诫他，言语不能让他改过。</p>
<p>劝人改过要区分对象，那些不明是非的死硬分子，苦口婆心对他们无有效力，打击惩处便是惟一的选择。不撞南墙不回头的人，让他们吃点苦头是必要的，善意的言辞他们可以置若罔闻，但现实的伤痛却能把他们唤醒，片面强调教育作用解决不了所有问题，方法有所变通，手段多样，只要行之有效，尽可以一用。</p>
<blockquote>
<p>存悔莫罚，责于心乎。</p>
</blockquote>
<p>有了悔意的人不要体罚他，责罚在心是最痛苦的。</p>
<p>肉体的惩罚只是皮肉之痛，而良心的谴责让人一世难安。在追悔莫及的时候，人才会想到他人的好处和反省自己，在痛苦中沉思，远比棒打能让人成熟起来。泄愤的方式有多种，在他人悔恨之时不动声色，温情不惩，更会使人心有愧疚，痛不欲生。从正面的意义讲，对悔过之人不穷追猛打、揪住不放，其震慑力和警醒力是最大的。</p>
<blockquote>
<p>势强自威，人弱自惭耳。</p>
</blockquote>
<p>势力强大自然有威严，弱者会自感羞愧。</p>
<p>劝诫别人必须自有身价，让人重视不能仅凭言辞。实力的作用在任何时候都不可替代，实力强大的本身就是最好的警戒。智者有时无法战胜愚蠢的强者，强者的荒谬有时可以被人推崇为真理，这都是强势的作用使然。身份低微的人在世俗社会黯然无声，真知灼见淹没在人们的趋炎附势上，只有大智慧的人，才能目光向下，从社会最底层的小人物身上，吸取营养</p>
<blockquote>
<p>变不可测，小戒大安也。</p>
</blockquote>
<p>变乱是难以测度的，小事上谨慎才能确保平安。</p>
<p>小处放纵往往酿成大祸，在这方面绝不可任性而为。听从劝诫重在不分事情大小，都记取在心，认真改过。在自重上坚持始终，就不会有疏漏的时刻了。居安思危是回避凶险的要件，在小事上看出隐患的存在，便能把大局安定。对自己不负责任的人，是没有警戒之心的；对他人劝告不以为然的人，谁也保护不了他。</p>
<blockquote>
<p>意可曲之，言虚实利也。</p>
</blockquote>
<p>意图可以曲解，说假话为了获取实际的利益。</p>
<p>在特定的场合和时期，善意的谎言是不该被指责的。为了使人猛醒，从迷途中解脱出来，故意曲解他人的意图，牵强附会，以达到劝戒的目的，也是一种智谋。再好的忠言也有不被接受的时候，适时变换一个方法，加上一个全新的角度，效果就会大不一样了。正面猛攻的人不一定会得手，学会迂回之术，胜率就大增了。</p>
<h2 id="诛心第十"><a href="#诛心第十" class="headerlink" title="诛心第十"></a>诛心第十</h2><ul>
<li>对敌人肉体伤害，不如摧残他的灵魂。</li>
<li>没有底牌可打的对手是脆弱的。</li>
<li>让人不能心愿得偿，心灰意冷是伤害的至毒招法。</li>
<li>虚荣心只会让弱者自卑，让强敌就范。</li>
<li>以名誉地位做诱饵，不仅廉价有效，且能让人死而无怨。</li>
</ul>
<blockquote>
<p>诛人者死，诛心者生。</p>
</blockquote>
<p>杀死人的人有死罪，杀死人心的人却能活命。</p>
<p>公开的暴行和罪恶，可以得到法律的严惩，但那些隐形伤害，法律乱奈何不了它了。摧残人的心灵，在精神上打击迫害，是不少人玩弄的整人招去，这既逃脱了罪名，也最能将人置于死地。肉体的创伤可以愈合，而精神的折磨却没有尽时，一个人如果到了生不如死的境地，无疑是最悲惨的。</p>
<blockquote>
<p>征国易，征心难焉。</p>
</blockquote>
<p>征服国家容易，征服人心困难。</p>
<p>建立在武力之上的统治，是不会长久的。武力可以打压反抗，但无法让人心顺服：征服人心不能依靠武力，一味讨好百姓也不是绝佳之策，只要在百姓最关心的问题上保持公正，予民实惠，形象便可很快确立。百姓的要求向来无多，他们要求的内容也并不复杂苛刻，统治者若能仁慈一点，克制一点，就不该以民为敌了。</p>
<blockquote>
<p>不知其思，无以讨之。</p>
</blockquote>
<p>不知晓他人的内心想法，就没有办法治理他。</p>
<p>一个人的内心想法决定着他的行为举止，这个秘密不侦知，治理他就无的放矢，成效甚微。人的内心千变万化，但还是有迹可寻的，只要掌握住人的思想脉络，他便毫无秘密可言，制服他便会毫不费力。表面的东西是一定要认真识别的，如果为其伪装所迷惑，判断就会有误，方法也舍失当，所有的努力都会变得徒劳。</p>
<blockquote>
<p>不知其情，无以降之。</p>
</blockquote>
<p>不了解他人的真实状况，就不能及时降服他。</p>
<p>把对手的底细摸透，了如指掌，始终是战胜对手的一个重要前提。一个人的实际状况是不会轻易显现的，这需要耐心细致的调查和取证才能搞清，在此不下大工夫是不行的，没有捷径可走。没有底牌可打的对手是最脆弱的，在他们的要害处轻轻一击，也就致命了。清楚他们的虚实，便会掌握他们的动态，抢在他们之前出手，被动的就不会是自己。</p>
<blockquote>
<p>其欲弗逞，其人殆矣。</p>
</blockquote>
<p>人的欲望得不到满足，这个人就危险了。</p>
<p>人的欲望是多样的，也是十分强烈的，欲望失落的人，往往会丧失斗志，对一切都心灰意冷，不能自拔 破坏别人的好事，让人不能心愿得偿，这是伤害人的至毒招去，它足以把人的意志全盘摧毁，沦为行尸走肉 欲望愈强的人，愈容易受到这种暗算，受伤害的程度也愈深。不为欲望所左右，才能更好地保护自己。</p>
<blockquote>
<p>敌强不可言强，避其强也。</p>
</blockquote>
<p>在强大的敌人面前不可以说强硬的话，要回避它强劲的势头。</p>
<p>鸡蛋碰石头只能毁灭自己，不知道回避凶险便一事无成。人的勇气和雄心并不能取代实力的地位，弱者在强者面前撒泼斗狠，可笑又可悲的还是弱者、避开他人的强悍，以柔克刚，是以弱胜强的法则；不让他人的优势发挥出来，力量对比便失去了意义。在智计上乡下功夫，在言辞上不刺激强敌，双方才会维持均衡；</p>
<blockquote>
<p>敌弱不可言弱，攻其弱也。</p>
</blockquote>
<p>在弱小的敌人面前不可以说软弱的话，要攻击他虚弱的地方。</p>
<p>再弱小的敌人也不会自动屈服的，如果打击不到他的痛处，他很可能套成为一个难缠的对手，，对弱者不能示弱，弱者更有理由让人同情；极言恫吓尽管无礼，但只要说出了弱者的要害，摆明了可能出现的严重后果，弱者仍是可以不战而胜的。无人以弱者为荣，弱者也不该以弱为耻，虚荣心只会让弱者自卑，在强敌面前束手就范。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在一读书公众号的推荐下陆陆续续看完了这本『奇书』，里面的套路不难，但怎么灵活掌握，就需要时间了。当然，还是少一点套路，多一些真诚&lt;/p&gt;
    
    </summary>
    
      <category term="Reading" scheme="http://wdxtub.com/categories/Reading/"/>
    
    
      <category term="古文" scheme="http://wdxtub.com/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="处世" scheme="http://wdxtub.com/tags/%E5%A4%84%E4%B8%96/"/>
    
  </entry>
  
  <entry>
    <title>【小土刀玩摄影】γ 从镜头到构图</title>
    <link href="http://wdxtub.com/2016/11/16/alpha-7-tour-3/"/>
    <id>http://wdxtub.com/2016/11/16/alpha-7-tour-3/</id>
    <published>2016-11-15T23:05:37.000Z</published>
    <updated>2016-11-16T15:33:05.000Z</updated>
    
    <content type="html"><![CDATA[<p>前面我们已经了解了相机的基本操作和功能，现在是时候学一些摄影基础了，有了这些基本知识，就可以拿起相机开始拍拍拍了。</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<ul>
<li>2016.11.16: 完成初稿</li>
</ul>
<p>更新计划</p>
<ul>
<li>简单配图</li>
</ul>
<h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><p>按下快门前应该懂的东西，当然，全自动傻瓜相机也不是不行。</p>
<h3 id="镜头"><a href="#镜头" class="headerlink" title="镜头"></a>镜头</h3><ul>
<li>焦距是最重要的镜头指标之一，表示镜头的光学中心到相机图像传感器的距离，单位是毫米</li>
<li>焦距决定了相机“看”到的物体大小以及镜头视角的广度</li>
<li>焦距越小，镜头视角越广；焦距越大，相机取景框中的物体越大</li>
<li>焦距和透视失真效果有密切关系，焦距越小，镜头前近物和远物呈现出的距离越大</li>
<li>微距镜头可以在极短的对焦距离上合焦</li>
</ul>
<p>根据镜头焦距的不同，我们把镜头分为几大类：</p>
<ul>
<li>鱼眼镜头：8-15mm，视角接近或等于 180 度，照片会出现明显的弯曲</li>
<li>广角镜头：14-35mm，视角从 52 到 82 度，常用于拍摄室内、风景、活动报道</li>
<li>标准镜头：35-60mm，约等于相机取景框的对角线长度，拍摄效果与人眼视觉效果十分相似</li>
<li>人像镜头：60-135mm，视野相对较窄，因为高感光度和软成像，能够更好地虚化背景以及突出主体，常用于拍摄（人像）特写</li>
<li>长焦镜头：135-800mm，视角小，会压缩空间纵身距离和夸大后景，常用于拍摄远距离物体</li>
</ul>
<h3 id="曝光"><a href="#曝光" class="headerlink" title="曝光"></a>曝光</h3><p>曝光指的是一定时间内到达相机的传感器的光的量，取决于『光圈』『快门速度』及『ISO』，根据参数的不同，可能会出现曝光不足（太暗）、曝光过度（太亮）和曝光正常。</p>
<p>『光圈』是以分数的形式来计算的，一般记为 <code>F2</code>, <code>F4</code> 等等，F 常常会被省略，并且 F 后面的数字（光圈值）是分母。也就是说，光圈值越大，光圈越小；反之，光圈值越小，光圈越大。一个从大到小的光圈序列可能是：<code>F1.2 F1.4 F1.8 F2.0 F2.8 F5.6 F10 F16</code>。</p>
<blockquote>
<p>『景深(DOF)』是指出物体看起来对焦清晰的区域，通常使用『调焦圈』来进行调整。景深取决于光圈的大小：光圈越大，景深越小，背景越模糊；反之，光圈越小，景深越大，清晰的区域更大。一般来说，拍摄建筑物和风景时，增加景深，保证清晰和纵深感；拍摄人像时，减少景深，虚化背景突出主体。</p>
</blockquote>
<p>『快门速度』则是快门打开的时间，在这个时间里光线得以到达图像传感器，所以快门速度越快，到达图像传感器的光越少，图像越暗；反之，快门速度越慢，到达图像传感器的光线越多，图像越亮。我们常说的安全快门，就是指焦距的倒数，比方说如果焦距是 70mm，那么快门速度至少要高于 1/70，才更能保证图片不因抖动而模糊。</p>
<blockquote>
<p>一般来说，在捕捉正在运动的物体时，我们需要尽可能提高快门速度来保证成像不模糊。但是也有特殊情况，比方说拍摄溪流和瀑布，通常会用较长的曝光时间来营造『水流』的效果。长时间曝光的时候，一定要注意稳定，最好使用牢固的三脚架。</p>
</blockquote>
<p>『ISO』越高，光传感器就越敏感，在其他条件相同的情况下，图片就越亮。通常情况下，ISO 小于 400 是比较好的选择，如果 ISO 太高，图像的噪点会非常严重。</p>
<p>而具体的曝光情况，则是由这三个因素共同决定的，所以如何去寻找最合适的组合就成了我们需要掌握的技能。光线充足的时候，寻找合适的曝光比较简单，但是在光线不好的时候，就需要一些技巧了。</p>
<h3 id="白平衡"><a href="#白平衡" class="headerlink" title="白平衡"></a>白平衡</h3><p>白平衡是让颜色『正常』的过程。这就需要了解色温，单位是开尔文(K)，参见下图：</p>
<p><img src="/images/14792939042853.jpg" alt=""></p>
<p>我们在设置相机白平衡的时候，是在设置光源的色温，也就是说，我们设置为多云，那么相机会认为此时是偏蓝，会往偏红的方向偏。一般来说，我们用人的肤色来作为调整白平衡的依据。但是有的时候，『正确』的白平衡值并没有办法表达摄影师的感觉，具体选用什么白平衡设置，就需要自己摸索了。</p>
<p>而用 RAW 格式保存的照片，因为保留了更多传感器原始的数据，所以后期调整的范围更大，一般我们都会用 RAW 格式。</p>
<h2 id="光"><a href="#光" class="headerlink" title="光"></a>光</h2><ul>
<li>灯光在摄影中非常重要</li>
<li>为光源定位和使用光源一样重要</li>
<li>光照的表面区域越大，光就越柔和</li>
<li>常见设备有：反光罩(R)、柔光箱(S)、雷达罩(B)</li>
</ul>
<p>每种光有不同的作用，比如：主光、补光、边缘光、背景光</p>
<ul>
<li>主光：创建主光效果</li>
<li>补光：补充因为主光造成的硬阴影和软阴影</li>
<li>边缘光：从后面照亮模特，突出整个或者部分轮廓，突出主题</li>
<li>背景光：将人物与背景分离开，创建更加三维的外形，放在主体后面，指向背景</li>
</ul>
<h2 id="构图"><a href="#构图" class="headerlink" title="构图"></a>构图</h2><p>基础原则</p>
<ul>
<li>新手须知的重要原则：水平对齐，照片不能歪</li>
<li>三分构图：把重要物体放在线条交叉点上</li>
<li>边缘整洁：照片边缘不要有什么杂物，可以通过缩放裁剪移动来控制</li>
</ul>
<p>引导眼睛</p>
<ul>
<li>人的眼睛会被照片中的线条所吸引<ul>
<li>水平线可以表现平静、稳定画面</li>
<li>垂直线条能让构图有前度，迫使观众从下往上研究构图</li>
<li>汇聚线可以创造角度并增加深度感</li>
<li>对角线使照片显得复杂和动态，引导观看者沿某一方向观察</li>
</ul>
</li>
<li>照片中有移动的物体也能引导视线，会跟随其运动路径</li>
<li>人的眼睛也是一个引导视线的方式，可以自动引导观看者的视线，在眼睛前面保留空白</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>看了一圈知乎，感觉大部分都是答主晒图，拍照这个东西，还是比较主观玄学的，基础的东西固然重要，更多的是需要多拍拍拍。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="http://www.thegreatphotoapp.com/" target="_blank" rel="external">The Great Photo App</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前面我们已经了解了相机的基本操作和功能，现在是时候学一些摄影基础了，有了这些基本知识，就可以拿起相机开始拍拍拍了。&lt;/p&gt;
    
    </summary>
    
      <category term="Life" scheme="http://wdxtub.com/categories/Life/"/>
    
    
      <category term="基础" scheme="http://wdxtub.com/tags/%E5%9F%BA%E7%A1%80/"/>
    
      <category term="拍摄" scheme="http://wdxtub.com/tags/%E6%8B%8D%E6%91%84/"/>
    
  </entry>
  
  <entry>
    <title>Javascript 编码风格指南</title>
    <link href="http://wdxtub.com/2016/11/14/javascript-style-guide/"/>
    <id>http://wdxtub.com/2016/11/14/javascript-style-guide/</id>
    <published>2016-11-14T11:26:27.000Z</published>
    <updated>2016-11-14T11:28:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>Javascript 作为一个非常灵活的脚本语言，光是比较流行的编码风格指南就有好几种。有 Google, NPM, Node.js, jQuery, Airbnb 等等。本文以 Airbnb 风格为基础来介绍 js 的编码风格，对原文的逻辑进行了梳理。</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<ul>
<li>2016.11.14: 初稿完成</li>
</ul>
<h2 id="格式规范"><a href="#格式规范" class="headerlink" title="格式规范"></a>格式规范</h2><ul>
<li><strong>命名规则：规范</strong><ul>
<li>避免单字母命名。命名应具备描述性</li>
<li>使用驼峰式命名对象、函数和实例（首字母小写）</li>
<li>使用帕斯卡式命名构造函数或类（首字母大写）</li>
<li>使用下划线 <code>_</code> 开头命名私有属性</li>
<li>别保存 <code>this</code> 的引用。使用箭头函数或 <code>Function#bind</code></li>
<li>如果你的文件只输出一个类，那你的文件名必须和类名完全保持一致</li>
<li>当你导出默认的函数时使用驼峰式命名。你的文件名必须和函数名完全保持一致</li>
<li>当你导出单例、函数库、空对象时使用帕斯卡式命名</li>
</ul>
</li>
<li><strong>代码块：规范</strong><ul>
<li>使用大括号包裹所有的多行代码块</li>
<li>如果通过 <code>if</code> 和 <code>else</code> 使用多行代码块，把 <code>else</code> 放在 <code>if</code> 代码块关闭括号的同一行</li>
</ul>
</li>
<li><strong>注释：规范</strong><ul>
<li>使用 <code>/** ... */</code> 作为多行注释。包含描述、指定所有参数和返回值的类型和值</li>
<li>使用 <code>//</code> 作为单行注释。在评论对象上面另起一行使用单行注释。在注释前插入空行</li>
<li>给注释增加 <code>FIXME</code> 或 <code>TODO</code> 的前缀可以帮助其他开发者快速了解这是一个需要复查的问题，或是给需要实现的功能提供一个解决方式。这将有别于常见的注释，因为它们是可操作的。使用 <code>FIXME -- need to figure this out</code> 或者 <code>TODO -- need to implement</code></li>
</ul>
</li>
<li><strong>空白：这个部分见仁见智保持一致即可</strong><ul>
<li>使用 2 个空格作为缩进</li>
<li>在花括号前放一个空格</li>
<li>在控制语句(<code>if</code>、<code>while</code>)等的小括号前放一个空格。在函数调用及声明中，不在函数的参数列表前加空格</li>
<li>使用空格把运算符隔开</li>
<li>在文件末尾插入一个空行</li>
<li>在使用长方法链时进行缩进。使用前面的点 <code>.</code> 强调这是方法调用而不是新语句</li>
<li>在块末和新语句前插入空行</li>
</ul>
</li>
<li><strong>逗号：规范</strong><ul>
<li>行首逗号：不需要</li>
<li>增加结尾的逗号: 需要。因为这会让 git diffs 更干净</li>
</ul>
</li>
<li><strong>分号：规范</strong><ul>
<li>使用分号，防止在极端情况下被合并   </li>
</ul>
</li>
</ul>
<h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><ul>
<li><strong>类型：核心思想是避免复杂类型的深浅复制</strong><ul>
<li>直接存取基本类型：字符串、数值、布尔类型、<code>null</code>、<code>undefined</code></li>
<li>通过引用的方式存取复杂类型：对象、数组、函数</li>
</ul>
</li>
<li><strong>引用：核心思想是最小化引用的影响范围，不要轻易变化</strong><ul>
<li>对所有的引用使用 <code>const</code>，不要使用 <code>var</code>。这能确保无法对引用重新赋值，避免出现 bug，减少理解成本</li>
<li>如果一定需要可变动的引用，使用 <code>let</code> 而不是 <code>var</code>。因为 <code>let</code> 是块级作用域，而 <code>var</code> 是函数作用域</li>
<li><code>let</code> 和 <code>const</code> 都是块级作用域</li>
</ul>
</li>
<li><strong>变量：</strong><ul>
<li>一直使用 <code>const</code> 来声明变量，如果不这样做就会产生全局变量。我们需要避免全局命名空间的污染</li>
<li>将所有的 <code>const</code> 和 <code>let</code> 分组，当你需要把已赋值变量赋值给未赋值变量时非常有用</li>
<li>在你需要的地方给变量赋值，但请把它们放在一个合理的位置。因为 <code>let</code> 和 <code>const</code> 是块级作用域而不是函数作用域</li>
</ul>
</li>
<li><strong>字符串：增加可读性</strong><ul>
<li>字符串使用单引号 <code>&#39;&#39;</code></li>
<li>字符串超过 80 个字节应该使用字符串连接号换行</li>
<li>过度使用字串连接符号可能会对性能造成影响</li>
<li>程序化生成字符串时，使用模板字符串代替字符串连接。因为模板字符串更为简洁，更具可读性</li>
</ul>
</li>
<li><strong>比较运算符 &amp; 等号：规范与代码可读性</strong><ul>
<li>优先使用 <code>===</code> 和 <code>!==</code> 而不是 <code>==</code> 和 <code>!=</code></li>
<li>条件表达式例如 <code>if</code> 语句通过抽象方法 <code>ToBoolean</code> 强制计算它们的表达式并且总是遵守下面的规则<ul>
<li><code>对象</code> 被计算为 <code>true</code></li>
<li><code>Undefined</code> 被计算为 <code>false</code></li>
<li><code>Null</code> 被计算为 <code>false</code></li>
<li><code>布尔值</code> 被计算为 <code>布尔的值</code></li>
<li><code>数字</code> 如果是 <code>+0</code>、<code>-0</code>、或 <code>NaN</code> 被计算为 <code>false</code>, 否则为 <code>true</code></li>
<li><code>字符串</code> 如果是空字符串 <code>&#39;&#39;</code> 被计算为 <code>false</code>，否则为 <code>true</code></li>
</ul>
</li>
<li>使用简写</li>
</ul>
</li>
<li><strong>类型转换：</strong><ul>
<li>在语句开始时执行类型转换</li>
<li>字符串不要用 <code>this.score + &#39;&#39;</code>，而是 <code>String(this.score)</code></li>
<li>对数字使用 <code>parseInt</code> 转换，并带上类型转换的基数</li>
<li>如果因为某些原因 parseInt 成为你所做的事的瓶颈而需要使用位操作解决<a href="http://jsperf.com/coercion-vs-casting/3" target="_blank" rel="external">性能问题</a>时，留个注释说清楚原因和你的目的</li>
<li>小心使用位操作运算符。数字会被当成 64 位值，但是位操作运算符总是返回 32 位的整数（<a href="http://es5.github.io/#x11.7" target="_blank" rel="external">参考</a>）。位操作处理大于 32 位的整数值时还会导致意料之外的行为。<a href="https://github.com/airbnb/javascript/issues/109" target="_blank" rel="external">关于这个问题的讨论</a>。最大的 32 位整数是 2,147,483,647</li>
<li>使用 <code>Boolean()</code> 或 <code>!!</code> 来进行布尔值的转换</li>
</ul>
</li>
<li><strong>存取器：一致性与规范</strong><ul>
<li>属性的存取函数不是必须的</li>
<li>如果你需要存取函数时使用 <code>getVal()</code> 和 <code>setVal(&#39;hello&#39;)</code></li>
<li>如果属性是布尔值，使用 <code>isVal()</code> 或 <code>hasVal()</code></li>
<li>创建 <code>get()</code> 和 <code>set()</code> 函数是可以的，但要保持一致</li>
</ul>
</li>
<li><strong>jQuery：明确指出使用 jQuery 的代码，优化性能</strong><ul>
<li>使用 <code>$</code> 作为存储 jQuery 对象的变量名前缀</li>
<li>缓存 jQuery 查询</li>
<li>对 DOM 查询使用层叠 <code>$(&#39;.sidebar ul&#39;)</code> 或 父元素 &gt; 子元素 <code>$(&#39;.sidebar &gt; ul&#39;)</code></li>
<li>对有作用域的 jQuery 对象查询使用 <code>find</code></li>
</ul>
</li>
</ul>
<h2 id="复杂结构"><a href="#复杂结构" class="headerlink" title="复杂结构"></a>复杂结构</h2><ul>
<li><strong>对象：考虑兼容性与可读性</strong><ul>
<li>使用字面值创造对象，如 <code>const item = {};</code> 而非 <code>const item = new Object();</code></li>
<li>浏览器环境中执行的代码不要使用 <a href="http://es5.github.io/#x7.6.1" target="_blank" rel="external">保留字</a> 作为键值（比如 <code>private</code> 这类就不要用），可以使用同义词替换所需要使用的保留字，比如说把 <code>class</code> 换成 <code>type</code></li>
<li>创建有动态属性名的对象时，使用可被计算的属性名称，这样就可以在一个地方定义所有的对象属性</li>
<li>使用对象方法和对象属性值的简写</li>
<li>在对象属性声明前把简写的属性分组，这样能清楚地看出哪些属性使用了简写</li>
</ul>
</li>
<li><strong>数组：可读性与操作简化</strong><ul>
<li>使用字面值创建数组，如 <code>const items = [];</code> 而非 <code>const items = new Array();</code></li>
<li>向数组添加元素时使用 <code>Arrary#push</code> 替代直接赋值</li>
<li>使用拓展运算符 <code>...</code> 复制数组，如 <code>const itemsCopy = [...items]</code></li>
<li>使用 <code>Array#from</code> 把一个类数组对象转换成数组</li>
</ul>
</li>
<li><strong>解构：减少操作开销</strong><ul>
<li>使用解构存取和使用多属性对象，这样能减少临时引用属性</li>
<li>对数组使用解构赋值</li>
<li>需要回传多个值时，使用对象解构，而不是数组解构。因为增加属性或者改变排序不会改变调用时的位置</li>
</ul>
</li>
<li><strong>函数：性能与可读性</strong><ul>
<li>使用函数声明代替函数表达式，如 <code>function foo() {}</code></li>
<li>永远不要在一个非函数代码块（if、while 等）中声明一个函数，把那个函数赋给一个变量。浏览器允许你这么做，但它们的解析表现不一致</li>
<li>ECMA-262 把 <code>block</code> 定义为一组语句。函数声明不是语句</li>
<li>永远不要把参数命名为 <code>arguments</code>。这将取代原来函数作用域内的 <code>arguments</code> 对象</li>
<li>不要使用 <code>arguments</code>。可以选择 rest 语法 <code>...</code> 替代。因为使用 <code>...</code> 能明确你要传入的参数。另外 rest 参数是一个真正的数组，而 <code>arguments</code> 是一个类数组</li>
<li>直接给函数的参数指定默认值，不要使用一个变化的函数参数</li>
<li>直接给函数参数赋值时需要避免副作用</li>
</ul>
</li>
<li><strong>箭头函数：简化代码，加强可读性</strong> <ul>
<li>当你必须使用函数表达式（或传递一个匿名函数）时，使用箭头函数符号</li>
<li>如果一个函数适合用一行写出并且只有一个参数，那就把花括号、圆括号和 return 都省略掉。如果不是，那就不要省略。如 <code>[1, 2, 3].map(x =&gt; x * x)</code></li>
</ul>
</li>
<li><strong>构造器：维持一致性，链式调用</strong><ul>
<li>总是使用 <code>class</code>，避免直接操作 <code>prototype</code>。因为 <code>class</code> 语法更有可读性</li>
<li>使用 <code>extends</code> 继承，因为 <code>extends</code> 是一个内建的原型继承方法并且不会破坏 <code>instanceof</code></li>
<li>方法可以返回 <code>this</code> 来帮助链式调用</li>
<li>可以写一个自定义的 <code>toString()</code> 方法，但要确保它能正常运行并且不会引起副作用</li>
</ul>
</li>
<li><strong>模块：确保模块化，符合规范</strong><ul>
<li>总是使用模组(<code>import</code>/<code>export</code>)而不是其他非标准模块系统。你可以编译为你喜欢的模块系统</li>
<li>不要使用通配符 <code>import</code>，这样能确保你只有一个默认 <code>export</code></li>
<li>不要从 <code>import</code> 中直接 <code>export</code>。虽然一行代码简洁明了，但让 import 和 export 各司其职让事情能保持一致</li>
</ul>
</li>
<li><strong>迭代器：往函数式编程上靠，减少副作用</strong><ul>
<li>不要使用 <code>iterators</code>。使用高阶函数例如 <code>map()</code> 和 <code>reduce()</code> 替代 <code>for-of</code>。因为处理纯函数的回调值更易读，这比它带来的副作用更重要</li>
</ul>
</li>
<li><strong>属性：区分是否通过变量来访问</strong><ul>
<li>使用 <code>.</code> 来访问对象的属性</li>
<li>当通过变量访问属性时使用中括号 <code>[]</code></li>
</ul>
</li>
<li><strong>事件：灵活性，降低判断成本</strong><ul>
<li>当给事件附加数据时（无论是 DOM 事件还是私有事件），传入一个哈希而不是原始值。这样可以让后面的贡献者增加更多数据到事件数据而无需找出并更新事件的每一个处理器</li>
</ul>
</li>
</ul>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="https://lzw.me/a/javascript-coding-style-reference.html/comment-page-1" target="_blank" rel="external">JavaScript 流行代码风格参考指南</a></li>
<li><a href="https://github.com/yuche/javascript" target="_blank" rel="external">Airbnb JavaScript 编码规范</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Javascript 作为一个非常灵活的脚本语言，光是比较流行的编码风格指南就有好几种。有 Google, NPM, Node.js, jQuery, Airbnb 等等。本文以 Airbnb 风格为基础来介绍 js 的编码风格，对原文的逻辑进行了梳理。&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="风格" scheme="http://wdxtub.com/tags/%E9%A3%8E%E6%A0%BC/"/>
    
      <category term="Javascript" scheme="http://wdxtub.com/tags/Javascript/"/>
    
  </entry>
  
  <entry>
    <title>第二十二周 - 在梅边</title>
    <link href="http://wdxtub.com/2016/11/12/zai-mei-bian/"/>
    <id>http://wdxtub.com/2016/11/12/zai-mei-bian/</id>
    <published>2016-11-12T03:21:32.000Z</published>
    <updated>2016-11-12T06:16:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>春水望断，夏花宿妆残。谁闻秋蝉，谁知冬来。</p>
<a id="more"></a>
<hr>
<p>天气忽然转冷，总算有了些许冬天的意思。世界各地这周可是热火朝天发生着轰轰烈烈的大改变，从长征五号到歼20再到川普成为美国总统最后到双十一，朋友圈也是被各种刷屏。不过归根结底还是要努力把日子过好，用胡适的话说就是『多研究些问题，少谈些主义』。</p>
<p>本周跑步两次，值得说说的是第二次，最近因为路线调整，总距离差不多六公里，之前跑起来到最后还是有点辛苦的，可能是因为心情好，这次跑起来的感觉完全不一样，这个故事告诉我们，还是要每天开开心心的，不然跑起来都没劲儿。背后的隐含意思其实是，生活中总是有很多不如意的地方，那就要多试试看能不能扭转成如意，如果连一点努力都不做就自暴自弃，是不是自暴自弃得太廉价了一点。</p>
<p>一直在做的其中一个项目进入中后期，随着各个模块的完成，因为涉及的数据非常重要，如何保证准确性和安全性就成了最重要的工作内容，这需要拿到各种数据进行交叉验证，如何把这个做好，其实也是很有意思的。我要检讨自己之前的工作态度，看起来简单枯燥的工作背后其实也有门道，把工作越挖越深越做越细的时候，才是最能发挥聪明才智的时候。解决一个一个问题当然重要，但更重要的是在这个过程中理解问题背后的东西，下次尽量避免再出同样的问题。</p>
<p>前些天上班路上听到了机核网介绍五年前刚开始做这档节目时大家的回忆，所有看起来很酷的东西一开始都是简陋慌张的，但是只要坚持，一定会慢慢成长起来的。之前定下的各项工作从本周起也基本在逐步走上正轨，希望自己的作品能早一点跟大家见面。</p>
<p>双十一终于剁手买了一部全画幅相机，等待收货的中午就在想，相机记录的其实是我们对这个世界的观察，影像记录的质量取决于我们观察的角度，这样的角度会对应于相机的各种参数（焦距光圈构图色彩等等）并最终转化成为一种感觉，也就是审美。</p>
<p>热热闹闹的买买买把光棍节原来的气氛完全冲走了，但从一个小朋友的角度来说，能在光棍节的晚上和喜欢的人一起蹲在地上捣鼓新玩具，是特别幸福的事情，一想到就开心。</p>
<p>在梅边落花似雪纷纷绵绵谁人怜，在柳边风吹悬念生生死死随人愿。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;春水望断，夏花宿妆残。谁闻秋蝉，谁知冬来。&lt;/p&gt;
    
    </summary>
    
      <category term="Gossip" scheme="http://wdxtub.com/categories/Gossip/"/>
    
    
      <category term="周记" scheme="http://wdxtub.com/tags/%E5%91%A8%E8%AE%B0/"/>
    
      <category term="双十一" scheme="http://wdxtub.com/tags/%E5%8F%8C%E5%8D%81%E4%B8%80/"/>
    
  </entry>
  
</feed>
