<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小土刀</title>
  <subtitle>Agony is my triumph</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wdxtub.com/"/>
  <updated>2016-10-02T03:55:39.000Z</updated>
  <id>http://wdxtub.com/</id>
  
  <author>
    <name>wdxtub</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>数据平台技术指南</title>
    <link href="http://wdxtub.com/2016/10/01/data-platform-tech-guide/"/>
    <id>http://wdxtub.com/2016/10/01/data-platform-tech-guide/</id>
    <published>2016-09-30T23:15:22.000Z</published>
    <updated>2016-10-02T03:55:39.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近大部分精力花在为公司搭建统一的数据平台上，从技术选型到最终落地像打通隧道一样艰难和痛快，本文主要介绍数据平台的技术相关实践与思考。具体的设计思路可以参考我的另一篇文章 - <a href="http://wdxtub.com/2016/10/01/data-platform-design-guide/">数据平台设计指南</a></p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<ul>
<li>2016.10.2: 完成初稿</li>
</ul>
<p>数据平台的解决方案有很多，从数据仓库到现在最火的 Hadoop/Spark，随着开源运动的蓬勃发展，几乎各个组件都有足够多的项目供开发者选择。虽然不需要自己做轮子了，但是如何选择合适的轮子拼成最高效的车子，仍然需要技术团队谨慎选择。</p>
<p>尤其是不同的团队不同的风格不同的业务需求，不太存在一劳永逸的做法，无论是架构还是功能，都应该保证螺旋上升的趋势，以应对各种突发情况。</p>
<p>注：本文不涉及数据平台的设计思路，感兴趣请参考 <a href="http://wdxtub.com/2016/10/01/data-platform-design-guide/">数据平台设计指南</a></p>
<h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><p>为了方便后文的叙述，先简要介绍一下背景。数据平台项目原先只是我们部门内部的一个项目，和我之前接手的日志项目基本处于并行的状态。数据平台项目和日志项目唯一的连接点在于数据的存储，共用一个 Elasticsearch 集群。</p>
<p>日志这边最初的架构是利用 Rsyslog + Logstash 直接把日志汇总到 Elasticsearch(后面用 ES 表示) 中。而数据平台的后端原先是基于 Ruby On Rails(后面用 RoR 表示) 的，功能也比较简单，一方面是利用 ES 的聚合来进行基本的日志数据收集，另一方面是从第三方的统计服务中（比如 Google Analysis）拉取数据，给前端进行展示。</p>
<p>在已有系统的基础上进行改动和完全从头开始搭建是两种完全不同的思路。虽然说从零开始几乎不受任何束缚，但实际情况中基本不太可能立马推倒重来，毕竟已有系统虽然比较简陋，至少还在服役中。于是只能一个模块一个模块进行调整，一是保证服务稳定，二是在人力不够的条件下，防止步子太大出问题。</p>
<p>所以在重构一开始，我给自己的设计定下的目标是：</p>
<ul>
<li>尽量小的改动（影响面越小，可能出的问题就越少）</li>
<li>尽量就近服务（因为要提供全球范围内的服务，需要尽量优化线路）</li>
<li>减少跨机房数据同步量（尤其是跨海传输，带宽和稳定性所带来的额外成本很令人头疼）</li>
</ul>
<p>在经历了一系列技术测试之后（详情见最后的链接），由我确定了日志部分的架构，而数据平台部分的架构由我的同事确定，后台部分最终选择的技术是：</p>
<p><strong>ELK Stack + Kafka + Spring MVC</strong></p>
<p>细节与原因如下：</p>
<ul>
<li>ELK Stack 在业界的实践中已被证明是比较靠谱的日志解决方案，加上原来的日志系统就已经采用了 ELK 方案，改动的成本较低</li>
<li>用 Logstash 取代了原先采用的系统级的 Rsyslog 用来传输日志，方便管理和配置（Logstash 的配置还是非常好写的）</li>
<li>加入了 Kafka 用作消息队列，把 Logstash 与 Elasticsearch 解耦，所有日志会先经过 Kafka，再由 Kafka 导入 Elasticsearch</li>
<li>出于性能考虑和其他一些因素的考虑，用基于 Java 的 Spring MVC 取代 Ruby on Rails，虽然 RoR 的开发效率很高，但是我和另一个核心开发人员都不熟悉 Ruby，所以转为 Java（至少好招人）</li>
</ul>
<p>总体来说，整个架构的调整需要考虑的因素很多，除了开发团队的技术栈外，更多是投入和产出的权衡。很多时候能争取到的资源非常有限，就需要想办法巧妇做少米之炊了。</p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>虽然前面提到的技术不多，但因为全球部署和全球服务的缘故，架构图还是有一些复杂的。理论上完美的方案，实际落地的时候会出现各种各样的因为物理因素导致的问题。这也是为什么要一个一个地区和市场去推进，不然不断涌现的各种问题，在人力不足的时候会把团队拖入『死亡进军』的状况。架构图做了一定化简（只有中、美两机房），具体如下：</p>
<p><img src="/images/14753730024863.jpg" alt=""></p>
<p>围绕着以 ES 集群为存储核心，整个系统主要分三大块：</p>
<ol>
<li>日志收集与分析</li>
<li>埋点上报与数据接入</li>
<li>数据与日志统计与分析</li>
</ol>
<p>因为采用了不同地区的不同服务提供商，还需要兼顾数据同步的问题，整个系统经过不断演化，最终达到了如上图所示的比较稳定的结构。不过由于我手头上的事情实在太多，具体的数据量、用户量、消息量评估只完成了最基本的部分。目前的重心主要还是在系统的完善与功能添加中，很多技术债是在人力不足的情况下不得不背的，对于我和另外一个同事这样的强迫症来说，只能尽量多做一点是一点了。</p>
<p>最后再强调一次，数据是拿来用的，一定要跟各个部门深入沟通好需求，并在不断磨合中找到让大家都最舒服的合作方式。很多技术和架构选择都是非常业务相关的，这里就不多提了。后面主要讨论的会是『如何让整一个系统流畅运行起来』这个问题</p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>这一部分主要是介绍 <a href="http://wdxtub.com/2016/10/01/data-platform-design-guide/">数据平台设计指南</a> 中提到的四个主要流程的具体实现和相关思路。</p>
<h3 id="采集与预处理"><a href="#采集与预处理" class="headerlink" title="采集与预处理"></a>采集与预处理</h3><ul>
<li>日志的收集要跟不同团队的开发人员对接，了解真正有价值的参数，减少带宽与存储的消耗（毕竟日志中会有大量的冗余）</li>
<li>提取日志中真正有价值的东西</li>
<li>分词问题，string 字段要在 logstash 阶段就要设置为 <code>not_index</code></li>
<li>数据上报系统采用 ID 与密钥配对方式进行有效性校验，并且利用另外的数据库做权限控制，具体需要做到的粒度可以根据需求进行控制</li>
<li>做多机房同步的时候尽量利用云服务本身提供的服务，自己做数据同步很辛苦，得不偿失</li>
<li>不同的服务要有流量和数据量控制，保证不因为单个系统的不稳定而拖挂整个系统</li>
<li>不同数据源如何对齐，公共字段需要仔细设置</li>
<li>写日志的时候就要考虑未来的处理和应用，尤其是和已有数据源的对齐</li>
<li>字段同名但类型不同导致的索引冲突问题</li>
<li>设计埋点及统计字段时一定要基于具体的统计需求，不能为了打点而打点，字段是什么，后面要如何使用，不同的字段如何联系与互动，都需要事先想好</li>
<li>专注于核心指标，不同指标的优先级是什么</li>
<li>界面、事件和事件参数独立，但必须有公共的统计参数（最好两个一上，冗余保证后续数据清洗及验证的准确性）</li>
<li>维护埋点，增加上报的信息量（同样大小的前提下），减少上报压力</li>
</ul>
<p>整个 ETL 过程需要建立固定的流程，为开发者准备好对应的接口、文档及测试系统。对于老数据的导入也需要有自动化可重复的工具链。而对于需要内网才能访问的系统，可以考虑在内网假设服务，然后走数据上报的流程进行数据汇总。</p>
<h3 id="清洗与分类"><a href="#清洗与分类" class="headerlink" title="清洗与分类"></a>清洗与分类</h3><p>这一层主要是进行分发与过滤，利用 Logstash 和 Kafka 的诸多特性，不需要写很多代码就可以完成。一些考虑有：</p>
<ul>
<li>根据服务区分 Kafka 中不同的 topic，来进行隔离，虽然是同一管道，但是也要尽量避免相互影响</li>
<li>日志中可能有的非法字符以及过长的日志需要进行过滤，不然进入 ES 可能会导致问题</li>
<li>需要有定期任务机制，清理不需要的数据，保存到 S3 这种比较便宜的存储中</li>
<li>贯彻二八原则，20% 最有价值的数据进行结构化存储，剩下的以文本形式保存在云存储中，除非必要时，一般不需要动</li>
</ul>
<p>因为不需要跟外部系统交互，这部分其实需要做的东西不算太多，但是作为最重要的中转站，需要保证高可用性，这就需要对各个组件有一定深入了解了。</p>
<h3 id="存储与查询"><a href="#存储与查询" class="headerlink" title="存储与查询"></a>存储与查询</h3><p>基于 Luence 的 ES 集群在处理中文的时候可能有坑，不过目前 IK 分词基本可以满足需求。其他需要注意的有</p>
<ul>
<li>ES 集群的监控一定要做，要好好做，可以采用业界流行的方案，也需要了解 ES 的基本 API 和相关设置。 </li>
<li>如果可能的话，尽量多配几台机器，可以由专门的机器做不负责存储只负责调度的主节点以及只负责存储及查询的数据节点，具体需要根据需求进行调整</li>
<li>很多暴露出来的问题，回归到最初都是因为存的时候太随意导致的，还是那句话，即使是类似 NoSQL 的存储，好的设计仍然无比重要</li>
<li>监控部分需要和运维密切配合，以达到快速反应，保证服务质量的目的</li>
<li>安全是非常重要的话题，内部系统的好处在于可以用白名单与二次验证的机制保证数据安全，具体的备份策略也需要仔细斟酌，找到一个平衡</li>
</ul>
<h3 id="展示与应用"><a href="#展示与应用" class="headerlink" title="展示与应用"></a>展示与应用</h3><p>这部分主要是前端展现与后端数据挖掘，这两部分涉及的话题太多，这里就不展开了，简单说一下。</p>
<ul>
<li>数据可视化的核心在于目标明确，而这个目标怎么找到，一定是和相关业务部门沟通出来的，不能是开发人员拍脑袋</li>
<li>需要结合不同部门之前的业务实践，走之前提到了『取代-超越』两步战略</li>
<li>随着数据量的增大，可以结合 Spark/Hadoop 等分布式计算框架来进行数据挖掘，当然，这是比较后面的工作了，可能需要专门找人来负责</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在数据平台的建设中，总是会有各种各样的小问题，我的感受是临时的补丁不是不能打，但是一定要及时找出问题的根源，从系统的层面解决掉，不然补丁好修复，但是补丁的补丁，甚至补丁的补丁的补丁一多，很容易造成几乎无解的局面。</p>
<p>而对于系统中使用的相关技术，也一定要在『会用』的接触上深入理解其工作原理和运行机制，不需要深入到代码级别，但至少要能在出了问题之后第一时间有基本的排查思路，不然依靠 google 和 stackoverflow 编程，只会给同事带来巨大的困扰。</p>
<p>当然，本文只是目前我的一些想法，会随着系统的开发不断更新内容。如果大家有做过相关系统的经验，欢迎共同讨论，如果在深圳的话，可以约出来吃个饭聊一聊嘛。</p>
<h2 id="相关文档"><a href="#相关文档" class="headerlink" title="相关文档"></a>相关文档</h2><ul>
<li><a href="http://wdxtub.com/2016/08/15/kafka-guide/">Kafka 指南</a></li>
<li><a href="http://wdxtub.com/2016/07/26/elk-guide/">ELK 指南</a></li>
<li><a href="http://wdxtub.com/2016/09/28/elasticsearch-cluster-guide/">Elasticsearch 集群指南</a></li>
<li><a href="http://wdxtub.com/2016/07/24/elastic-search-guide/">Elasticsearch 入门指南</a></li>
<li><a href="http://wdxtub.com/2016/07/24/logstash-guide/">Logstash 入门指南</a></li>
<li><a href="http://wdxtub.com/2016/08/18/logstash-kafka-guide/">Logstash 连接 Kafka 指南</a></li>
<li><a href="http://wdxtub.com/2016/08/17/rsyslog-kafka-guide/">Rsyslog 连接 Kafka 指南</a></li>
<li><a href="http://wdxtub.com/2016/08/12/rsyslog-logstash-guide/">Rsyslog + Logstash 日志传输指南</a></li>
<li><a href="http://wdxtub.com/2016/09/28/linux-server-check-guide/">Linux 服务器检查指南</a></li>
<li><a href="http://wdxtub.com/2016/07/26/crontab-guide/">Crontab 指南</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近大部分精力花在为公司搭建统一的数据平台上，从技术选型到最终落地像打通隧道一样艰难和痛快，本文主要介绍数据平台的技术相关实践与思考。具体的设计思路可以参考我的另一篇文章 - &lt;a href=&quot;http://wdxtub.com/2016/10/01/data-platform-design-guide/&quot;&gt;数据平台设计指南&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="技术" scheme="http://wdxtub.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="数据" scheme="http://wdxtub.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>数据平台设计指南</title>
    <link href="http://wdxtub.com/2016/10/01/data-platform-design-guide/"/>
    <id>http://wdxtub.com/2016/10/01/data-platform-design-guide/</id>
    <published>2016-09-30T23:11:20.000Z</published>
    <updated>2016-10-01T03:03:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近大部分精力花在为公司搭建统一的数据平台上，在不断地踩坑中慢慢摸索出了一套行之有效的方法，本文主要介绍数据平台的流程设计与相关思考，具体的技术实现可以参考我的另一篇文章 - <a href="http://wdxtub.com/2016/10/01/data-platform-tech-guide/">数据平台技术指南</a></p>
<a id="more"></a>
<hr>
<h2 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h2><p>市场、运营、研发还是内部管理每天都会产生各种各样的数据及报表，一是用于监控各项事宜的运作情况，二是给决策提供更多有价值的信息。随着公司的快速发展与业务的不断扩大，产生和消费的数据也越来越多，传统手工以及简单的电子化统计已经不能满足各个部门的需求。我们来看看下面这三个问题：</p>
<ol>
<li>从前收集数据和制作报表只需要半天，但是现在随着需要统计的内容增多，可能需要三天，也就是说数据最重要的时效性大打折扣</li>
<li>很多时候依靠单一部门的数据无法完成复杂的分析，但由于不同部门间天生较高的沟通成本，除了需要专人对接外，还需要走一定的流程，就把原本简单的工作变得复杂了，甚至因为各种推诿最终不了了之</li>
<li>不同部门的业务统计很多需求是一致或者类似的，只是统计的数据维度不同，这也意味着很多没有意义的重复劳动</li>
</ol>
<p>为了解决上面提到的三个问题，一个统一的内部数据平台便应运而生。在此基础上，我们还从另外两个维度扩展了数据平台，一是更基础的服务监控，二是更高级的智能分析。更让我骄傲的是，整个项目的核心开发者只有三人，其中前端一人，后台及服务器两人（在此感谢曾为此项目付出过的其他同事）。</p>
<p>从白手起家到接入来自公司不同部门的十多项业务，从最初简单的原型到现在初具规模的系统，每次重构与架构调整，都是大家一起摸着石头过河淌出来的。虽然还有许多堆积的需求（缺人力呀），但只要地基打得好，就不怕盖高楼。</p>
<p>注：本文不涉及具体的技术实践，感兴趣请参考 <a href="http://wdxtub.com/2016/10/01/data-platform-tech-guide/">数据平台技术指南</a></p>
<h2 id="方向"><a href="#方向" class="headerlink" title="方向"></a>方向</h2><p>在这个『大数据』与『云计算』概念满天飞的年代，我对于数据平台的思考应该是偏谨慎的。这是屁股决定脑袋的一个非常清晰的例子，创业公司最需要的就是给投资人描绘一个愿景，那么就需要带上各种时髦的词汇；而对于我在做的数据平台来说，最重要的是提供有价值的服务，真正能帮助各个部门节约时间、综合信息、提高决策效率的服务。正因如此，我没有给数据平台制定一个看得见摸不着的目标，而是打算分两步走：</p>
<p><strong>第一步：取代</strong>。深入各个部门的业务流程与实践，了解第一手的需求。这里的取代，指的是利用数据平台自动化处理数据生成报表，把他们从繁重的人工统计中解放出来（用 Excel 仍然需要大量需要人工参与的中间过程）。只要各个部门把数据接入并打通数据流，我们就可以根据需求制作相应的页面（这里主要指长期且能够流程化处理的需求）。当他们需要具体数据与报表时，只需要登录网站查看即可。如果需要做一些临时分析，也可以把数据导出为 Excel 表格自行处理。</p>
<p><strong>第二步：超越</strong>。在接入了不同部门的数据后，数据平台实际上拥有了综合不同数据源进行协同统计的可能，相当于把原先部门范围的数据辐射到了公司范围，各个部门都可以方便地利用更加全面的信息进行业务判断。所谓超越，指数据平台应该能完成原先 Excel 不能做（或者是难以做好）的深入分析。通过挖掘隐藏在数据背后的规律，给各个部门提供更加简单轻松的数据服务。</p>
<p>我给这个方案起了个名字，叫做『数据自治自洽』，本质是给公司和用户带来有价值的数据产品，用来给公司的各项业务提供数据支持。作为公司平台化和数据化的重要一环，数据平台的意义不仅在于数据本身，而是通过信息共享与集体智慧形成某种意义上的『群脑』，最终转化成为更有意义的产品和服务。</p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>其实数据平台的流程化简之后都差不多，难点不在于思路而在于具体实现。这里简要介绍一下各个步骤中的设计要点，具体的实现可在 <a href="http://wdxtub.com/2016/10/01/data-platform-tech-guide/">数据平台技术指南</a> 查看</p>
<h3 id="采集与预处理"><a href="#采集与预处理" class="headerlink" title="采集与预处理"></a>采集与预处理</h3><p>数据采集也许是最被低估的一个步骤。做过数据挖掘和模型分析的朋友应该都知道『Garbage in, Garbage out』这个简单的道理，数据模型可谓是数据平台的灵魂，而数据采集的方法和策略是数据模型的基础，一定要谨慎。如果要用一句话总结数据收集的思路，那就是：</p>
<p><strong>从用数据的角度出发收集数据，而不是反过来</strong></p>
<p>具体的思路就有很多的扩展了，主要三点：细粒度、围绕业务、概念层级一致。</p>
<h3 id="清洗与分类"><a href="#清洗与分类" class="headerlink" title="清洗与分类"></a>清洗与分类</h3><p>这部分的内容需要大量的跨部门沟通，比如不同业务系统的日志信息筛选过滤，一是能够有效减少无意义的存储（日志中会有大量重复信息），二是为后续的存储与查询打下良好的基础。</p>
<p>我们目前是按照业务来进行划分的，不同的业务有不同的工作流，优点在于比较灵活，缺点在于没有把通用的部分抽出来（主要问题是目前公共的部分并不多）。</p>
<p>在这一步我们需要进行概念统一，比方说外部代号与内部代号的映射，这样在之后的统计分析中，我们能够以比较简洁的代码和模型去处理，而不用再去纠结格式与编号问题（与网络分层模型的思路一致）</p>
<h3 id="存储与查询"><a href="#存储与查询" class="headerlink" title="存储与查询"></a>存储与查询</h3><p>这一步唯一需要统一的就是『存储是为了查询』。存的时候随意存，查的时候肯定就没办法随意。我见过很多把 NoSQL 数据库当做 MySQL 来用的做法，那不就是自找苦吃嘛。</p>
<p>提一下『数据自治自洽』这个概念，自治指的是数据流的通畅以及自动根据多个系统的信息综合验证补全修复非正常数据，自洽指的是通过不同数据源得出的结论是说得通可以互相验证的。</p>
<p>这一阶段技术细节比较多，本文不再深入。</p>
<h3 id="展示与应用"><a href="#展示与应用" class="headerlink" title="展示与应用"></a>展示与应用</h3><p>展示与应用是数据平台价值的外现，也是各个部门实际能够体验感知的部分。根据前面提出的『取代-超越』两步走思路，注定是一个比较耗费人力且业务导向的工作。</p>
<p>这就涉及到数据可视化和数据挖掘的内容了，等我多看些书，请教下相关领域老司机，经过一段时间再找各个部门反馈一下再来更新后续内容。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>能够从零开始参与公司数据平台的设计和建设，感觉自己非常幸运，同时也责任重大。而在具体实践中能够一点一点把自己在学校里所学的东西真正用起来，才算是真正完成了从书本到实践的最终转变。说『数据』的公司很多，但是真正用好『数据』的公司却不多，在我看来，数据平台的设计和开发，与其说是一个项目，不如说是火种。到底能不能燎原，就要看具体能推进到什么程度了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近大部分精力花在为公司搭建统一的数据平台上，在不断地踩坑中慢慢摸索出了一套行之有效的方法，本文主要介绍数据平台的流程设计与相关思考，具体的技术实现可以参考我的另一篇文章 - &lt;a href=&quot;http://wdxtub.com/2016/10/01/data-platform-tech-guide/&quot;&gt;数据平台技术指南&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="设计" scheme="http://wdxtub.com/tags/%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="数据" scheme="http://wdxtub.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>第十六周 - 林中鸟</title>
    <link href="http://wdxtub.com/2016/09/30/bird-in-forest/"/>
    <id>http://wdxtub.com/2016/09/30/bird-in-forest/</id>
    <published>2016-09-30T13:10:08.000Z</published>
    <updated>2016-09-30T15:01:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>来不及祈祷就开始奔跑，总觉得外面世界有多美好。角落太寂静城市太喧闹，这世界很忙其实我都知道。离开了地面就随风飘摇，决定要走遍天涯心比天高。</p>
<a id="more"></a>
<hr>
<p>这周应该是开始工作以来最忙的一周，为了迎接一年中最长的假期，多做点工作也是应该的。能在节前完成大部分计划好的任务，并且把服务器的稳定性提高到足以安心放假的水平，我对自己的表现还是很满意的，毕竟我已经爆发出了洪荒之力了。</p>
<p>因为负责另外一个项目的同事在欧洲玩耍，我临时帮忙维护对应的日常工作。上周风平浪静，本以为能够相安无事度过这周，却在周末就出了乱子，警报邮件和短信直接把收件箱发爆。既来之则安之，就硬着头皮上吧。</p>
<p>临时接班最痛苦的是需要在缺乏上下文的情况下快速搞清楚状况，并在出问题的时候准确定位及处理。虽说同事千叮咛万嘱咐，不过还是有之前没有遇到的突发情况，于是我开始了翻日志查资料调配置测集群的工作，在忐忐忑忑中找到了问题所在，并顺利解决。</p>
<p>工作中遇到的很多问题，光看错误日志其实是颇为头疼医头脚疼医脚的方法，如果不深挖下去找到根源，这样的技术债迟早会让团队破产。这个时候之前打下的比较牢固的基础就发挥了作用，从虚拟机配置到垃圾回收机制，从网络通信到集群优化，看起来可能只是一点点改动，但需要做的分析和排查工作非常多。这不由得让我想起一个故事，大意是机器坏了，高价请来的工程师敲了一下就好了，于是付钱的人觉得很亏，花这么多钱就只为了这一下。而工程师说百分之一的价钱是为了敲这一下，而另外百分之九十九是为了确定这一下要敲在哪里。很多看起来暂时没用的偏基础的知识，在融会贯通后就起到的是这百分之九十九的作用，不然像无头苍蝇一样瞎折腾，不但问题解决不了，甚至可能把情况弄得更糟。</p>
<p>在公司做新业务，大家都不懂，其实是很正常的，但是一定要在每次掉坑里爬出来后学到点什么。除了插个牌子告诉大家这里有坑之外，更需要依靠合理的规范铺成一条路，这样后面的才可能跑自行车、汽车、火车等等。一直是泥泞的土路，肯定行不通。</p>
<p>周二深夜，公司正式在纽约发布了之前泄露的『小飞机』Mavic，看到我司直接甩出一个吊打一切的产品，自己内心确实是骄傲的，而且之后我也会参与到提供给用户的相关服务的设计和开发，想到自己的努力能让大家玩得更开心，拍得更精彩，就觉得忙一点累一点其实也是很有意义的。在这里我想特别感谢一下硬件研发相关的同事，是他们长期不懈努力精益求精，才让 Mavic 能够一发布就取得如此叫好又叫座的成绩。要知道做硬件和做软件不同，很多时候需要配合工厂和供应链的节奏，每个时间点的设定，都是根据发布日期倒推的，卡得很死。如果到某个时间点没有达到预计的进度，除了耽误时间，更是会带来各种实实在在的成本。相比之下，软件开发是一个顺序的工作，延迟主要是时间成本，虽然看起来轻松一些，但是一想到其他同事这么努力，还是希望自己能够拿出对得起他们的努力的作品。</p>
<p>其实任何创造价值的事情，都不太可能是轻松的。当初编辑问我是走『著』还是『编著』路线的时候，年少轻狂觉得要『著』，真正创造一些价值，而不是编撰整理成为搬运工。『创造价值』是『实现价值』的升级，所谓实现价值，可能是完成一个功能，一个项目。但是创造价值，则是在完成工作的基础上，通过深入思考，勇于承担责任，找到可以把工作做得更好，辐射影响力的方法。</p>
<p>当初选择回国选择到大疆，一是对于螺丝钉式工作的厌恶，二是想真正用自己的能力去承担更多的责任，三是渴望接受更大的挑战。虽然当初自己也不知道将来会变成怎样，但是一步一步走过来，一个一个小目标竟也都达到了，果然从心的路，就是最好的路。</p>
<p>放假前和 Prisma（就是那个火遍全球的照片风格化应用）的 CEO 以及投资顾问聊了聊，才知道原来他们一共就八个人，其中只有俩做研究。虽然利用深度学习进行风格化早在一年前就有人做出来，不过能够把它优化到能在移动设备上跑，也是非常了不起的工作（尤其考虑到他们是小团队）。不由得想起之前把一个平滑算法移植到 iOS 时的艰难，为了优化性能真是无所不用其极，最后也仅仅做到了『可以接受』的程度。而在具体的沟通过程中，我也深深意识到了拥有核心竞争力以及底层开发能力是多么重要的财富，没有牛逼的技术，再怎么吹商业思维也没用。</p>
<p>回家的路上我开始思考如何进一步在有限的时间内提高效率。一个人的高效其实是有限的，可能拿一个成功团队和一个失败团队比较，两个团队里最厉害的人提供的输出可能是差不多的，之所以会一个天上一个地下，更多的差别在于团队，而不在于个体（虽然团队也是由个体组成的）。</p>
<p>所以如何是一个团队成为成功团队，才是高效的秘密所在。一个优秀的技术领导，是能够在面对复杂问题时，不会被习惯和情绪左右，而是专注于问题本身，利用常识做出正确的判断。而这种做事的方法是会『传染』的，团队成员也会以这种方式处理问题，自然就能获得极高的解决问题的效率。真正的成功团队一定是从一个个坑中爬出来，越磨练越强大的，不可能是上几节课看几个视频就可以搞定的。在实战中提高技艺，反思每天的工作，用联系的方式去观察和思考问题，才可能找到真正的开门钥匙。</p>
<p>不由得想起笑傲江湖里的一段话：</p>
<blockquote>
<p>死招数破得再妙，遇上了活招数，免不了缚手缚脚，只有任人屠戮。这个‘活’字，你要牢牢记住了。学招时要活学，使招时要活使。倘若拘泥不化，便练熟了几千万手绝招，遇上了真正高手，终究还是给人家破得干干净净。</p>
<p>活学活使，只是第一步。要做到出手无招，那才真是踏入了高手的境界。你说‘各招浑成，敌人便无法可破’，这句话还只说对了一小半。不是‘浑成’，而是根本无招。你的剑招使得再浑成，只要有迹可寻，敌人便有隙可乘。但如你根本并无招式，敌人如何来破你的招式？</p>
</blockquote>
<p>我就像那一只林中的小鸟，努力挣脱冲向蓝天怀抱。勇敢的张开双臂闭上了双眼，远方离我只有一步之遥。那带血的羽毛不向命运乞讨，跌倒只能让我越飞越高。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;来不及祈祷就开始奔跑，总觉得外面世界有多美好。角落太寂静城市太喧闹，这世界很忙其实我都知道。离开了地面就随风飘摇，决定要走遍天涯心比天高。&lt;/p&gt;
    
    </summary>
    
      <category term="Gossip" scheme="http://wdxtub.com/categories/Gossip/"/>
    
    
      <category term="周记" scheme="http://wdxtub.com/tags/%E5%91%A8%E8%AE%B0/"/>
    
      <category term="工作" scheme="http://wdxtub.com/tags/%E5%B7%A5%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 集群指南</title>
    <link href="http://wdxtub.com/2016/09/28/elasticsearch-cluster-guide/"/>
    <id>http://wdxtub.com/2016/09/28/elasticsearch-cluster-guide/</id>
    <published>2016-09-28T13:03:57.000Z</published>
    <updated>2016-09-28T13:04:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>Elasticsearch 集群的设置虽然比较简单，但是具体使用其实有很多需要注意的地方。本文结合工作中的实战经验，分享一下 Elasticsearch 集群的相关技巧。</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<ul>
<li>2016.09.28: 初稿完成，Elasticsearch 版本 2.4.0</li>
</ul>
<p>如果是第一次接触 Elasticsearch，不妨先看看我之前写的 <a href="http://wdxtub.com/2016/07/24/elastic-search-guide/">Elasticsearch 入门指南</a>，本文主要是介绍 Elasticsearch 集群相关的内容。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>虽然 Elasticsearch 的安装比较简单，不过我还是写了一个安装脚本，可以在<a href="https://github.com/wdxtub/wdxtools/tree/master/linux-script" target="_blank" rel="external">这里</a>查看，具体来说其实就两步，下载和解压，如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.4.0/elasticsearch-2.4.0.tar.gz</div><div class="line">tar -xvzf elasticsearch-2.4.0.tar.gz</div></pre></td></tr></table></figure>
<p>分别在集群中每台机器中完成安装即可，具体的启动也非常简单，如果要在前台，直接 <code>./bin/elasticsearch</code> 即可，如果要放到后台，则使用 <code>nohup ./bin/elasticsearch &amp;</code>。</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>配置文件位于 <code>config</code> 文件夹中，其中 <code>elasticsearch.yml</code> 是 elasticsearch 的配置，而 <code>logging.yml</code> 是输出日志相关的设置。配置文件的内容有很多，不过因为默认值基本都够用了，所以我们只需要配置很少的内容。假设现在有两个节点，内部 IP 地址分别为 <code>A: 10.1.1.0</code> 和 <code>B: 10.1.1.1</code>，那么配置为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># 节点 A</div><div class="line">cluster.name: wdxtubes</div><div class="line">node.name: &quot;es01&quot;</div><div class="line">bootstrap.mlockall: true</div><div class="line">network.host: 10.1.1.0</div><div class="line">network.publish_host: 10.1.1.0</div><div class="line">discovery.zen.ping.unicast.hosts: [&quot;10.1.1.1&quot;]</div><div class="line">discovery.zen.fd.ping_timeout: 120s</div><div class="line">discovery.zen.fd.ping_retries: 6</div><div class="line">discovery.zen.fd.ping_interval: 30s</div><div class="line"></div><div class="line"></div><div class="line"># 节点 B</div><div class="line">cluster.name: wdxtubes</div><div class="line">node.name: &quot;es02&quot;</div><div class="line">bootstrap.mlockall: true</div><div class="line">network.host: 10.1.1.1</div><div class="line">network.publish_host: 10.1.1.1</div><div class="line">discovery.zen.ping.unicast.hosts: [&quot;10.1.1.0&quot;]</div><div class="line">discovery.zen.fd.ping_timeout: 120s</div><div class="line">discovery.zen.fd.ping_retries: 6</div><div class="line">discovery.zen.fd.ping_interval: 30s</div></pre></td></tr></table></figure>
<p>这里需要注意的是我们采用单播的方式来进行集群中机器的查找，因为 elasticsearch 已经尽量帮我们做好了集群相关的工作，只要保证 <code>cluster.name</code> 一致，就可以自动发现。另外，我们调大了超时的间隔和互相 ping 发送的频率以及重试次数，防止某台机器在 Full GC 的时候因未能及时响应而造成的连锁反应（后面会详细说明）</p>
<p>多说一句，机器配置的时候，最好确保两台机器可以互相 ping 通，并开放所有端口的内部访问（如果是用云主机的话，尤其需要注意这一点）</p>
<p>如果需要扩展的话，只需要保证 <code>cluster.name</code> 一致即可，比如说现在新加入一台 <code>C: 10.1.1.2</code>，那么配置可以这么写</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># 节点 C</div><div class="line">cluster.name: wdxtubes</div><div class="line">node.name: &quot;es03&quot;</div><div class="line">bootstrap.mlockall: true</div><div class="line">network.host: 10.1.1.2</div><div class="line">network.publish_host: 10.1.1.2</div><div class="line">discovery.zen.ping.unicast.hosts: [&quot;10.1.1.0&quot;]</div><div class="line">discovery.zen.fd.ping_timeout: 120s</div><div class="line">discovery.zen.fd.ping_retries: 6</div><div class="line">discovery.zen.fd.ping_interval: 30s</div></pre></td></tr></table></figure>
<p>这里 <code>discovery.zen.ping.unicast.hosts</code> 中只需要填写原有集群中任意一台机器的地址即可。</p>
<p>然后我们可以在集群中的机器上使用 <code>curl http://10.1.1.0:9200/_cluster/health</code> 来查看集群状态。比如：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="attr">"cluster_name"</span>:<span class="string">"wdxtub-es"</span>,</div><div class="line">    <span class="attr">"status"</span>:<span class="string">"green"</span>,</div><div class="line">    <span class="attr">"timed_out"</span>:<span class="literal">false</span>,</div><div class="line">    <span class="attr">"number_of_nodes"</span>:<span class="number">2</span>,</div><div class="line">    <span class="attr">"number_of_data_nodes"</span>:<span class="number">2</span>,</div><div class="line">    <span class="attr">"active_primary_shards"</span>:<span class="number">821</span>,</div><div class="line">    <span class="attr">"active_shards"</span>:<span class="number">1642</span>,</div><div class="line">    <span class="attr">"relocating_shards"</span>:<span class="number">0</span>,</div><div class="line">    <span class="attr">"initializing_shards"</span>:<span class="number">0</span>,</div><div class="line">    <span class="attr">"unassigned_shards"</span>:<span class="number">0</span>,</div><div class="line">    <span class="attr">"delayed_unassigned_shards"</span>:<span class="number">0</span>,</div><div class="line">    <span class="attr">"number_of_pending_tasks"</span>:<span class="number">0</span>,</div><div class="line">    <span class="attr">"number_of_in_flight_fetch"</span>:<span class="number">0</span>,</div><div class="line">    <span class="attr">"task_max_waiting_in_queue_millis"</span>:<span class="number">0</span>,</div><div class="line">    <span class="attr">"active_shards_percent_as_number"</span>:<span class="number">100.0</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果状态是 green，那就没有问题啦。下面我们会结合不同的实例进行介绍</p>
<h2 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h2><p>Elasticsearch 的重启是一个非常需要按规矩操作的过程，否则会带来一系列的意想不到的问题，所以一定要按照官方建议的步骤来进行。</p>
<p>首先，因为 Elasticsearch 自带的高可用机制，一旦一个节点下线，就会在集群内部进行数据的重分配，会带来很多不必要的开销，所以需要先关闭，关闭方法是给集群发送一个请求，这个请求可以动态修改集群的设置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">PUT /_cluster/settings</div><div class="line">&#123;</div><div class="line">  &quot;persistent&quot;: &#123;</div><div class="line">    &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>而在重启之后需要进行数据恢复，如果停止索引并发送一个同步刷新请求，这个过程就会快很多，需要注意的是，如果此时有任何正在进行的索引操作，这个 flush 操作会失败，因此必要时我们可以重试多次，这是安全的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">POST /_flush/synced</div></pre></td></tr></table></figure>
<p>现在我们可以停止集群中的各个节点，完成重启或升级的操作。具体单台机器的操作可以看<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/rolling-upgrades.html#upgrade-node" target="_blank" rel="external">这里</a></p>
<p>完成之后，我们最好先启动那些 <code>node.master</code> 设置为 true 的节点（这也是默认设置），等到集群选举出了 master 节点，就可以继续添加数据节点了（即那些 <code>node.master</code> 为 false 且 <code>node.data</code> 为 true 的），这里我们可以用以下方式进行监控</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">GET _cat/health</div><div class="line"></div><div class="line">GET _cat/nodes</div></pre></td></tr></table></figure>
<p>每个节点加入集群之后，就会开始恢复本地保存的首要分片，一开始 <code>_cat/health</code> 查询的结果是 red，之后会变成 yellow，也就意味着所有的首要分片已经恢复了，但是其他的复制分片还没有恢复，因为我们一开始已经设置不恢复复制分片。</p>
<p>最后一步，我们需要重新开启集群的数据重分配，以保证集群的高可用性，操作也很简单：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">PUT /_cluster/settings</div><div class="line">&#123;</div><div class="line">  &quot;persistent&quot;: &#123;</div><div class="line">    &quot;cluster.routing.allocation.enable&quot;: &quot;all&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>当使用 <code>_cat/health</code> 的结果为 green 时，则重启和恢复顺利完成。</p>
<h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p>无论是 Elasticsearch 官方还是社区，有很多插件可以完成监控的任务，但是本文只介绍默认的 API，主要是 <code>_cat</code> 和 <code>_cluster</code> 这两个接口，具体的文档可以在 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/cat.html" target="_blank" rel="external">cat API</a> 和 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster.html" target="_blank" rel="external">cluster API</a> 中查看，这里简要介绍一下。</p>
<p>对于 <code>_cat</code> 接口，在请求后面加上 <code>?v</code> 就会输出详细信息，例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ curl 10.1.1.10:9200/_cat/master?v</div><div class="line">id                     host      ip        node   </div><div class="line">AoVFmiU4Q2SAHNVcMGPsWQ 10.1.1.11 10.1.1.11 node-2</div></pre></td></tr></table></figure>
<p>如果对于字段的名字有疑问，可以使用 <code>?help</code>，例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ curl 10.1.1.10:9200/_cat/master?<span class="built_in">help</span></div><div class="line">id   |   | node id    </div><div class="line">host | h | host name  </div><div class="line">ip   |   | ip address </div><div class="line">node | n | node name</div></pre></td></tr></table></figure>
<p>如果只想要查看指定字段，可以利用 <code>?h=</code> 来进行指定，例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ curl 10.1.1.10:9200/_cat/nodes?h=ip,port,heapPercent,name</div><div class="line">10.1.1.11 9300 64 node-2 </div><div class="line">10.1.1.10 9300 71 node-1</div></pre></td></tr></table></figure>
<p>对于带数字的输出，可以利用管道来进行排序，比如下面的命令就可以按照索引大小来进行排序（这里的 <code>-rnk8</code> 指的是按照第八列排序）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ curl 10.1.1.10:9200/_cat/indices?bytes=b | sort -rnk8</div><div class="line">green open slog-2016-09-11   5 1 9729152      0 11128793222 5564396611 </div><div class="line">green open slog-2016-09-12   5 1 8355880      0  9539380440 4769690220 </div><div class="line">green open slog-2016-09-25   5 1 6720954      0  7415719218 3707859609 </div><div class="line">green open slog-2016-09-19   5 1 5840177      0  6575155002 3287577501 </div><div class="line">green open slog-2016-09-10   5 1 5858916      0  6504251544 3252125772</div></pre></td></tr></table></figure>
<p>其他比较常用的命令如下所示，具体的可以参阅文档，这里不再赘述：</p>
<ul>
<li><code>_cat/count</code> 文档总数</li>
<li><code>_cat/count/[index_name]</code> 某个索引的文档总数</li>
<li><code>_cat/fielddata?v</code> 显示每个节点的字段的堆内存使用量</li>
<li><code>_cat/health?v</code> 节点的健康状况<ul>
<li>可以使用下面的命令来自动检查集群状况</li>
<li><code>while true; do curl localhost:9200/_cat/health; sleep 120; done</code></li>
</ul>
</li>
<li><code>_cat/indices?v</code> 查看每个索引的详细信息，配合管道命令可以有很多应用，比如<ul>
<li>找出所有状态为 yellow 的索引 <code>curl localhost:9200/_cat/indices | grep ^yell</code></li>
<li>排序 <code>curl &#39;localhost:9200/_cat/indices?bytes=b&#39; | sort -rnk8</code></li>
<li>指定列及内存使用状况 <code>curl &#39;localhost:9200/_cat/indices?v&amp;h=i,tm&#39;</code></li>
</ul>
</li>
<li><code>_cat/nodes</code> 展示集群的拓扑结构</li>
<li><code>_cat/pending_tasks?v</code> 显示正在排队的任务</li>
<li><code>_cat/recovery?v</code> 显示分片恢复的过程</li>
<li><code>_cat/thread_pool?v</code> 显示线程池相关信息，有很多信息，可以根据需要进行查询</li>
<li><code>_cat/shards?v</code> 显示分片的相关信息</li>
<li><code>_cat/shards/[index-name]</code> 显示指定索引的分片信息  </li>
</ul>
<p><code>_cluster</code> 的接口的用法和 <code>_cat</code> 类似，这里就不再赘述了。</p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><h3 id="合理计划服务器"><a href="#合理计划服务器" class="headerlink" title="合理计划服务器"></a>合理计划服务器</h3><p>在 Elasticsearch 的配置文件中，可以根据两个配置(<code>node.master</code> 和 <code>node.data</code>)选项来分配不同节点的角色，以达到提高服务器性能的目的。</p>
<ul>
<li><code>node.master: false; node.data: true</code> - 该节点只作为数据节点，用于存储和查询，资源消耗会较低</li>
<li><code>node.master: true; node.data: false</code> - 该节点只作为 master 节点，不存储数据，主要负责协调索引请求和查询请求</li>
<li><code>node.master: false; node.data: falst</code> - 该节点不作为 master 节点，也不存储数据，主要用于查询时的负载均衡（做结果汇总等工作）</li>
</ul>
<p>另外，一台服务器最好只部署一个节点以维持服务器稳定，毕竟资源是有限的，多开也没啥</p>
<h3 id="数据节点就是数据节点"><a href="#数据节点就是数据节点" class="headerlink" title="数据节点就是数据节点"></a>数据节点就是数据节点</h3><p>如果有配置数据节点，那么可以关闭其 http 功能，让它专注于索引的操作。插件之类的也最好安装到非数据节点服务器上，这样是一个兼顾数据安全和服务器性能的考虑。具体的配置项是 <code>http.enabled: false</code></p>
<h3 id="线程池配置"><a href="#线程池配置" class="headerlink" title="线程池配置"></a>线程池配置</h3><p>针对 Elasticsearch 的不同操作，可以配置不同大小的线程池，这个需要根据业务需求确定最佳值，场景的操作有：index, search, suggest, get, bulk, percolate, snapshot, snapshot_data, warmer, refresh。</p>
<p>这里以 index(创建/更新/删除索引数据)和 search(搜索操作)为例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">threadpool:</div><div class="line">     index:</div><div class="line">         type: fixed</div><div class="line">         size: 24（逻辑核心数*3）</div><div class="line">         queue_ size: 1000</div><div class="line"> </div><div class="line">     search:</div><div class="line">         type: fixed</div><div class="line">         size: 24（逻辑核心数*3）</div><div class="line">         queue_ size: 1000</div></pre></td></tr></table></figure>
<h3 id="分片与副本"><a href="#分片与副本" class="headerlink" title="分片与副本"></a>分片与副本</h3><p>默认的参数是 5 个分片(shard)和 1 个副本(replica)，碎片数目越多，索引速度越快；副本数目越多，搜索能力及可用性更高。分片的数目是在一开始就设定好的，但是副本的数目是可以后期修改的。</p>
<p>而在恢复数据的时候，可以先减少分片刷新索引的时间间隔，如</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">curl -XPUT <span class="string">'http://10.1.1.0:9200/_settings'</span> <span class="_">-d</span> <span class="string">'&#123; </span></div><div class="line">    "index" : &#123; </div><div class="line">        "refresh_interval" : "-1" </div><div class="line">    &#125; </div><div class="line">&#125;'</div></pre></td></tr></table></figure>
<p>完成插入之后再恢复</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">curl -XPUT <span class="string">'http://10.1.1.0:9200/_settings'</span> <span class="_">-d</span> <span class="string">'&#123; </span></div><div class="line">    "index" : &#123; </div><div class="line">        "refresh_interval" : "1s" </div><div class="line">    &#125; </div><div class="line">&#125;'</div></pre></td></tr></table></figure>
<h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><p>查询中最重要的思路就是 routing，尽量减少慢查询的次数。而当索引越来越大的时候，每个分片也会增大，查询速度就会变慢。一个可行的解决思路就是分索引，比方说不同类型的数据利用不同的 routing 进行分离。</p>
<p>还有一个从业务出发的思路，就是不索引不需要的字段，这样就可以减小集群所需资源的量。</p>
<h3 id="JVM-设置"><a href="#JVM-设置" class="headerlink" title="JVM 设置"></a>JVM 设置</h3><p>关于 JVM 的设置我还在摸索中，不过有几个技巧：</p>
<ul>
<li>JVM 的堆大小不要超过 32G，来源 <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html#compressed_oops" target="_blank" rel="external">Don’t Cross 32 GB!</a></li>
<li>使用 <code>bootstrap.mlockall: true</code>，启动时就锁定内存</li>
<li>用较小的 heapsize 配合 SSD</li>
</ul>
<h2 id="排查"><a href="#排查" class="headerlink" title="排查"></a>排查</h2><p>这里以一个实例来介绍我是如何在生产环境中排查和修复 Elasticsearch 集群忽然响应时间剧增的问题的。</p>
<p>情况是这样的，随着接入 Elasticsearch 的数据量增大，忽然有一个周末出问题了 - ES 集群的查询和插入都变得巨慢无比。监控报警都把邮箱和手机发爆炸了。</p>
<p>那么问题来了，究竟是哪里出了乱子？</p>
<p>因为发送数据的客户端和服务器近期并没有特别大的改动，我检查了 Kafka 队列也一切正常，于是可以锁定问题出在 Elasticsearch 身上。</p>
<p>第一反应就是先去看 Elasticsearch 的日志，发现根据日志显示，一致在不停的垃圾回收。因此对症下药，把 JVM 的堆内存改大。但是在集群重启之后仍然会出现性能急剧下降的状况，于是继续检查日志，发现是因为 JVM 进行 Full GC 的时间过长，导致 ES 集群认为拓扑结构改变，开始迁移数据所导致。而迁移数据本身又会导致 Full GC，让情况更糟的是，在 Full GC 结束之后，集群的拓扑结构又再次改变，于是就陷入了这样的死循环。</p>
<p>破局的方法其实非常简单粗暴，把检测集群拓扑的时间间隔和超时次数加大一点，留足够的时间给 JVM 进行 Full GC 即可。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>经历了一次事故排查之后，我对 Elasticsearch 集群的相关认识也达到了比较深的程度，虽然在黑暗中探索的那两天很痛苦，不过总算是走出来了，于是赶紧把经验分享出来，这样大家可以少走弯路。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="https://my.oschina.net/shyloveliyi/blog/653751" target="_blank" rel="external">elasticsearch2.3.1 集群安装</a></li>
<li><a href="http://zhousheng29.iteye.com/blog/2101905" target="_blank" rel="external">ElasticSearch优化的一些方法</a></li>
<li><a href="http://chuansong.me/n/1610745" target="_blank" rel="external">亿级规模的Elasticsearch优化实战</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/restart-upgrade.html" target="_blank" rel="external">Full cluster restart upgrade</a></li>
<li><a href="https://www.loggly.com/blog/nine-tips-configuring-elasticsearch-for-high-performance/" target="_blank" rel="external">9 Tips on ElasticSearch Configuration for High Performance</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Elasticsearch 集群的设置虽然比较简单，但是具体使用其实有很多需要注意的地方。本文结合工作中的实战经验，分享一下 Elasticsearch 集群的相关技巧。&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="技巧" scheme="http://wdxtub.com/tags/%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Elasticsearch" scheme="http://wdxtub.com/tags/Elasticsearch/"/>
    
      <category term="集群" scheme="http://wdxtub.com/tags/%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>Linux 服务器检查指南</title>
    <link href="http://wdxtub.com/2016/09/28/linux-server-check-guide/"/>
    <id>http://wdxtub.com/2016/09/28/linux-server-check-guide/</id>
    <published>2016-09-28T11:48:04.000Z</published>
    <updated>2016-09-28T14:13:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>服务器有时候像一个爱哭爱闹的小宝宝，能听到它在哭，但如果不够熟悉的话，一时半会儿还真不知道到底是为啥而哭。本文结合自己工作中的一些经验，给出一些检查服务器运行状况的通用技巧。</p>
<a id="more"></a>
<hr>
<p>注，章节名称源自英雄联盟中盲僧李青的技能。</p>
<p>更新历史：</p>
<ul>
<li>2016.09.28: 完成初稿</li>
</ul>
<h2 id="天音波-回音击"><a href="#天音波-回音击" class="headerlink" title="天音波/回音击"></a>天音波/回音击</h2><h3 id="htop"><a href="#htop" class="headerlink" title="htop"></a>htop</h3><p>最基本的招式就是 <code>htop</code> 了，基本囊括了各种信息（一般系统默认是 <code>top</code>）</p>
<p><img src="/images/14750633917258.jpg" alt=""></p>
<p>观察一段时间大概能对服务器的基本状态有一个认知，可以比较直观找出占用 CPU 和内存的应用。这里简单说明一下如何利用这些数据。</p>
<p>右上角的信息也可以通过 <code>uptime</code> 进行查看，比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ uptime</div><div class="line">06:49:47 up 49 days,  2:29,  1 user,  load average: 0.21, 0.13, 0.19</div></pre></td></tr></table></figure>
<p>最后的三个数字表示 1 分钟、5 分钟和 15 分钟的平均负载，一般来说 0.7 是一个警戒线（对于单核来说）。从图中我们可以看到该服务器有 4 个核心，所以负载的数值超过 1 都是很正常的。</p>
<h3 id="free"><a href="#free" class="headerlink" title="free"></a>free</h3><p>我们可以使用 <code>free -m</code> 来以 mb 为单位查看内存使用情况，如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ free -m</div><div class="line">             total       used       free     shared    buffers     cached</div><div class="line">Mem:         16047      15871        176          0        217       9436</div><div class="line">-/+ buffers/cache:       6217       9830</div><div class="line">Swap:            0          0          0</div></pre></td></tr></table></figure>
<p>虽然看起来 free 部分内存很少，但是第二行表示大部分内存是被缓存占用的，是 Linux 尽量利用内存的正常现象。这里只要注意 swap 的数值为 0 即可，否则频繁使用交换区充当内存，会明显降低系统性能。</p>
<h2 id="金钟罩-铁布衫"><a href="#金钟罩-铁布衫" class="headerlink" title="金钟罩/铁布衫"></a>金钟罩/铁布衫</h2><h3 id="dmesg"><a href="#dmesg" class="headerlink" title="dmesg"></a>dmesg</h3><p><code>dmesg</code> 输出系统日志，不过比较杂也比较难看懂</p>
<h3 id="vmstat"><a href="#vmstat" class="headerlink" title="vmstat"></a>vmstat</h3><p><code>vmstat 1</code> 每行会输出一些系统核心指标（后面的数字表示每隔 1 秒输出一次）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ vmstat 1</div><div class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</div><div class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   <span class="keyword">in</span>   cs us sy id wa st</div><div class="line"> 1  0      0 341460 220212 9530820    0    0    10   436    1    1  8  1 86  5  0</div><div class="line"> 0  0      0 341452 220212 9530820    0    0     0 10412  580  681  0  0 99  0  0</div><div class="line"> 0  0      0 341420 220212 9530820    0    0     0     0  371  693  0  0 100  0  0</div><div class="line"> 0  0      0 341420 220212 9530820    0    0     0     0  389  737  0  0 100  0  0</div><div class="line"> 1  0      0 339320 220212 9532844    0    0     0  9020 9561 8007 15  4 70 11  0</div><div class="line"> 0  0      0 335616 220212 9536784    0    0     0     0 1149 1295  6  1 93  0  0</div><div class="line"> 0  0      0 339984 220212 9532188    0    0     0  5428  581  832  0  0 100  0  0</div></pre></td></tr></table></figure>
<p>具体介绍一下几个特别需要关注的指标：</p>
<ul>
<li><code>r</code> 值，在等待 CPU 资源的进程数（不包含等待 IO 的进程），如果这个数值大于 CPU 的核心数目，就说明 CPU 资源已饱和</li>
<li><code>free</code> 值，可用的内存大小（单位: KB）</li>
<li><code>si</code> 与 <code>so</code> 值，交换区写入和读取的数量，如果不为 0，则说明系统在使用 swap 空间，物理内存不足</li>
<li><code>us</code>, <code>sy</code>, <code>id</code>, <code>wa</code>, <code>st</code> 值，表示用户时间(user)，系统时间(system)，空闲时间(idle)，IO 等待时间(wait)和被偷走的时间(stolen，一般被其他虚拟机消耗)</li>
</ul>
<p>如果用户时间和系统时间相加比较大，则 CPU 忙于执行指令，如果 IO 等待时间很长，那么系统的瓶颈在磁盘 IO。</p>
<h3 id="pidstat"><a href="#pidstat" class="headerlink" title="pidstat"></a>pidstat</h3><p>需要先安装 <code>sudo apt install sysstat</code>，然后使用 <code>pidstat 1</code> 可以查看进程的 CPU 占用率</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ pidstat 3</div><div class="line">Linux 3.13.0-91-generic      09/26/2016      _x86_64_        (4 CPU)</div><div class="line"></div><div class="line">07:16:38 AM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</div><div class="line">07:16:41 AM     0         7    0.00    0.33    0.00    0.33     2  rcu_sched</div><div class="line"></div><div class="line">07:16:41 AM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</div><div class="line">07:16:44 AM  1001     20573    0.00    0.33    0.00    0.33     2  pidstat</div><div class="line"></div><div class="line">07:16:44 AM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</div><div class="line">07:16:47 AM     0        10    0.00    0.33    0.00    0.33     1  rcuos/2</div><div class="line">07:16:47 AM     0       386    0.00    0.33    0.00    0.33     1  jbd2/dm-0-8</div><div class="line">07:16:47 AM  1001     13003    0.00    0.67    0.00    0.67     0  nginx</div><div class="line">07:16:47 AM  1001     13004    0.00    0.67    0.00    0.67     1  nginx</div><div class="line">07:16:47 AM  1001     13005    0.67    0.67    0.00    1.33     2  nginx</div><div class="line">07:16:47 AM  1001     13006    0.67    0.00    0.00    0.67     3  nginx</div><div class="line">07:16:47 AM  1001     22179    0.33    0.00    0.00    0.33     1  node</div><div class="line"></div><div class="line">07:16:47 AM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</div><div class="line">07:16:50 AM  1001     19021    0.33    0.33    0.00    0.67     1  sshd</div><div class="line">07:16:50 AM  1001     20573    0.00    0.33    0.00    0.33     2  pidstat</div><div class="line"></div><div class="line">07:16:50 AM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</div><div class="line">07:16:53 AM     0         8    0.00    0.33    0.00    0.33     2  rcuos/0</div><div class="line">07:16:53 AM     0       386    0.00    0.33    0.00    0.33     1  jbd2/dm-0-8</div><div class="line">07:16:53 AM  1001      3408   76.33    8.33    0.00   84.67     3  java</div><div class="line">07:16:53 AM  1001     13003    0.00    0.67    0.00    0.67     0  nginx</div><div class="line">07:16:53 AM  1001     13005    0.67    0.67    0.00    1.33     2  nginx</div><div class="line">07:16:53 AM  1001     13006    0.33    0.33    0.00    0.67     3  nginx</div><div class="line">07:16:53 AM  1001     22179    0.00    0.33    0.00    0.33     0  node</div><div class="line"></div><div class="line">07:16:53 AM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</div><div class="line">07:16:56 AM  1001      3408    1.00    0.00    0.00    1.00     3  java</div><div class="line">07:16:56 AM  1001     20573    0.00    0.33    0.00    0.33     2  pidstat</div><div class="line">^C</div><div class="line"></div><div class="line">Average:      UID       PID    %usr %system  %guest    %CPU   CPU  Command</div><div class="line">Average:        0         7    0.00    0.06    0.00    0.06     -  rcu_sched</div><div class="line">Average:        0         8    0.00    0.06    0.00    0.06     -  rcuos/0</div><div class="line">Average:        0        10    0.00    0.06    0.00    0.06     -  rcuos/2</div><div class="line">Average:        0       386    0.00    0.11    0.00    0.11     -  jbd2/dm-0-8</div><div class="line">Average:     1001      3408   12.89    1.39    0.00   14.28     -  java</div><div class="line">Average:     1001     13003    0.00    0.22    0.00    0.22     -  nginx</div><div class="line">Average:     1001     13004    0.00    0.11    0.00    0.11     -  nginx</div><div class="line">Average:     1001     13005    0.22    0.22    0.00    0.44     -  nginx</div><div class="line">Average:     1001     13006    0.17    0.06    0.00    0.22     -  nginx</div><div class="line">Average:     1001     19021    0.06    0.06    0.00    0.11     -  sshd</div><div class="line">Average:     1001     20573    0.00    0.17    0.00    0.17     -  pidstat</div><div class="line">Average:     1001     22179    0.06    0.06    0.00    0.11     -  node</div></pre></td></tr></table></figure>
<p>这个命令的好处是不会覆盖之前的数据，我们能够方便地观察系统动态。</p>
<h3 id="iostat"><a href="#iostat" class="headerlink" title="iostat"></a>iostat</h3><p>可以使用 <code>iostat -xz 1</code> 来查看机器磁盘 IO 情况，如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ iostat -xz 1</div><div class="line">Linux 3.13.0-91-generic       09/26/2016      _x86_64_        (4 CPU)</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           8.01    0.00    0.71    5.04    0.02   86.22</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">xvda              0.00     0.20    0.07    0.34     1.70     3.60    26.23     0.00    1.43    1.06    1.50   0.24   0.01</div><div class="line">xvdb              0.00   158.04    1.76   47.14    28.13  1289.27    53.89     0.16    3.21    3.49    3.20   0.71   3.49</div><div class="line">dm-0              0.00     0.00    2.48  228.71    37.46  1732.41    15.31     0.06    0.24    7.13    0.17   0.56  12.89</div><div class="line">xvdf              0.00     1.19    0.72   22.34     9.33   443.14    39.24     0.58   24.94   15.99   25.23   4.28   9.87</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           0.00    0.00    0.00    0.00    0.00  100.00</div><div class="line"></div><div class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</div><div class="line">xvdb              0.00   143.00    0.00    6.00     0.00   596.00   198.67     0.00    0.00    0.00    0.00   0.00   0.00</div><div class="line">dm-0              0.00     0.00    0.00  149.00     0.00   596.00     8.00     0.00    0.00    0.00    0.00   0.00   0.00</div><div class="line"></div><div class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</div><div class="line">           0.25    0.00    0.00    0.00    0.00   99.75</div></pre></td></tr></table></figure>
<ul>
<li><code>r/s</code>, <code>w/s</code>, <code>rkB/s</code>, <code>wkB/s</code> 表示每秒的读写次数和每秒读写的数据量，如果过大会引起性能问题</li>
<li><code>await</code> 是 IO 操作的平均等待时间，如果数据异常增大，可能是硬件出了问题</li>
<li><code>avgqu-sz</code> 是向设备发出的平均请求数量，大于 1 一般是硬件设备已饱和的表现</li>
<li><code>%util</code> 是设备利用率，如果超过 60 就可能会影响 IO 性能</li>
</ul>
<h2 id="天雷破-摧筋断骨"><a href="#天雷破-摧筋断骨" class="headerlink" title="天雷破/摧筋断骨"></a>天雷破/摧筋断骨</h2><h3 id="sar"><a href="#sar" class="headerlink" title="sar"></a>sar</h3><p><code>sar -n DEV 1</code> 用来查看网络设备的吞利率，如</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub@spro-usa-elasticsearch01:~$ sar -n DEV 1</div><div class="line">Linux 3.13.0-91-generic (spro-usa-elasticsearch01)      09/26/2016      _x86_64_        (4 CPU)</div><div class="line"></div><div class="line">07:49:06 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil</div><div class="line">07:49:07 AM      eth0      2.00      0.00      0.13      0.00      0.00      0.00      0.00      0.00</div><div class="line">07:49:07 AM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</div><div class="line"></div><div class="line">07:49:10 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil</div><div class="line">07:49:11 AM      eth0    289.00    214.00    202.80     60.45      0.00      0.00      0.00      0.12</div><div class="line">07:49:11 AM        lo    206.00    206.00    180.29    180.29      0.00      0.00      0.00      0.00</div><div class="line"></div><div class="line">07:49:15 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil</div><div class="line">07:49:16 AM      eth0   2364.00   1723.00   1488.95    459.65      0.00      0.00      0.00      0.87</div><div class="line">07:49:16 AM        lo   1771.00   1771.00   1101.98   1101.98      0.00      0.00      0.00      0.00</div><div class="line"></div><div class="line">Average:        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil</div><div class="line">Average:         eth0    275.37    204.90    176.24     93.42      0.00      0.00      0.00      0.10</div><div class="line">Average:           lo    204.82    204.82    137.94    137.94      0.00      0.00      0.00      0.00</div></pre></td></tr></table></figure>
<p>可以看到网络流量的波动特别大，但是远没有到达瓶颈，所以可能是其他的问题，需要继续排查。</p>
<p><code>sar -n TCP,ETCP 1</code> 用来查看 TCP 连接的状态，如</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub@spro-usa-elasticsearch01:~$ sar -n TCP,ETCP 1</div><div class="line">Linux 3.13.0-91-generic (spro-usa-elasticsearch01)      09/26/2016      _x86_64_        (4 CPU)</div><div class="line"></div><div class="line">07:52:50 AM  active/s passive/s    iseg/s    oseg/s</div><div class="line">07:52:51 AM      0.00      0.00      2.00      0.00</div><div class="line"></div><div class="line">07:52:50 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s</div><div class="line">07:52:51 AM      0.00      0.00      0.00      0.00      0.00</div><div class="line"></div><div class="line">07:52:54 AM  active/s passive/s    iseg/s    oseg/s</div><div class="line">07:52:55 AM    176.00    339.00   4046.00   3443.00</div><div class="line"></div><div class="line">07:52:54 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s</div><div class="line">07:52:55 AM      0.00      0.00      0.00      0.00      0.00</div><div class="line"></div><div class="line">07:52:57 AM  active/s passive/s    iseg/s    oseg/s</div><div class="line">07:52:58 AM      4.00      4.00     32.00     32.00</div><div class="line"></div><div class="line">07:52:57 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s</div><div class="line">07:52:58 AM      0.00      0.00      0.00      0.00      0.00</div><div class="line"></div><div class="line">Average:     active/s passive/s    iseg/s    oseg/s</div><div class="line">Average:        21.48     41.25    495.45    422.05</div><div class="line"></div><div class="line">Average:     atmptf/s  estres/s retrans/s isegerr/s   orsts/s</div><div class="line">Average:         0.00      0.00      0.00      0.00      0.00</div></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li><code>active/s</code> 是每秒本地发起的 TCP 连接数目，即 <code>connect</code></li>
<li><code>passive/s</code> 是每秒远程发起的 TCP 连接数目，即 <code>accept</code></li>
<li><code>retrans/s</code> 每秒 TCP 重传数量</li>
</ul>
<h2 id="猛龙摆尾"><a href="#猛龙摆尾" class="headerlink" title="猛龙摆尾"></a>猛龙摆尾</h2><p>虽然现在各种框架和服务器基本已经帮我们处理好了 JVM 相关事宜，不过有些时候出了比较奇怪的问题，还是需要深入到 JVM 内部才能找到问题根源（最近我就经历了这样一次排查），下面是相关的一些命令指南。</p>
<h3 id="jps"><a href="#jps" class="headerlink" title="jps"></a>jps</h3><p>输出 JVM 中运行的进程状态信息，比如 <code>jps -m -l</code>，会输出传入 main 方法的参数和类的全名，如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub@:~$ jps -m <span class="_">-l</span></div><div class="line">21843 org.elasticsearch.bootstrap.Elasticsearch start</div><div class="line">23012 sun.tools.jps.Jps -m <span class="_">-l</span></div></pre></td></tr></table></figure>
<h3 id="jstack"><a href="#jstack" class="headerlink" title="jstack"></a>jstack</h3><p>用来查看某个 Java 进程内的线程堆栈信息。比较常用的还是 <code>-m</code> 和 <code>-l</code> 选项，其中 <code>-m</code> 会输出 Java 及 C/C++ 的堆栈信息，而 <code>-l</code> 是会打印出额外的锁信息。</p>
<p>我们可以 <code>htop</code> 查看进程信息，随手找一个 Java 应用，比方说 elasticsearch，对应的 pid 是 32346(不同机器不一样)。当然，也可以使用命令 <code>ps -ef | grep elasticsearch | grep -v grep</code>。</p>
<p>然后我们可以看看这个进程内最吃 CPU 的线程，可以用的命令比较多，比如：<code>ps -Lfp 32346</code>, <code>ps -mp 32346 -o THREAD,tid,time | sort</code> 或 <code>top -Hp 32346</code></p>
<p>我们这里使用 <code>ps -mp 32346 -o THREAD,tid,time | sort</code>，排序之后的结果是</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub    0.4  19    - futex_    -      -   571 00:05:31</div><div class="line">wdxtub    0.6  19    - futex_    -      - 32374 00:08:57</div><div class="line">wdxtub    0.7  19    - futex_    -      - 32452 00:10:48</div><div class="line">wdxtub    0.7  19    - futex_    -      - 32642 00:11:01</div><div class="line">wdxtub    0.8  19    - futex_    -      - 18940 00:07:26</div><div class="line">wdxtub    0.8  19    - futex_    -      - 32412 00:11:27</div><div class="line">wdxtub    0.8  19    - futex_    -      -   471 00:11:31</div><div class="line">wdxtub    0.8  19    - futex_    -      -   472 00:11:15</div><div class="line">wdxtub    0.9  19    - futex_    -      - 32650 00:13:03</div><div class="line">wdxtub   28.5   -    - -         -      -     - 06:36:47</div><div class="line">USER     %CPU PRI SCNT WCHAN  USER SYSTEM   TID     TIME</div></pre></td></tr></table></figure>
<p>我们这里记录下最耗费时间的线程，编号为 32650，转换成十六进制为 <code>0x7f8a</code>，然后就可以查看最耗费时间的代码了，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ jstack 32346 | grep 7f8a</div><div class="line"><span class="string">"elasticsearch[node-2][refresh][T#2]"</span> <span class="comment">#279 daemon prio=5 os_prio=0 tid=0x00007fd39447a000 nid=0x7f8a waiting on condition [0x00007fd147d2c000]</span></div></pre></td></tr></table></figure>
<p>可以看到这里是在等待某个条件，不过因为 elasticsearch 的代码无法直接看到，这里就不能找找具体的原因了。</p>
<h3 id="jmap-与-jhat"><a href="#jmap-与-jhat" class="headerlink" title="jmap 与 jhat"></a>jmap 与 jhat</h3><p><code>jmap</code> 是 Java Memory Map，用来查看堆内存使用状况，而 <code>jhat</code> 是 Java Heap Analysis Tool，正好就是用来分析堆内存。这里我们尝试几个命令来看看效果：</p>
<p><code>jmap -heap pid</code> 查看堆内存使用情况，包括使用的GC算法、堆配置参数和各代中堆内存使用情况，一个例子如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ jmap -heap 8183    </div><div class="line">Attaching to process ID 8183, please wait...</div><div class="line">Debugger attached successfully.</div><div class="line">Server compiler detected.</div><div class="line">JVM version is 25.102-b14</div><div class="line"></div><div class="line">using thread-local object allocation.</div><div class="line">Parallel GC with 4 thread(s)</div><div class="line"></div><div class="line">Heap Configuration:</div><div class="line">   M<span class="keyword">in</span>HeapFreeRatio         = 0</div><div class="line">   MaxHeapFreeRatio         = 100</div><div class="line">   MaxHeapSize              = 1073741824 (1024.0MB)</div><div class="line">   NewSize                  = 357564416 (341.0MB)</div><div class="line">   MaxNewSize               = 357564416 (341.0MB)</div><div class="line">   OldSize                  = 716177408 (683.0MB)</div><div class="line">   NewRatio                 = 2</div><div class="line">   SurvivorRatio            = 8</div><div class="line">   MetaspaceSize            = 21807104 (20.796875MB)</div><div class="line">   CompressedClassSpaceSize = 1073741824 (1024.0MB)</div><div class="line">   MaxMetaspaceSize         = 17592186044415 MB</div><div class="line">   G1HeapRegionSize         = 0 (0.0MB)</div><div class="line"></div><div class="line">Heap Usage:</div><div class="line">PS Young Generation</div><div class="line">Eden Space:</div><div class="line">   capacity = 335544320 (320.0MB)</div><div class="line">   used     = 334734664 (319.2278518676758MB)</div><div class="line">   free     = 809656 (0.7721481323242188MB)</div><div class="line">   99.75870370864868% used</div><div class="line">From Space:</div><div class="line">   capacity = 11010048 (10.5MB)</div><div class="line">   used     = 8929984 (8.51629638671875MB)</div><div class="line">   free     = 2080064 (1.98370361328125MB)</div><div class="line">   81.10758463541667% used</div><div class="line">To Space:</div><div class="line">   capacity = 11010048 (10.5MB)</div><div class="line">   used     = 0 (0.0MB)</div><div class="line">   free     = 11010048 (10.5MB)</div><div class="line">   0.0% used</div><div class="line">PS Old Generation</div><div class="line">   capacity = 716177408 (683.0MB)</div><div class="line">   used     = 439459664 (419.1013946533203MB)</div><div class="line">   free     = 276717744 (263.8986053466797MB)</div><div class="line">   61.361844019519815% used</div><div class="line"></div><div class="line">20959 interned Strings occupying 2601056 bytes.</div></pre></td></tr></table></figure>
<p>使用 <code>jmap -histo[:live] pid</code> 查看堆内存中的对象数目、大小统计直方图，如果带上 live 则只统计活对象，如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ jmap -histo:live 8183</div><div class="line"> num     <span class="comment">#instances         #bytes  class name</span></div><div class="line">----------------------------------------------</div><div class="line">   1:         25679       47998512  [B</div><div class="line">   2:         66216       15910168  [C</div><div class="line">   3:          8707        2980024  [I</div><div class="line">   4:         62197        1492728  java.lang.String</div><div class="line">   5:         28749         919968  java.util.HashMap<span class="variable">$Node</span></div><div class="line">   6:         17168         824064  org.apache.tomcat.util.buf.ByteChunk</div><div class="line">   7:         15363         737424  org.apache.tomcat.util.buf.CharChunk</div><div class="line">   8:         14563         699024  org.apache.tomcat.util.buf.MessageBytes</div><div class="line">   9:          6009         677840  java.lang.Class</div><div class="line">  10:          9152         608784  [Ljava.lang.Object;</div><div class="line">  11:          1976         497128  [Ljava.util.HashMap<span class="variable">$Node</span>;</div><div class="line">  12:         15396         492672  java.util.concurrent.ConcurrentHashMap<span class="variable">$Node</span></div><div class="line">  13:          6690         380824  [Ljava.lang.String;</div><div class="line">  14:          4270         375760  java.lang.reflect.Method</div><div class="line">  15:           448         206128  [Ljava.util.concurrent.ConcurrentHashMap<span class="variable">$Node</span>;</div><div class="line">  16:         11699         187184  java.lang.Object</div><div class="line">  17:          2687         171968  java.net.URL</div><div class="line">  18:          2887         138576  java.util.HashMap</div><div class="line">  19:          4154         132928  java.util.Hashtable<span class="variable">$Entry</span></div><div class="line">  20:          5077         121848  org.apache.tomcat.util.http.MimeHeaderField</div><div class="line">  21:          2923         116920  java.util.LinkedHashMap<span class="variable">$Entry</span></div><div class="line">  22:          2492          99680  org.apache.catalina.loader.ResourceEntry</div><div class="line">  23:           678          97632  java.text.DecimalFormat</div><div class="line">  24:          1420          90880  java.util.concurrent.ConcurrentHashMap</div><div class="line">  25:          3703          88872  java.util.ArrayList</div><div class="line">  26:          1795          86160  java.nio.HeapByteBuffer</div><div class="line">  27:          2017          80680  java.lang.ref.SoftReference</div><div class="line">  28:           691          77392  java.util.GregorianCalendar</div><div class="line">  29:          1372          76832  java.util.LinkedHashMap</div><div class="line">  30:          2246          71872  java.lang.ref.WeakReference</div></pre></td></tr></table></figure>
<p>其中 class name 有一些缩写，具体的意思是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">B  byte</div><div class="line">C  char</div><div class="line">D  double</div><div class="line">F  float</div><div class="line">I  int</div><div class="line">J  long</div><div class="line">Z  boolean</div><div class="line">[  数组，如[I表示int[]</div><div class="line">[L+类名 其他对象</div></pre></td></tr></table></figure>
<p>当然，我们也可以把内存 dump 到文件中，再用 jhat 查看，比如 <code>jmap -dump:format=b,file=dumpFileName 8183</code>，dump 出来的文件可以使用 jhat 查看，如果 dump 文件太大，就可以加上 <code>-J-Xmx512m</code> 指定最大内存，比如 <code>jhat -J-Xmx512m -port 9998 /tmp/dump.dat</code>，然后就可以输入 <code>主机地址:9998</code> 来查看了</p>
<h3 id="jstat"><a href="#jstat" class="headerlink" title="jstat"></a>jstat</h3><p>这个命令主要用来统计 JVM 信息，必须要指定的是虚拟机 ID，一般就是进程号，比方说 <code>jstat -gc 8183 500 5</code> 就是指 500ms 采样一次，采样数字为 5，比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">wdxtub:~$ jstat -gc 8183 500 5</div><div class="line"> S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT   </div><div class="line">10752.0 10752.0 8881.2  0.0   327680.0  2318.5   699392.0   79410.9   36992.0 35946.6 3968.0 3721.2   5567   54.352   6      0.711   55.063</div><div class="line">10752.0 10752.0 8881.2  0.0   327680.0  5282.0   699392.0   79410.9   36992.0 35946.6 3968.0 3721.2   5567   54.352   6      0.711   55.063</div><div class="line">10752.0 10752.0 8881.2  0.0   327680.0  7929.1   699392.0   79410.9   36992.0 35946.6 3968.0 3721.2   5567   54.352   6      0.711   55.063</div><div class="line">10752.0 10752.0 8881.2  0.0   327680.0  9310.1   699392.0   79410.9   36992.0 35946.6 3968.0 3721.2   5567   54.352   6      0.711   55.063</div><div class="line">10752.0 10752.0 8881.2  0.0   327680.0 11648.8   699392.0   79410.9   36992.0 35946.6 3968.0 3721.2   5567   54.352   6      0.711   55.063</div></pre></td></tr></table></figure>
<p>这里需要先讲解一下 JVM 堆内存的设计</p>
<p><img src="/images/14750634259927.jpg" alt=""></p>
<p>简单来说，JVM 的堆分成三代：年轻代、年老代和永久代，年轻代里又分为 Eden 区以及 Suvivor 的 From 和 To 区，在 Survivor 区的对象如果经过多次 GC 还存活的话，会转移到年老区。参考链接中有一个具体的<a href="http://www.idouba.net/a-simple-example-demo-jvm-allocation-and-gc/" target="_blank" rel="external">例子</a>，感兴趣的同学可以前往查看。</p>
<p>简单来说，年轻代使用复制算法和标记-清除垃圾收集算法，永久代使用标记-整理算法进行垃圾回收算法，而年老代使用标记-整理垃圾回收算法，这里需要注意的是对年老代的的垃圾回收会停止所有事情(Stop The World)，如果应用需要高实时，那么就要尽量避免年老代的垃圾回收（也就是 Full GC 了），否则可能整个服务器十多分钟没有响应。</p>
<p>具体调优的经验和规则可以参考<a href="http://alexchan.iteye.com/blog/1980072" target="_blank" rel="external">这里</a>，本文不深入了。</p>
<p>现在可以来介绍前面各个字段的意思了：</p>
<ul>
<li>S0C、S1C、S0U、S1U：Survivor 0/1 区容量(Capacity)和使用量(Used)</li>
<li>EC、EU：Eden 区容量和使用量</li>
<li>OC、OU：年老代容量和使用量</li>
<li>PC、PU：永久代容量和使用量</li>
<li>YGC、YGT：年轻代 GC 次数和 GC 耗时</li>
<li>FGC、FGCT：Full GC 次数和 Full GC 耗时</li>
<li>GCT：GC 总耗时</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>工作以来除了开发工作，也承担了一部分运维的责任，所以 DevOps 最大的推动力其实就是『不够人』。服务器出现异常，一般来说是由于多种因素共同作用引起的，这就需要我们能够以全局的视角，顺藤摸瓜，各个击破，找到问题最终的根源，才能治标治本。</p>
<p>本文也会不断更新，争取能做一套自动化检测工具，减少排查难度。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="http://www.infoq.com/cn/news/2015/12/linux-performance" target="_blank" rel="external">用十条命令在一分钟内检查Linux服务器性能</a></li>
<li><a href="https://my.oschina.net/feichexia/blog/196575" target="_blank" rel="external">JVM性能调优监控工具</a></li>
<li><a href="https://my.oschina.net/secisland/blog/672715" target="_blank" rel="external">Elasticsearch 2.3.0 老版本升级指南</a></li>
<li><a href="http://www.idouba.net/a-simple-example-demo-jvm-allocation-and-gc/" target="_blank" rel="external">最简单例子图解JVM内存分配和回收</a></li>
<li><a href="http://blog.csdn.net/u012152619/article/details/46981643" target="_blank" rel="external">JVM垃圾回收机制</a></li>
<li><a href="http://www.cnblogs.com/redcreen/archive/2011/05/04/2037057.html" target="_blank" rel="external">JVM参数设置、分析</a></li>
<li><a href="http://alexchan.iteye.com/blog/1980072" target="_blank" rel="external">JVM-GC调优的经验和规则</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;服务器有时候像一个爱哭爱闹的小宝宝，能听到它在哭，但如果不够熟悉的话，一时半会儿还真不知道到底是为啥而哭。本文结合自己工作中的一些经验，给出一些检查服务器运行状况的通用技巧。&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="Linux" scheme="http://wdxtub.com/tags/Linux/"/>
    
      <category term="服务器" scheme="http://wdxtub.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
      <category term="运维" scheme="http://wdxtub.com/tags/%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>【Web 之旅】I Web 快速入门</title>
    <link href="http://wdxtub.com/2016/09/26/web-dev-first-step/"/>
    <id>http://wdxtub.com/2016/09/26/web-dev-first-step/</id>
    <published>2016-09-25T23:49:11.000Z</published>
    <updated>2016-09-27T23:22:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>虽然我是原生应用的坚定粉，但是随着微信小程序的出现，还是得了解一下 Web 应用的开发。本文结合 CMU 15417 Web Application Development 这门课，大致梳理一下入门 Web 开发的必备知识及思维方式上需要转变的地方。</p>
<a id="more"></a>
<hr>
<p>更新记录</p>
<ul>
<li>2016.09.27 更新『优秀学习资源』和一些链接</li>
<li>2016.09.26 更新『Web 发展历程』与『Web 技术演进』</li>
<li>2016.09.25 完成『Web 之难』与『一次点击背后』</li>
</ul>
<h2 id="Web-之难"><a href="#Web-之难" class="headerlink" title="Web 之难"></a>Web 之难</h2><p>对于大多数同学来说，如果没有业余做一些小项目，其实是很难理解 Web 到底是怎么回事儿的，至少我当年就因为『觉得』 Web 很难所以『抗拒』Web 和网络相关的开发。虽然课堂上学过计算机网络，甚至也去实验室捣鼓过路由器交换机，但是真到自己开发的时候，真的是一脸懵逼。现在回过头来看，发现主要有以下原因：</p>
<ul>
<li>教学内容僵硬，硬件部分只讲硬件，软件部分只讲软件，没有联系起来</li>
<li>实验设计不接地气，为了实验而实验，没有结合具体的场景来复制相关概念的理解</li>
</ul>
<p>当然，最重要的原因还是在自己的『好奇心』不足，没有追根溯源把事儿弄明白。底层原理和上层应用的有机结合本来就是非常需要花功夫的，以目前国内高校的现状来看，甚至是『吃力不讨好』的。如果体制内没有变革的动力，那不妨通过外部努力进行自下而上的改变。</p>
<p>看到越来越多非常走心的教程以开源的方式出现在网上，我特别开心。这种开放和分享的精神在中文（互联网）世界里生根发芽，信息流动的过程本身就是一种平等。只要有网络和一颗想要学习的心，不需要缴纳高昂的学费，同样可以学到本领。程序员有程序员改变世界的方式，这就是我开博客写文章的初心了。</p>
<p>Web 之难，主要是简单操作背后所隐藏着的复杂体系，需要有比较完善的计算机及网络相关的知识积累，既需要大局观，也需要懂细节，这对于初学者来说可能就像无法逾越的大山，很多东西只知道怎么做，却不知道为什么要这样做。与此同时，遇到问题也没有解决的思路，就很容易有挫败感。（心疼当年的自己一秒）</p>
<p>希望本文能给在困惑中的同学一点帮助，虽然不能面面俱到，但至少能给出一些有用的提示和方法，出了问题不至于束手无策。</p>
<h2 id="一次点击背后"><a href="#一次点击背后" class="headerlink" title="一次点击背后"></a>一次点击背后</h2><p>之前在 caoz 的公众号中看到过，他喜欢出的一道面试题是：</p>
<blockquote>
<p>从浏览器地址栏输入网址，到网页彻底打开，中间都发生了什么？</p>
</blockquote>
<p>这道题看起来很简单，但其实需要答题者对 Web 的工作过程有整体认识。与此同时，面试官也可以根据具体情况选择一到两个细节进行深入的讨论。只有明白了整个系统运行的机制，之后的调试、测试、优化才不是无源之水。而弄懂这些问题本身，也能体现一个人学习的习惯和对技术的追求，这才是面试最需要体现的东西。</p>
<p>我一直认为，即使是做一个小的模块，也应该把自己放到更大的场景中去思考，这个模块在系统中所处的位置，与其他模块的关系与交互方式等等都是需要去思考的，这样才能写出最有价值的代码，并从中找到之后改进的方向。如果让我去面试，具体的技术细节我反而不会去拘泥太多，毕竟聪明的人很快就能学会，我在意的是候选人能不能真正以网络和计算机的方式去思考问题，这才是最重要的。（原文可以在<a href="http://chuansong.me/n/1795517" target="_blank" rel="external">caoz 的梦呓</a>中查看）</p>
<p>仔细读题，我们应该想到的细节问题是：</p>
<ul>
<li>为什么我们要输入网址而不是其他什么东西？</li>
<li>浏览器做了什么事情？</li>
<li>网址最后去了哪里？</li>
<li>服务器是怎么收到网址的？</li>
<li>服务器做了什么事情？</li>
<li>不同的页面效果是怎么出来的？</li>
</ul>
<p>化简一下，就是『客户端』、『网络』和『服务端』。每个部分都有各自相关的技术体系，学习的时候一定要弄清楚自己处于哪一块，比如上面几个问题涉及的相关知识点是：</p>
<ul>
<li>为什么我们要输入网址而不是其他什么东西？<ul>
<li>DNS 服务器的工作原理。具体每个部分的缓存机制，如何依次更新？</li>
<li>CDN 的工作原理。如何在硬件条件限制的情况下提供最佳服务质量？</li>
</ul>
</li>
<li>浏览器做了什么事情？<ul>
<li>Host 文件的作用。应用扩展与劫持。</li>
</ul>
</li>
<li>网址最后去了哪里？<ul>
<li>不同层的网络协议(HTTP, TCP, UDP)</li>
<li>路由规则，传播路径，tracert</li>
</ul>
</li>
<li>服务器是怎么收到网址的？<ul>
<li>端口监听</li>
<li>静态资源</li>
<li>动态请求处理</li>
</ul>
</li>
<li>服务器做了什么事情？<ul>
<li>防火墙</li>
<li>缓存</li>
<li>数据库</li>
<li>负载均衡</li>
<li>集群</li>
</ul>
</li>
<li>不同的页面效果是怎么出来的？<ul>
<li>javascript</li>
<li>css/html </li>
</ul>
</li>
</ul>
<p>一个网址请求背后就有这么多的东西，基本上每一个都可以开一门一学期的课程，初学者忽然面对这样概念饱和的轰炸，真的是九死一生。而这么多知识点，真的要样样精通，不太可能，不过如果有一个完整的概念，学习或工作中涉及具体的某个领域，再根据需要深挖，就能逐步触类旁通，找到技术的感觉。</p>
<p>可能前面说的都比较虚，了解系统原理最直接的好处是：出了问题知道怎么排查。比如前一阵子我的博客访问忽然变慢，我做了什么呢？</p>
<ol>
<li>梳理架构及流程。我的博客是静态博客，评论系统采用第三方服务，页面部署在 Github 和 Coding 双平台。因为是第三方托管，所以服务器的部分我不需要操心，而客户端的话我在手机和电脑都测试过，也并没有表现出设备相关的特性，于是把问题锁定在网络传输层面。</li>
<li>因为是静态网站，静态本身已经帮我缩小了可能出现问题的范围，无非是几个可能：页面内容传输、图片传输、字体渲染、图标显示和评论系统加载，逐个进行排查。</li>
<li>切换 VPN 确定 Github 和 Coding 没有问题后（即页面内容和图片的传输正常），发现字体渲染卡住了，检查后是因为所用的字体库不稳定（为了照顾国内使用了 360 的源），所以切换到了中科大的源。</li>
<li>问题解决。另外，几天后，360 官方也给出通告，停止了该源的维护，所以我也经历了一次『春江水暖刀先知』了</li>
</ol>
<p>平时遇到的问题大多是模糊的，只有对系统运行的机制有基本的理解，才能快速找到问题的关键所在，而这就是个人价值的体现。</p>
<p>另一篇类似的文章是<a href="http://kb.cnblogs.com/page/132716/" target="_blank" rel="external">技术普及帖：你刚才在淘宝上买了一件东西</a></p>
<h2 id="Web-的发展历程"><a href="#Web-的发展历程" class="headerlink" title="Web 的发展历程"></a>Web 的发展历程</h2><p>通过前面一道面试题，我们大致了解了 Web 的整体框架逻辑，这里我们从历史出发，分门别类介绍一下 Web 相关的技术</p>
<ul>
<li>1989 - HTML - SGML 的一个子集，由 1960 年代的 GML 衍生而来</li>
<li>1990 - HTTP 协议 - 一开始只有一个方法 GET</li>
<li>1993 - CGI(Common Gateway Interface)，允许应用程序动态生成 HTML</li>
<li>1994 - Cookies</li>
<li>1995 - SSL</li>
<li>1996 - JavaScript</li>
<li>1999 - AJAX</li>
<li>2008 - 开始制定 HTML5 标准</li>
</ul>
<h3 id="HTML-与-CSS"><a href="#HTML-与-CSS" class="headerlink" title="HTML 与 CSS"></a>HTML 与 CSS</h3><p>HTML 其实是一个比较笼统的说法，具体的规范有很多，比如 HTML4, XML, XHTML, HTML5 等等，各有各的标准。问题在于这种标准并不是强制性的，所以现实生活中往往不同的厂商有不同的实现方式，目前看来，HTML5 是比较有前途的。</p>
<p>最原始的页面基本都是非常『简陋』的，就是把需要显示的内容显示出来。而随着时代的发展，大家对于外观的要求越来越高，慢慢就出现了样式和内容分离的趋势，也就是 CSS(Cascading Style Sheets) 的出现。</p>
<p>纵观历史，就会发现这样的解耦其实无处不在。为什么每一次解耦都能够带来巨大的进步呢？因为解耦实际上是沟通方式的抽象化，用更加高层的抽象能够表示更多的细节，分工更细，自然挖掘得更深。</p>
<h3 id="DOM-Document-Object-Model"><a href="#DOM-Document-Object-Model" class="headerlink" title="DOM - Document Object Model"></a>DOM - Document Object Model</h3><p>提到 HTML，就不得不提 DOM 这概念，甚至可以这么说，万变不离其宗，我们看到的五花八门的各种前端技术，实际上都是基于 DOM 这个东西的。DOM 可以认为是一个 HTML 的对象模型，一个表示 HTML 文档的节点树。树中的每个节点可能是元素(element)，属性(attribute)或文本(text)，我们通过操作不同的节点，就可以展现出不同的页面。</p>
<p>尤其是在动态页面大行其道的今天（但静态仍然有静态的好处，比如本博客就是静态博客），如何看待 DOM，如何操作 DOM 是每个前端框架都必须要回答的问题，比方说 React 提出的 Virtual DOM，就是希望优化传统对 DOM 操作可能带来的各种问题。</p>
<h3 id="Javascript"><a href="#Javascript" class="headerlink" title="Javascript"></a>Javascript</h3><p>如何去操作 DOM？如何在页面中展现动态效果呢？这就离不开基于浏览器的脚本语言 - JavaScript 了。看现在的趋势，JavaScript 还真有一统前端天下的感觉，虽然最初设计得很烂（十天搞定），但是架不住用的人多呀。</p>
<p>而随着语言本身的不断进化，也出现了各种各样的『方言』，虽然说最终都会转化成 JavaScript，但如果开发过程中有特定的需求（比方说希望有强类型），还是有用武之地的。</p>
<p>简单描述 JavaScript 就是：</p>
<ul>
<li>类 C 语法</li>
<li>垃圾回收</li>
<li>基于对象（函数是对象）</li>
<li>对象有具名属性</li>
<li>函数可以是属性</li>
<li>基于原型</li>
<li>解释型</li>
<li>动态类型</li>
<li>在浏览器中运行</li>
</ul>
<p>好了，相信再多写点大家也看不下去了，总之写的时候多思考下就好。</p>
<h3 id="jQuery"><a href="#jQuery" class="headerlink" title="jQuery"></a>jQuery</h3><p>有一定开发经验的同学都知道，没有各种各样的库的支持，开发起来真的是捉襟见肘。对于前端来说，jQuery 虽然现在听起来有些过时，但确实是一代王者。在它的帮助下，我们得以以更加清晰的方式来进行开发。jQuery 提供了：</p>
<ul>
<li>DOM 操作支持（元素选择，遍历等等）</li>
<li>事件支持</li>
<li>AJAX 支持</li>
<li>工具支持</li>
<li>插件支持</li>
</ul>
<p>不过现在各大公司都在推自己的前端技术栈，希望大家在看热闹的同时不要忘记曾经的英雄 - jQuery。</p>
<h3 id="AJAX"><a href="#AJAX" class="headerlink" title="AJAX"></a>AJAX</h3><p>前面提到的 AJAX 并不是一种语言，而是一种技术，允许异步 HTTP 调用，识得更具交互性的 web 应用成为可能，因为我们不在需要每次都刷新整个页面，减少服务器负载的同时，增加了灵活性。</p>
<p>具体的原理也很简单，使用 JavaScript 通过 XMLHttpRequest 从服务端获取数据，把数据转换成 DOM 树，再融合到现有的 Dom 树中，就完成了页面的更新。</p>
<h3 id="HTTP-与服务器"><a href="#HTTP-与服务器" class="headerlink" title="HTTP 与服务器"></a>HTTP 与服务器</h3><p>除了前面提到的技术，Web 另一部分非常重要的内容就是服务器。这里以 HTTP 服务器为例，简要进行说明。开始之前，先来看一眼服务器的市场份额：</p>
<p><img src="/images/14748987739818.jpg" alt=""></p>
<p>老牌劲旅 Apache 在最近两年和 Microsoft 的缠斗中逐渐失去了王者地位，从最高的 70%（大约是 05-06 年）跌落到现在的不足 30%，而微软倒是不紧不慢地突破了 40%，还有一个值得注意的特点是 nginx 这种反向代理服务器的异军突起。</p>
<p>简单来说，用户通过 URI 指定要访问的资源，向服务器发起请求。传输的协议基于 TCP，默认是服务器的 80 端口进行接收。具体的服务器实现因为 HTTP 规范，所以比较复杂，但基本结构是简单的，就是读取请求 - 处理请求 - 返回响应，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">while (true) &#123;</div><div class="line">    request = readHttpRequest(...);</div><div class="line">    response = processHTTPRequest(request);</div><div class="line">    sendHttpResponse(..., response);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>服务器需要照顾的东西非常多，比如：</p>
<ul>
<li>服务器名称</li>
<li>电子邮件</li>
<li>文档位置</li>
<li>IP 地址和端口</li>
<li>超时</li>
<li>最大请求长度</li>
<li>缓存</li>
<li>目录显示</li>
<li>验证与授权</li>
<li>日志与监控</li>
<li>错误处理</li>
<li>系统管理</li>
<li>性能</li>
<li>安全</li>
<li>….</li>
</ul>
<p>不一而足，这里就暂时不展开了。</p>
<h3 id="Cookies-与-Sessions"><a href="#Cookies-与-Sessions" class="headerlink" title="Cookies 与 Sessions"></a>Cookies 与 Sessions</h3><p>前面忘了说，HTTP 其实是无状态的，即不同的请求没有上下文关系，但是很多时候页面上的操作是需要依赖上下文的，比方说登录注册购物车。这时候就是 Cookies 与 Sessions 登场的时候了。</p>
<p>Cookies 有几种类型：</p>
<ul>
<li>Session Cookie - 浏览器关闭就删除</li>
<li>Persistent Cookie - 过期才删除</li>
<li>第三方 Cookie - 从其他站点得到的，通常用于追踪，可以在浏览器中设置拒绝</li>
</ul>
<p>而 Sessions 则可以认为是一个短期的状态暂存，通常用 cookie 来实现。我们保存一个 session id，通过这个 id 来取出服务器上对应的 <code>(name, object)</code>，来进行相关操作。</p>
<h3 id="网络地址"><a href="#网络地址" class="headerlink" title="网络地址"></a>网络地址</h3><p>回过头来说说网络传输层面，针对不同层级，我们都需要一个方式来区别不同的设备和应用，于是有了：</p>
<ul>
<li>MAC 地址 - 底层 - 硬件地址</li>
<li>IP 地址 - 可路由的地址 </li>
<li>DNS 主机名 - 高层 - 逻辑地址</li>
</ul>
<p>确定了服务器之后，使用不同的端口来和不同的应用沟通，比如</p>
<ul>
<li>telnet - 23</li>
<li>smtp - 25</li>
<li>rdp - 3389</li>
</ul>
<p>在开发和部署中，也有一些惯例，我们在开发的时候最好也遵守这种约定：</p>
<ul>
<li>部署<ul>
<li>HTTP - 80</li>
<li>SSL - 443</li>
<li>MySQL - 3306</li>
</ul>
</li>
<li>开发 <ul>
<li>HTTP - 8080 </li>
<li>SSL - 8443</li>
</ul>
</li>
</ul>
<h2 id="Web-技术演进"><a href="#Web-技术演进" class="headerlink" title="Web 技术演进"></a>Web 技术演进</h2><h3 id="CGI"><a href="#CGI" class="headerlink" title="CGI"></a>CGI</h3><p>虽然现在可能很多人都不知道 CGI(Common Gateway Interface)是啥了，但是从 1993 年出现其，CGI 使得在网页上动态显示内容成为可能。这里的动态并不是指页面在动，而是可以通过 Web 请求动态生成内容。这是怎么做到的呢？说来也简单，CGI 可以认为是 Web 服务器用来执行外部程序的接口，等于把一个 HTTP 请求通过 CGI 转化成了一个函数调用，而具体调用的函数可以由我们自己编写。当年最流行的语言是 Perl, Shell, 和 C，只要符合 CGI 接口标准，就可以把内容发送给 Web 服务器，用户也就能看到了。</p>
<p>借助 CGI 这一层，我们把 Web 请求和处理请求的程序解耦了。当年的网站大概是这样的：</p>
<p><img src="/images/14749872547418.jpg" alt=""></p>
<h3 id="PHP"><a href="#PHP" class="headerlink" title="PHP"></a>PHP</h3><p>能显示动态内容是一个巨大的进步，不过很快人们就发现 CGI 没有办法满足需求了，因为每来一个请求，就要启动一个进程来处理。而且需要我们的程序自己输出 HTML 字符串，哪怕只需要一个简单的页面，也不得不输出成吨的 HTML 代码。</p>
<p>程序员就想，那我把不变的部分抽出来，把动态内容留个占位符最后填充进去不就省事儿了吗？于是，我们就有了模板。折腾的人多了，自然就要弄出一个新东西，于是 PHP 就在 1994 年横空出世（毕竟是『最好的』语言）。</p>
<p>之后的 ASP 和 JSP 其实可以认为是类似 PHP 这样的模板引擎，只不过后端的语言不同罢了。后来为了把内容和样式分离，1996 年的时候 W3C 发布了 CSS 1.0 规范。这下好了，Web 终于成了一个可以处理复杂事务的平台了。</p>
<h3 id="J2EE-Net"><a href="#J2EE-Net" class="headerlink" title="J2EE / .Net"></a>J2EE / .Net</h3><p>随着 Web 应用越来越大，大家又不满足了。分布式要考虑，安全要考虑，事务要考虑，部署方式要考虑。各大公司一看，这是一个可以赚钱的事儿，于是双雄争霸，Java 派以 Servlet, JSP 和 EJB 合体出战，是为 J2EE。而微软甩出 ASP.Net 和 Visual Studio，用拖拽组件方式创建 Web 页面，极大降低了门槛。</p>
<h3 id="框架的兴起"><a href="#框架的兴起" class="headerlink" title="框架的兴起"></a>框架的兴起</h3><p>不同的技术方案在发展到一定程度，再次面临了同一个问题，就是如何多人协作，如何组织代码。回答这两个方式有多种答案，但是最流行的答案是 MVC 的方法，即 Model/View/Controller 的套路。这种分类方式按照不同的角色进行代码复用和组织，Web 应用可以以更加灵活的方式进行配置。</p>
<p>有的框架大而全，如果没有特别多个性化需求，几乎可能在很短的时间完成开发工作，但缺点是易学难精，一旦出现问题和稍微复杂且小众的需求，就需要大量的开发工作。</p>
<p>有的框架小而灵活，不过需要使用者对于自己的需求和技术整体有比较清晰的认知，才能挑选出正确的组件完成工作。</p>
<p>不同语言基本都有自己的框架，具体怎么选择就看团队和业务的要求了，如果好奇各个框架的性能，可以看<a href="http://www.techempower.com/benchmarks/#section=data-r12&amp;hw=peak&amp;test=query" target="_blank" rel="external">这里</a>，进行查看，比如说：</p>
<p><img src="/images/14749903956246.jpg" alt=""></p>
<p>随着前端的复杂度越来越高，各种各样前端的框架也应运而生，比如 BackboneJS, AngularJS, EmberJS（然而我并不熟悉，就此略过）</p>
<p>框架另外做的事情是 ORM，我们不需要自己去写 SQL 语句，而是像操作对象一样操作数据库中的数据即可。</p>
<p>更多内容可以查看<a href="https://www.zhihu.com/question/25654738" target="_blank" rel="external">Spring，Django，Rails，Express这些框架技术的出现都是为了解决什么问题，现在这些框架都应用在哪些方面？</a></p>
<h3 id="RESTful"><a href="#RESTful" class="headerlink" title="RESTful"></a>RESTful</h3><p>从原来的静态页面开始，到各种框架，Web 本身几乎已经淹没于各种技术名词中。直到 REST 的提出和 RESTful API 的广泛使用，通过 URL 而不是其他来组织功能，可以看做是 Web 精神的回归。</p>
<p>不过 REST 和 MVC 并不是互斥的关系，经过合理的设计，其实可以真正发挥 Web 开放、简洁且平等的力量。</p>
<h2 id="优秀学习资源"><a href="#优秀学习资源" class="headerlink" title="优秀学习资源"></a>优秀学习资源</h2><ul>
<li><a href="https://www.freecodecamp.cn/" target="_blank" rel="external">从零开始学习Web开发 - FreeCodeCamp</a></li>
<li><a href="https://github.com/justjavac/free-programming-books-zh_CN" target="_blank" rel="external">免费的编程中文书籍索引</a></li>
<li><a href="https://github.com/JacksonTian/fks" target="_blank" rel="external">前端技能汇总</a></li>
<li><a href="https://www.zhihu.com/question/19834302" target="_blank" rel="external">零基础的前端开发初学者应如何系统地学习？</a></li>
<li><a href="https://github.com/nieweidong/fetool" target="_blank" rel="external">大前端工具集</a></li>
<li><a href="https://www.zhihu.com/question/19696149" target="_blank" rel="external">单人做一个网站需要掌握哪些知识？</a></li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>前面走马观花写了这么多，可能还是有很多地方没有讲清楚。之后会以系列文章的形式，把自己学习 Web 相关技术的过程跟大家分享。最后会制作一个较大型的开源 Web 应用，以实例讲解的形式完成这个系列的文章。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="https://news.netcraft.com/archives/2016/09/19/september-2016-web-server-survey.html" target="_blank" rel="external">September 2016 Web Server Survey</a></li>
<li><a href="https://www.tianmaying.com/tutorial/web-history" target="_blank" rel="external">Web开发技术发展历史</a></li>
<li><a href="http://www.williamlong.info/archives/3829.html" target="_blank" rel="external">中国互联网二十年回忆</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;虽然我是原生应用的坚定粉，但是随着微信小程序的出现，还是得了解一下 Web 应用的开发。本文结合 CMU 15417 Web Application Development 这门课，大致梳理一下入门 Web 开发的必备知识及思维方式上需要转变的地方。&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="开发" scheme="http://wdxtub.com/tags/%E5%BC%80%E5%8F%91/"/>
    
      <category term="Web" scheme="http://wdxtub.com/tags/Web/"/>
    
      <category term="入门" scheme="http://wdxtub.com/tags/%E5%85%A5%E9%97%A8/"/>
    
  </entry>
  
  <entry>
    <title>三学 - 写给转计算机专业的同学们</title>
    <link href="http://wdxtub.com/2016/09/24/siksa/"/>
    <id>http://wdxtub.com/2016/09/24/siksa/</id>
    <published>2016-09-24T07:20:48.000Z</published>
    <updated>2016-09-24T11:19:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>我曾不止一次被问过，本科非计算机相关专业毕业的同学，要如何在读研究生的一到两年中平衡生活和学习，并找到一份软件工程师的工作。本文是我的回答。</p>
<a id="more"></a>
<hr>
<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>在 CMU 读研究生的日子里，我见证来自不同学校不同专业的同学们，如何凭借自己的努力，以软件工程师的身份拿到各个公司门票的历程。对于本科并非计算机相关专业的同学来说，这个过程并不轻松。除了要学的东西太多外，怎么学，学习顺序是什么，如何平衡生活、学习和求职，诸如此类层出不穷的问题所带来的困惑、迷茫和挣扎，同样让人煎熬。</p>
<p>希望本文这点微小的工作，能给日夜兼程的同学们一些鼓励与支持。</p>
<p>佛教术语中的<a href="https://zh.wikipedia.org/wiki/%E4%B8%89%E5%AD%B8" target="_blank" rel="external">『三学(śikṣā)』</a>，指的是『增上戒学(adhisīla-sikkhā)』、『增上意学(adhicitta-sikkhā)』和『增上慧学(adhipaññā-sikkhā)』，也就是我们常说的『戒』『定』『慧』，是达到解脱三界生死结䌸烦恼、得到漏尽通的修行之道。</p>
<p>虽然我们的境界不需要到超脱生死，但是『三学』的方法本身，给出了针对佛教中『三毒』- 『贪』『嗔』『痴』的应对方法，无疑是值得借鉴的。『三学』的具体修行称为<a href="https://zh.wikipedia.org/wiki/%E5%85%AB%E8%81%96%E9%81%93%E5%88%86" target="_blank" rel="external">『八正道』</a>，正语、正业、正命为戒学，正精进、正念、正定为定学，正见、正思维为慧学。我本人并不是佛教徒，在接下来的写作中也不会拘泥于教义指定的理解，而是会根据具体情况展开，这里先提前说明一下。</p>
<p>网游中的『转生』和『渡劫』是简单的，但是在现实生活中，系统性转变总是困难的，尤其对于异国他乡的学子，忽然面对如此大的变化，难免彷徨。我想说的其实是：没有什么过不去的坎儿，遇到困难要学会寻求帮助，最好找几个交心的好朋友，总而言之别都憋在心里。大家相遇相知就是缘分，可能的话，互相拉一把。</p>
<h2 id="持戒-由戒生定"><a href="#持戒-由戒生定" class="headerlink" title="持戒 - 由戒生定"></a>持戒 - 由戒生定</h2><p>『戒』可以认为是节制和取舍，正如古希腊的孩子们从小接受的教导那样：缺少适度和节制，完美便如镜中花、水中月，永不能企及。对于很多同学来说，各种烦恼的因，其实在一开始就种下了，比如：</p>
<ul>
<li>选课的时候贪多<ul>
<li>知识密度超过了自己的学习能力，只能牺牲质量，到最后似懂非懂，而且因为各种熬夜，把身体也弄垮了</li>
<li>作业量过大，每天处于 deadline 的高压状态，只能『完成』而非『做好』，也没有时间进行反思，为了做作业而做作业</li>
</ul>
</li>
<li>诱惑太多欲望太多<ul>
<li>各种各样的活动都想凑凑热闹，除了成为吃瓜群众，没有任何有价值的输入</li>
<li>为了免费食物东跑跑西转转，省了点钱却不在意极高的时间成本</li>
</ul>
</li>
<li>找工作的时候目标太多且不定<ul>
<li>不同的职位不同的公司一股脑全投简历，平均到每次面试，准备时间都很少</li>
<li>因为目标太分散，漫长的求职季让本就不宽裕的时间捉襟见肘，最后顾此失彼</li>
</ul>
</li>
</ul>
<p>之所以会出现这些问题，归根结底是犯了『戒』，给自己定下了不切实际的目标，既要鱼又要熊掌还要自行车，毕竟咱也不是哆啦a梦，还是要学会取舍，尤其对于没有太多计算机基础的同学而言，很容易落入『矫枉过正』的陷阱中。先给自己定一个小目标，至于这个小目标要怎么定就因人而异了，不同的人不同的目标不同的背景不同的基础不同的习惯。在这里我只能说一定要想清楚自己到底要什么，大处着眼小处着手目标明确。根据不同人的情况提供具体的计划和建议一直是我的收费服务，这里就不再展开。</p>
<p>前面提到，正语、正业、正命为戒学。</p>
<p>所谓『正语』，在佛教中指不妄语、不慢语、不恶语、不谤语、不绮语、不暴语，远离一切戏论。对于我们来说则是为人真实，对他人有益，这样不但自己没有太多包袱，也会有更多的人愿意在我们困难时伸出援手。</p>
<p>所谓『正业』，在佛教中指不杀生、不偷盗、不邪淫，不作一切恶行。对于我们来说则是为人正直，不因为时间短而抄袭或作弊（可以跟老师说明情况申请缓期），不把他人的帮助视为理所当然（除了几句感谢外，还要意识到别人为了帮助你所付出的时间成本）。</p>
<p>所谓『正名』，在佛教中指远离一切不正当的职业。对于我们来说则是遵纪守法，不在规章制度或法律面前动歪脑筋，以欺诈、胁迫等手段牟利的事情不要参与，也不要故意去破坏可能并非那么完善的制度（ICC, CCC）</p>
<p>对于大部分同学来说，即使是第一步，很多时候也并不简单。我能理解想让自己快速变强的心情，但是如果不加节制，好心就常常导致坏事儿。饭要一口一口吃，路要一步一步走，实话说，看到同学们这么着急，我就很替他们的着急而着急。</p>
<p>跑五公里，最快的方式是合理安排体力保持基本恒定的速度，一开始拼尽全力后面就很痛苦，太晚发力又来不及，难就难在找到合适的节奏，而秘诀，就是『戒』。</p>
<h2 id="禅定-因定发慧"><a href="#禅定-因定发慧" class="headerlink" title="禅定 - 因定发慧"></a>禅定 - 因定发慧</h2><p>『定』可以认为是心中一种平衡稳定的状态，英雄联盟里有个忍者英雄叫做凯南，他的口头禅是『均衡，存乎万物之间』，而找到这种『均衡』，就是在『戒』的基础上，可以追寻的更高的目标了。比方说：</p>
<ul>
<li>生活与课程的平衡：努力学习少点玩，留学在外需要操心的事情很多，尽量减少琐事所占用的精力和时间，不要为了省几个小钱而多花数倍的时间。本身在起跑线上就已经落后一截了，跑的时候就少歇几次吧。有的时候真的会很辛苦，既要补基础又要学新东西，的的确确要多花很多时间，提高效率，一点一点进步，真的也没有特效药。</li>
<li>课程与求职的平衡：大部分同学转计算机都是为了更好找到工作留在美国，求职所需要的能力和在学校中虽有交集，但并不大，很多东西都需要从头学起。我的建议是尽量利用学校的资源，跟着公司招聘的节奏，提前一两个月准备，极端情况下，课程甚至可以放一放。但是也不要孤注一掷，毕竟 CMU 的教育资源过了这村就没这店了（网课的体验还是有差距），要把长期目标和短期目标有机结合起来。</li>
</ul>
<p>在生活、课程与求职的三方拉锯中，一个好的心态是非常重要的</p>
<ul>
<li>积极：前进的道路上难免摔跟头，爬起来拍一拍灰，继续上路就是了，挫折只是对过去的当时的你的不肯定，不要因为过去而放弃将来。一次成绩不好，下次考好就是了；一次面试挂了，找到原因下次改进就是了。考卷和面试官都不知道你的过去，现在的你是怎么样，你就是怎么样。</li>
<li>不比较：有些时候，可能感觉平时还不如自己的同学表现得比自己好，就不要心里不平衡了，每个人背后都有旁人看不见的努力，纠结这些毫无意义，把该做的事情做好，比什么都重要。</li>
<li>踏实：遇到比较困难的问题，要踏踏实实把硬骨头努力啃下去，当然，如果时间安排太紧就没有这个时间了，解决难题才是进步的最佳方式，不然只是训练熟练度而已。</li>
</ul>
<p>当人真正『定』下来之后，才可能产生真正的智慧。就我个人的经验来说，写周记记录自己的心路历程是特别好的监督和安抚自己的方式，感兴趣的同学可以在博客中的<a href="http://wdxtub.com/1990/09/11/life-page/">生活栏目</a>中看到我两个学期的周记。还是和前面说的一样，有什么问题，多多找朋友和同学分担一下，年轻人，哪有什么过不去的坎儿嘛。</p>
<p>前面提到，正精进、正念、正定为定学。</p>
<p>所谓『正精进』，佛教中指正确的努力，止恶修善、去恶从善，自觉努力。对我们来说，路途漫漫，可以放慢速度，但千万不要停下，不要懈怠。毕竟一鼓作气，再而衰，三而竭。</p>
<p>所谓『正念』，佛教中指四念住，即随念于身、受、心、法四种所缘。对我们来说，是要积极调整心态，坚持锻炼，让身心都处于比较好的状态。</p>
<p>所谓『正定』，佛教中指正身端作，专心一志，身心寂静，深入一心。对我们来说，则是『因定发慧』的前提条件。</p>
<p>到了这一阶段，烦恼也会少很多，才更能专注把自己想要完成的事情做好。跑五公里，最好的状态就是只去想这一步和下一步，摒除杂念，回归事物本身。</p>
<h2 id="智慧-由慧起修"><a href="#智慧-由慧起修" class="headerlink" title="智慧 - 由慧起修"></a>智慧 - 由慧起修</h2><p>『慧』可以看作是『三学』的最终目标，但从更长远的修行来说，拥有『戒』『定』『慧』只不过是基础，就像魔兽世界中，满级之后，游戏才真正开始。</p>
<p>可惜的是，这一部分我也在努力求索中，只能以同路人的角度给一些自己的想法了：</p>
<ul>
<li>做一件事情，需要思考的除了事情本身，还要努力以更大的尺度去看待。比方说面对基础课和应用课的选择，基础课短期收益小长期收益大，需要积累的时间也更多，所以要早学，勤学；应用课短期收益大长期收益小，可以快速突击，可以根据自己的节奏与基础课配合着学习。</li>
<li>困难本身就是线索，能够一针见血指出自己一直以来学习或者工作的弱点及考虑不周之处，这才是真正需要花时间去提高的地方，也是一旦提高最有效果的地方（木桶理论）。不要出了问题找到答案就完事儿了，答案其实是最不重要的，不要捡了芝麻丢了西瓜。</li>
<li>一定要意识到时间的重要性，这是真正的稀缺且不可再生的资源。</li>
</ul>
<p>前面提到，正见、正思维为慧学。所谓『正见』，在佛教中指的是正确的佛理知见。所谓『正思维』，在佛教中指的是正确思维，以引导生如理如实的智慧。</p>
<p>生活是现实的，但是我们不能因为现实的生活而放弃了对『慧』的追求，这是旧世界的最后一扇门，也是新世界的第一扇门。</p>
<h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>虽说是写给转专业同学的文章，但其实做事儿的道理就这么多，其中的建议，或多或少哪里都能用上。写了这么多佛教，就以道德经中的一句话来结束吧：</p>
<p>上士闻道，勤而行之；中士闻道，若存若亡；下士闻道，大笑之。不笑不足以为道。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我曾不止一次被问过，本科非计算机相关专业毕业的同学，要如何在读研究生的一到两年中平衡生活和学习，并找到一份软件工程师的工作。本文是我的回答。&lt;/p&gt;
    
    </summary>
    
      <category term="Thinking" scheme="http://wdxtub.com/categories/Thinking/"/>
    
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="计算机" scheme="http://wdxtub.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"/>
    
      <category term="转专业" scheme="http://wdxtub.com/tags/%E8%BD%AC%E4%B8%93%E4%B8%9A/"/>
    
  </entry>
  
  <entry>
    <title>大河与大坝 - 也谈知识输入输出</title>
    <link href="http://wdxtub.com/2016/09/24/big-river-and-dam/"/>
    <id>http://wdxtub.com/2016/09/24/big-river-and-dam/</id>
    <published>2016-09-23T22:33:40.000Z</published>
    <updated>2016-09-24T02:05:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>前些天有朋友在博客里问我如何进行高效率的输出，如果你在写作的时候也遇到过无从下笔、不知所云的问题，那么这篇博客也许值得一读。</p>
<a id="more"></a>
<hr>
<p>用大河和大坝来解释高效输出这个问题特别贴切，很多现成的名言警句都可以直接派上用场，比如『不积跬步无以至千里，不积小流无以成江海』以及『飞流直下三千尺，疑是银河落九天』。输出的源头是输入，平时的积累就是细流汇聚成江河的过程；而输出的方式则更类似大坝，让水的势能积累到一定程度，再根据需要进行释放，可以汹涌，可以平静。</p>
<p>所以我们就来聊聊大河（输入）和大坝（输出）。这俩事儿整清楚了，剩下的细节问题就可以在实践中找到最适合自己的答案了。</p>
<h2 id="一条大河"><a href="#一条大河" class="headerlink" title="一条大河"></a>一条大河</h2><p>关于如何高效学习这个话题，畅销书和网络中的各种大道理已经过于泛滥了，各种各样的理论（象限、金字塔），各种各样的规则（番茄、GTD），各种各样的技巧（康奈尔笔记、思维导图），说句不好听的，没太多用处，或者说是成本比收益高太多的赔本买卖。刚开始用来培养习惯锻炼思维能力是挺好的，但是拐杖用得再好也不是正常行走。领会精神之后就没必要再按图索骥了，形式主义的歧途，走两步看看就足够了。</p>
<p>厚着脸皮说一句，论输入，我的豆瓣有已读 1532 本，我的书摘早已过了两百万字。论输出，我的 lofter 有文章 754 篇，我的独立博客有文章 622 篇。兜兜转转才发现，大道至简。</p>
<p>输入输出的本质其实特别简单，就是『Garbage IN, Garbage OUT』，<strong>只有高质量的输入才可能有高质量的输出</strong>。我当然可以写一堆冠冕堂皇的话，拼上各种让人心生欢喜的字眼：比如知识输出是记忆固化/思维训练/自我体验。但是再怎么样也是没用的鸡汤，就和我这篇文章一样，所以还是少谈些主义，直接上干货。</p>
<ul>
<li>水至清则无鱼。平时的信息获取要多元，交叉验证，不要一根筋听到啥看到啥就是啥。先入为主是偏见的主要来源。</li>
<li>不良的信息源是水污染，不及时控制住和处理好，会臭了一条河。</li>
<li>河道及路线无须刻意，但有一个基本的框架还是重要的，这样才能滋养一大片土地。不然动不动洪水泛滥，损失很大的。这里的框架即自己的知识体系。</li>
<li>河道的上中下游都需要有一定的过滤，不然杂质会越积越多。比方说，我订阅了不少公众号，只有当下我觉得有价值的才会发送的 kindle 细看，而发送到 kindle 的文章我又会隔一周左右看，这样又利用了时间进行过滤，可以去掉很多『当时觉得有用但其实并没有任何用』的信息。</li>
<li>尽量形成水系，比方说主题式阅读和在维基中『顺藤摸瓜』，从问题触发，找背后的理念以及问题和解法本身的进化过程。</li>
<li>小溪流也不可忽视，零碎时间做基本的筛选或构思字句，重要的是一种积累并利用的习惯，从小事儿做起是成本最低最无痛的方式。</li>
<li>逆势而行会很累，毕竟水往低处流。不要太依赖自己的记忆力，好记性不如烂笔头，尤其是时间和动作相关的信息，记下来准没错。</li>
</ul>
<h2 id="一座大坝"><a href="#一座大坝" class="headerlink" title="一座大坝"></a>一座大坝</h2><p>大坝的功能，一是积累，二是控制。水位越高，所积累的能量也就越大，但反过来对大坝本身的要求也就更高。蕴藏巨大能量之后，如何使用也需要精心控制，用牛刀还是施小计，都可以根据具体情况进行调整。一些大坝的施工技巧是：</p>
<ul>
<li>设计很重要。确定要表达的主题，学会问自己问题，通过回答相关问题，围绕主题展开构思和写作，列提纲，多思考，逻辑上要自洽。</li>
<li>建材质量要高。从经典中获取原料，精细深入思考进行合成与锻造。思考是填充零碎时间的法宝，等待是可以思考，焦虑时同样可以思考。</li>
<li>他山之石。看看别人的思路，如果可能的话，就写得再深入一些。</li>
<li>先攻克难点。本质是什么，基本定理是什么（比方说热力学三定律），整体的架构是如何围绕基本定理组成的。</li>
<li>枢纽的重要性。找到不同事物的联系，如果只写一件事情，那么很受限制，联系到其他事物的话，不仅可以写其他事物，联系本身也可以去探究（比较与异同）</li>
<li>从最基础的做起。只假设读者有最基本的知识，用构建完整体系的思路去写作，通常就能够找到其中的『势』</li>
<li>写作的局限大约是思维的局限，大坝不够高，水位攒不高，还可能崩塌。</li>
</ul>
<p>其实还是那句话：大处着眼，小处着手，目标清晰。输出困难，大约是因为输入不够。输入的时候思考一下别人是如何进行输出的，其实就能发现很多有趣的事情了。</p>
<h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>我很不喜欢现在流行的某些所谓『知识类』节目所流露出来的观念，所有想帮别人思考和成长的人，不是呆就是坏；所有想让别人代替自己读书和成长的人，不是蠢就是懒。愿我们都不要成为自己讨厌的那种人。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前些天有朋友在博客里问我如何进行高效率的输出，如果你在写作的时候也遇到过无从下笔、不知所云的问题，那么这篇博客也许值得一读。&lt;/p&gt;
    
    </summary>
    
      <category term="Thinking" scheme="http://wdxtub.com/categories/Thinking/"/>
    
    
      <category term="思考" scheme="http://wdxtub.com/tags/%E6%80%9D%E8%80%83/"/>
    
      <category term="写作" scheme="http://wdxtub.com/tags/%E5%86%99%E4%BD%9C/"/>
    
      <category term="知识" scheme="http://wdxtub.com/tags/%E7%9F%A5%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>第十五周 - A Star Is Born</title>
    <link href="http://wdxtub.com/2016/09/23/a-star-is-born/"/>
    <id>http://wdxtub.com/2016/09/23/a-star-is-born/</id>
    <published>2016-09-23T11:27:05.000Z</published>
    <updated>2016-09-23T12:24:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>It’s a time for pulling out the stops. Come blow your horn. Gonna shout it from the mountaintops - A star is born.</p>
<a id="more"></a>
<hr>
<p>漫长的一周终于结束了，即使想到国庆后要连续上七天班，也丝毫没有让连续上六天班的本周变得好过一些。</p>
<p>大约是平淡且身体被掏空的一周，除了给同事过生日以及和同事一起跑步回家，似乎并没有太多不一样的事情发生。</p>
<p>转正之后的工作除了更加多了之外并没有太多的不同，因为同事出去旅游临时接下的摊子总算渡过了一半，虽然事儿是有趣，但是忙不过来就不有趣了。就拿数据平台来说，背靠数据挖掘和机器学习这两个领域，其实有很多值得探索的地方。和知识产权部门以及市场部门的合作中我也学到了不少东西，因为基础知识的限制，主要能学到的是思考问题的角度。</p>
<p>当然好消息也是有的，我负责的项目的第一期开发预计下周能够结束，也算是一个小小的里程碑，无论是美国的同事还是我都很开心，能在各种事务缠身的情况下按时完成开发，感觉还有点小激动。</p>
<p>除工作外也有好消息，新书的写作也终于结束了目录编排和资料整理的部分，可以进入下一阶段了。不过和工作一样，一山放过一山拦，还是要做好打持久战的准备，广积粮缓称王，闷声发大财。</p>
<p>闲暇时间看了三场电影：《追凶者也》看刘烨，《我的战争》看刘烨和王珞丹，《一次邂逅》看苏菲玛索。有黑色幽默，有女神，有绝妙的配乐，其实也就足够了。不由得想起《一次邂逅》全片高潮时候的配乐 For Once in My Life:</p>
<blockquote>
<p>For once in my life, I have someone who needs me. Someone I’ve needed so long.<br>For once unafraid, I can go where life leads me. Somehow I know, I’ll be strong.<br>For one, I can touch what my heart used to dream of. Long before I knew.</p>
</blockquote>
<p>这样想想，其实歌词里描述的状态，还真是特别美好。很多事情都是现在不做以后就不再有机会去做，所以忘掉『以后』吧，就是『现在』。趁着中秋节撺掇着把家里的网换成了 100M 的光纤，又给爸妈买了个电视盒子，你别说，还确实是挺方便的。</p>
<p>可能因为最近生活终于慢慢稳定了下来，又开始思索自己到底想要什么样的生活了，也许要勇敢多迈出一两步，用另一种打开方式开启生活。</p>
<p>Just remember in the darkest hour. Within your heart is the power. For making you a HERO too. So don’t lose hope when you’re forlorn. Just keep your eyes upon the skies.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;It’s a time for pulling out the stops. Come blow your horn. Gonna shout it from the mountaintops - A star is born.&lt;/p&gt;
    
    </summary>
    
      <category term="Gossip" scheme="http://wdxtub.com/categories/Gossip/"/>
    
    
      <category term="周记" scheme="http://wdxtub.com/tags/%E5%91%A8%E8%AE%B0/"/>
    
      <category term="工作" scheme="http://wdxtub.com/tags/%E5%B7%A5%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>接口、系统、管理与熵</title>
    <link href="http://wdxtub.com/2016/09/22/interface-system-management-and-entropy/"/>
    <id>http://wdxtub.com/2016/09/22/interface-system-management-and-entropy/</id>
    <published>2016-09-22T12:45:41.000Z</published>
    <updated>2016-09-22T15:20:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近无论是写书还是设计系统都攒了不少思考，有(fei)些(chang)凌乱，但是还是想写一写。</p>
<a id="more"></a>
<hr>
<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>回国之后，工作强度还是比较大的。好在经过一段时间的适应和磨合，总算慢慢找到了节奏。思考和总结的好处有很多，对我来说最重要的有两个方面：一是能够从实践中萃取最多的养分让自己快速成长；二是针对暴露出的问题进行定向改进，能极大提高工作效率。</p>
<p>原则上我是希望在博客中尽量保持某种意义上的中立的，但是在这里，我依然想感谢公司给予我极高的自由度，职位或者项目并没有成为桎梏，我因此得以把触角伸向各个领域。接触各个项目的好处不言而喻，除培养大局观外，学会以不同的角色站在不同部门不同角度去思考问题，也是极好的。更有意思的是，之前看的诸多『闲书』，现在竟以各种各样的方式发挥着作用，果真『功不唐捐』。</p>
<p>今天早上正好跟同学聊起留美还是回国，抛开各种外在因素不说，回国最吸引我的就一点——一个验证自己可能性的机会。从小就听老爸说要『在广阔天地里大有作为』，真的离开学校之后，发现很多同学早已把『星辰大海』抛诸脑后。也许每个理想主义者终究要落地，但是我想在这之前去看看天有多高，地有多厚。</p>
<p>如果有缘能看到，这也是我最想对还在学校的同学们说的，每一次选择在当时看起来不过如此，但是回过头来看，很多巨变在那一刻就已经开始了。不要想着『以后我要怎样怎样』，如果真的想，就『现在』去做。</p>
<p>回到主题，既然名义上我还是工程师，就从工程师的工作来说起吧。</p>
<h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p>最近在做的主要工作之一是设计接口，作为应用程序对外的『门面』，接口的设计很多时候比具体实现要重要得多，这也是为什么我花了大量时间和精力去尝试和构思。虽然大家都知道要 RESTful 要正交，但有的时候这种灵活性带来的副作用是复杂。耦合虽说不容易修改，但一旦在精心设计之后形成一股合力，本身紧密的作用力带来的好处可能要比得到一定程度的灵活性要大得多。这些内容其实任何一本经典的计算机书籍都会涉及，但是具体的度，和细节中的推敲，就需要一定的工程实践以及实际检验才能给出答案了。</p>
<p>设计系统是如此，写书亦是如此，甚至更要精细打磨，因为程序能够修改，书印出来了，白纸黑字就没法改了。接口之于应用，就好比目录之于书籍，新书目录的确定真真切切是非常痛苦的事情，在一个多月的时间内至少变动了几十次，终于达到了令自己满意的状态。这些改动其实是随着准备工作的进行而不断发生的，在参阅了大量经典书籍和课程后，在不断的切磋中，才终于找到了自己的方向。但其实这才是万里长征的第一步，后面还有很多艰巨的工作在等着我。虽然是初出茅庐，但依然得假扮老司机，相信假着假着，就成真了。</p>
<h2 id="系统"><a href="#系统" class="headerlink" title="系统"></a>系统</h2><p>系统是复杂的，哪怕是一个小的社区，其实往深处想，也有很多门道。如何去梳理整体的逻辑？三点：大处着眼，小处着手、目标清晰。从这里出发，可以给自己提出很多问题，比如：</p>
<ul>
<li>社区的历史包袱是什么？能不能找到一种方式，尽可能无痛甩开包袱？</li>
<li>社区的目标群体的层次是什么？现在主要需要抓住哪一类用户，如何去发现并抓住这些用户？</li>
<li>社区的推荐系统以及能量流动是怎样的规则，用户能从中获得什么，机制如何去影响用户？</li>
<li>社区的定位是什么，长中短期目标是什么？</li>
<li>能否参考不同领域的做法，比方说游戏中的常见玩法（工会、赛季、攻擂守擂等等）</li>
</ul>
<p>如果这些问题都想清楚了，恐怕社区下一步的目标就足够清晰了。而转念一想，写书同样要考虑清楚类似的问题：读者群体是什么、内容编排怎么做、能给读者提供什么、在整个阅读过程中的长中短期目标是什么等等。</p>
<h2 id="管理"><a href="#管理" class="headerlink" title="管理"></a>管理</h2><p>先提一句，这里的管理是从自我管理出发，慢慢延伸到更广义的管理的。自我管理的核心是效率，也就是说管理的终极目的是用更少的资源做成更多的事情。那么，对于我来说，自我管理就包含了一个巨大的矛盾：我需要以不同的角色参与到不同的项目中，但与此同时我们都知道『任务单一时效率最高』。</p>
<p>就像软件工程中没有银弹一样，这个矛盾同样没有完美的解法，只能在现有的框架中找寻最合理的解决方案。比方说我现在需要扮演的角色除了开发人员，还有产品经理、项目管理、沟通协调和部门对接，要处理的任务必然是持续且无序的。如果来一个做一个，频繁切换上下文，效率就很低。</p>
<p>目前的做法就是尽量把不同角色任务凑到一起，一次解决一系列问题，尽量减少切换次数，具体编排的依据就是那些不能变动的会议了，这样一口气解决，无论是状态还是具体的准备工作都能达到较好的程度。不过有的时候还是不可避免会『撞车』，今天以三个角色开完三个会之后我真的感觉自己已经是一个废人了，缓了好一阵才把各种事情梳理清晰，加入到之后的待办事项中。</p>
<p>解决了任务切换过多的问题，接下来就是时间控制和优先级设置的问题了，这个就我目前的经验来看，按照自己预估的完成时间乘以二或者三大概就是实际完成的时间，这样既考虑了难以预计的突发事件（比方说同事请假出去玩半个月），也照顾了需求临时变动所导致的时间变化。</p>
<p>个人尚且如此，如果是一个团队，则需要面对更复杂的多样性，难度是指数级增加的，关于这个问题，我自己也在慢慢摸索，这里就不妄下结论了。</p>
<h2 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h2><p>熵是一个足够伟大的定义。考虑到热力学在一定程度上的普适性，很多风马牛不相及的事情背后，都能看到熵的影子。简单来说，熵越大，有效能量就越小，系统也就越无序。但热力学第二定律告诉我们，熵的增加从总体来看是不可逆的。就像人固有一死一样，我们的目标就是重于泰山，而不是轻于鸿毛。</p>
<p>就拿写代码来说，如果随着业务需求不断增补，整个工程的熵就会快速增加，直到有一天再也无法维护，所以我的做法是一边写一边重构，尽量让熵增加的量最少。而好的架构设计使得一开始的基础熵值很小，并且架构本身也抑制了熵的快速增长；而坏的架构则是『助纣为虐』，最后变成谁都不愿意接的烂摊子。</p>
<p>项目管理和人员管理同样也是这个道理，不过有意思的是，团队并不是热力学中的『隔离系统』，是有机会发展成『自组织系统』的。所谓『自组织系统』，要点在于内部的有序结构，以及形成这种有序结构的推动力。自组织的程度越高，创新的能力就越强。与传统的他组织系统（需要依靠外部指令维持）相比，自组织系统能够各尽其责而又协调地自动地形成有序结构，是管理者梦寐以求的。</p>
<p>从维基中的介绍中我们能从不同的角度感受到自组织系统的魅力：</p>
<ul>
<li>从系统论的观点来说，”自组织”是指一个系统在内在机制的驱动下，自行从简单向复杂、从粗糙向细致方向发展，不断地提高自身的复杂度和精细度的过程</li>
<li>从热力学的观点来说，”自组织”是指一个系统通过与外界交换物质、能量和信息，而不断地降低自身的熵含量，提高其有序度的过程</li>
<li>从统计力学的观点来说，”自组织”是指一个系统自发地从最可几状态向几率较低的方向迁移的过程</li>
<li>从进化论的观点来说，”自组织”是指一个系统在”遗传”、”变异”和”优胜劣汰”机制的作用下，其组织结构和运行模式不断地自我完善，从而不断提高其对于环境的适应能力的过程</li>
<li>从结构论-泛进化理论的观点来说，”自组织”是指一个开放系统的结构稳态从低层次系统向高层次系统的构造过程，因系统的物质、能量和信息的量度增加，而形成比如生物系统的分子系统、细胞系统到器官系统乃至生态系统的组织化度增加，基因数量和种类自组织化和基因时空表达调控等导致生物的进化与发育（Evo-Dev）过程</li>
</ul>
<p>更多的介绍可以自行搜索『自组织』。</p>
<p>对我来说，自组织其实是应对熵增加的法宝，也给前面提到的『自我管理』指出了一个不一样的方向。不过具体还需要一段时间的磨练，只能希望自己早点『悟道』了。不过这个跟禅修一样，勉强不来，还是顺其自然，水到渠成就好。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>学 SIFT 算子的时候就深深意识到同一个东西，从不同的尺度去观察，就能看到不同的东西。从『看山不是山，看水不是水』到『看山还是山，看水还是水』也是这么个理儿。</p>
<p>不要限定自己，敢于跳出框架思考，在不同的领域和学科间游走，融会贯通后，去创造新世界。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近无论是写书还是设计系统都攒了不少思考，有(fei)些(chang)凌乱，但是还是想写一写。&lt;/p&gt;
    
    </summary>
    
      <category term="Thinking" scheme="http://wdxtub.com/categories/Thinking/"/>
    
    
      <category term="思考" scheme="http://wdxtub.com/tags/%E6%80%9D%E8%80%83/"/>
    
      <category term="系统" scheme="http://wdxtub.com/tags/%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="自洽" scheme="http://wdxtub.com/tags/%E8%87%AA%E6%B4%BD/"/>
    
  </entry>
  
  <entry>
    <title>Byobu 指南</title>
    <link href="http://wdxtub.com/2016/09/21/byobu-guide/"/>
    <id>http://wdxtub.com/2016/09/21/byobu-guide/</id>
    <published>2016-09-21T12:21:56.000Z</published>
    <updated>2016-09-21T12:23:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>如果你觉得 tmux 或者 screen 的快捷键设置反人类，那么 Byobu 就是一个让你重新热爱终端的理由。</p>
<a id="more"></a>
<hr>
<p>作为一个黄金分段的 tmux 选手，在背熟了各种快捷键之后，就形成了一种惰性，懒得尝试新工具了。但是 byobu 绝对是一个值得尝试的『神器』，可以认为是 tmux 加上了一个靠谱的产品经理，各种功能和界面的设计都友好了很多，接下来就简要来说说如何使用。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>借助包管理器，安装 byobu 是非常简单的事情：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># Mac</span></div><div class="line">brew install tmux</div><div class="line">brew install byobu</div><div class="line"></div><div class="line"><span class="comment"># Ubuntu</span></div><div class="line">sudo apt install tmux</div><div class="line">sudo spt install byobu</div></pre></td></tr></table></figure>
<p>打开终端，键入 <code>byobu</code>，就可以看到完整界面了，如果之前有使用 tmux 的话，需要输入 <code>tmux kill-server</code> 关闭所有会话，然后再输入 <code>byobu</code>，不然看到的仍然是 tmux 的界面。</p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>我们先来简单了解一下 Byobu 的界面，Mac 的界面如下：</p>
<p><img src="/images/14744606094223.jpg" alt=""></p>
<p>而 Ubuntu 的界面如下：</p>
<p><img src="/images/14744605905498.jpg" alt=""></p>
<p>命令行的部分和正常的终端没任何差别，主要的变化是下面的状态栏，集成了窗口管理和系统重要信息显示等功能。比如说：启动时间、系统负载、核心数目、核心频率、内存大小、内存占用率、日期时间等等（这些都可以配置，具体参考文档）</p>
<h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><p>如果是纯新手，那么上来先按一下 <code>F9</code>，就会进入 Byobu 的配置界面，这里包括了快速帮助和基本的配置调整，如下图所示：</p>
<p><img src="/images/14744605754279.jpg" alt=""></p>
<p>我们先跟着快速入门指南来学习一下基本的操作（这里只列出最常用的，具体的大家可以自己查阅）：</p>
<ul>
<li><code>Shift-F1</code> 在一个新窗口中显示帮助。有什么操作忘记的话，这是最快捷的方法</li>
<li><code>F2</code> 创建一个新窗口。跟 F2 相关的操作都是跟界面相关的（其中 Session 部分因为不太直观，这里不介绍）<ul>
<li><code>Shift-F2</code> 水平切分窗口</li>
<li><code>Ctrl-F2</code> 垂直切分窗口</li>
</ul>
</li>
<li><code>F3/F4</code> 用来切换窗口。<ul>
<li><code>Alt-Left/Right</code> 切换窗口</li>
<li><code>Shift-Left/Right/Up/Down</code> 在切分的窗口间切换</li>
<li><code>Shift-F3/F4</code> 在切分的窗口间切换</li>
</ul>
</li>
<li><code>F5</code> 重载 profile，刷新数据</li>
<li><code>F6</code> 关闭会话，但是在 Mac 上键盘是冲突的</li>
<li><code>F7</code> 进入滚动模式，用来查看历史记录</li>
<li><code>F8</code> 给当前的窗口重命名，方便以后辨认</li>
<li><code>F9</code> 启动 byobu 配置窗口<ul>
<li><code>Ctrl-F9</code> 输入命令，并且在所有的窗口中执行</li>
<li><code>Shift-F9</code> 输入命令，并且在所有的切分面板中执行</li>
</ul>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>就我个人的使用体验来说，byobu 在 tmux 的基础上把一些常用操作的逻辑和按键进行了优化，比方说窗口切换就从原来的两组按键变成了一个。不过工具这个东西，还是要按照个人喜好，见仁见智了，不过更多选择更多欢笑，至少 byobu 好看呀。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="http://byobu.co/" target="_blank" rel="external">Byobu 官网</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果你觉得 tmux 或者 screen 的快捷键设置反人类，那么 Byobu 就是一个让你重新热爱终端的理由。&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="终端" scheme="http://wdxtub.com/tags/%E7%BB%88%E7%AB%AF/"/>
    
      <category term="Byobu" scheme="http://wdxtub.com/tags/Byobu/"/>
    
  </entry>
  
  <entry>
    <title>【Redis 实战】读书笔记</title>
    <link href="http://wdxtub.com/2016/09/20/redis-in-action-clip/"/>
    <id>http://wdxtub.com/2016/09/20/redis-in-action-clip/</id>
    <published>2016-09-20T13:14:40.000Z</published>
    <updated>2016-09-20T13:18:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>Redis 是一个速度非常快的非关系型数据库，可以将存储在内存的键值对数据，可以使用复制特性来扩展性能，还可以使用客户端分片来扩展写性能。这本书从消灭瓶颈、简化代码、收集数据、分发数据、构建实用程序出发，并最终帮助读者更轻松地完成构建软件的任务。</p>
<a id="more"></a>
<hr>
<p>Redis 是一个速度非常快的非关系型数据库，可以将存储在内存的键值对数据，可以使用复制特性来扩展性能，还可以使用客户端分片来扩展写性能。</p>
<p>与 memcached 的不同：memcached 只能存储普通的字符串键，而 Redis 因为有不同的数据结构，能解决更广泛的问题，并且既可以用作主数据库使用，又可以作为其他存储系统的辅助数据库使用</p>
<p>Redis 每种数据类型都有自己的专属命令，另外还有批量操作(bulk operation)和不完全(partial)的事务支持。发布与订阅、主从复制、持久化、脚本</p>
<p>使用 Redis 而不是关系数据库或者其他硬盘存储数据库，可以避免写入不必要的临时数据，也免去了对临时数据进行扫描或者删除的麻烦，并最终改善程序的性能。</p>
<p>消灭瓶颈、简化代码、收集数据、分发数据、构建实用程序，并最终帮助读者更轻松地完成构建软件的任务</p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>类型 - 结构存储的值 - 结构的读写能力</p>
<p>STRING - 可以是字符串、整数或者浮点数 - 对整个字符串或者字符串的其中一部分执行操作；对整数和浮点数执行自增或者自减操作</p>
<p>LIST - 一个链表，链表上的每个借点都包含了一个字符串 - 从链表的两端推入或者弹出元素；根据偏移量对链表进行修剪(trim)；读取单个或者多个元素；根据值查找或者移除元素</p>
<p>SET - 包含字符串的无序收集器(unordered collection)，并且被包含的每个字符串都是独一无二、各不相同的 - 添加、获取、移除单个元素；检查一个元素是否存在于集合中；计算交集、并集、差集；从集合里面随机获取元素</p>
<p>HASH - 包含键值对的无序散列表 - 添加、获取、移除单个键值对；获取所有键值对</p>
<p>ZSET - 字符串成员(member)与浮点数分值(score)之间的有序映射，元素的排列顺序由分值的大小决定 - 添加、获取、删除单个元素；根据分值范围(range)或者成员来获取元素</p>
<h2 id="文章投票"><a href="#文章投票" class="headerlink" title="文章投票"></a>文章投票</h2><p>根据文章的发布时间、投票数量计算出一个评分，然后按照这个评分来决定如何排序和展示文章。</p>
<p>一些规则</p>
<ul>
<li>一篇文章如果获得了至少 200 张支持票，就认为是有趣的文章</li>
<li>有趣的文章需要放到前 100 位至少一天</li>
<li>评分是随时间流逝不断减少的</li>
<li>使用 Unix 时间</li>
<li>计算评分需要乘以一个常量，这个常量是 432，因为一天的秒数 86400 除以所需要的支持票 200 就是 432</li>
<li>每篇文章会使用一个散列来存储文章的标题、指向文章的网址、发布文章的用户、文章的发布时间、文章得到的投票数量等信息</li>
</ul>
<p>命名空间的构建一般可以用类别和编号来构成，可以用 <code>:</code>, <code>.</code>, <code>/</code>, <code>|</code> 之类的来做分隔符，主要要保证分隔符的一致性。</p>
<p>注意使用冒号创建嵌套命名空间的方法</p>
<p>使用两个有序集合来有序地存储文章：第一个有序集合的成员为文章 ID，分值为文章的发布时间；第二个有序集合的成员同样为文章 ID，而分值则为文章的评分。通过这两个有序集合，网站既可以根据文章发布的先后顺序来展示文章，又可以根据文章评分的高低来展示文章。</p>
<p>为了防止用户对同一篇文章进行多次投票，网站需要为每篇文章记录一个已投票用户名单。为此，程序将为每篇文章创建一个集合，并使用这个集合来存储所有已投票用户的 ID</p>
<p>为了尽量节约内存，我们规定当一篇文章发布期满一周之后，用户将不能对它进行投票，文章的评分将被固定下来，而记录文章已投票用户名单的集合也会被删除</p>
<p>群组功能由两个部分组成，一个部分负责记录文章属于哪个群组，另一个部分负责取出群组里面的文章。为了记录各个群组都保存了哪些文章，网站需要为每个群组创建一个集合，并将所有同属一个群组的文章 ID 都记录到那个集合里面</p>
<p>然后可以使用这个群组集合与分值的有序集合做 <code>ZINTERSTORE</code> 操作，就可以得到该群组里面文章的对应分值。这里最好把每次计算的结果保存 60 秒，避免短时间内大量的重复计算</p>
<h2 id="Web-应用中的-Redis"><a href="#Web-应用中的-Redis" class="headerlink" title="Web 应用中的 Redis"></a>Web 应用中的 Redis</h2><ul>
<li>基于令牌 cookie 和 Redis 一起实现的登录功能</li>
<li>利用 Redis 保存购物车信息，每个购物车都是一个散列，存储了商品 ID 与商品订购数量</li>
<li>缓存网页（不需要每次都进行渲染）</li>
<li>缓存数据行（尽量减少直接访问数据库的机会）</li>
<li>自动补全程序的数据源</li>
<li>构建分布式锁来提高性能（锁本身也可以带有超时）</li>
<li>开发计数信号量来控制并发</li>
<li>任务队列</li>
<li>消息拉取系统来实现延迟消息传递</li>
<li>文件分发</li>
</ul>
<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>要在 Redis 里面执行事务，我们首先需要执行 MULTI 命令，然后输入那些我们想要在事务里面执行的命令，最后再执行 EXEC 命令。当 Redis 从一个客户端那里接收到 MULTI 命令时，Redis 会将这个客户端之后发送的所有命令都放入到一个队列里面，直到这个客户端发送 EXEC 命令为止，然后 Redis 就会在不被打断的情况下，一个接一个地执行存储在队列里面的命令。从语义上来说，Redis 事务在 Python 客户端上面是由流水线实现的：对连接对象调用 pipeline() 方法将创建一个事务，在一切正常的情况下，客户端会自动地使用 MULTI 和 EXEC 包裹起用户输入的多个命令。此外，为了减少 Redis 与客户端之间的通信往返次数，提升执行多个命令时的性能，Python 的 Redis 客户端会存储起事务包含的多个命令，然后在事务执行时一次性地将所有命令都发送给 Redis。</p>
<p>MULTI 和 EXEC 事务的一个主要作用是移除竞争条件。</p>
<h2 id="过期时间"><a href="#过期时间" class="headerlink" title="过期时间"></a>过期时间</h2><p>只有少数几个命令可以原子地为键设置过期时间，并且对于列表、集合、散列和有序集合这样的容器来说，键过期命令只能为整个键设置过期时间，而没办法为键里面的单个元素设置过期时间（为了解决这个问题，本书在好几个地方都使用了存储时间戳的有序集合来实现针对单个元素的过期操作）</p>
<p>这部分需要深挖一下</p>
<h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><h3 id="快照"><a href="#快照" class="headerlink" title="快照"></a>快照</h3><p>Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。在创建快照之后，用户可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本，还可以将快照留在原地以便重启服务器时使用。</p>
<p>根据配置，快照将被写入 dbfilename 选项指定的文件里面，并存储在 dir 选项指定的路径上面。如果在新的快照文件创建完毕之前，Redis、系统或者硬件这三者之中的任意一个崩溃了，那么 Redis 将丢失最近一次创建快照之后写入的所有数据</p>
<p>在个人开发服务器上面，主要考虑的是尽可能地降低快照持久化带来的资源消耗。基于这个原因以及对自己硬件的信任，我只设置了 <code>save 900 1</code> 这一条规则。其中 <code>save</code> 选项告知 Redis，它应该根据这个选项提供的两个值来执行 <code>BGSAVE</code> 操作。在这个规则设置下，如果服务器距离上次成功生成快照已经超过了 900 秒，并且在此期间执行了至少一次写入操作，那么 Redis 就回自动开始一次新的 <code>BGSAVE</code> 操作。</p>
<p>如果你打算在生产服务器中使用快照持久化并存储大量数据，那么你的开发服务器最好能够运行在与生产服务器相同或者相似的硬件上面，并在这两个服务器上使用相同的 <code>save</code> 选项、存储相似的数据集并处理相近的负载量。把开发环境设置得尽量贴近生产环境，有助于判断快照是否生成得过于频繁或者过于稀少。</p>
<p>当 Redis 存储的数据量只有几个 GB 的时候，使用快照来保存数据是没有问题的。Redis 会创建子进程并将数据保存到硬盘里面，生成快照所需的时间比你读这句话所需的时间还要短。但随着 Redis 占用的内存越来越多，<code>BGSAVE</code> 在创建子进程时耗费的时间也会越来越多。如果 Redis 的内存占用量达到数十个 GB，并且剩余的空闲内存并不多，或者 Redis 运行在虚拟机上面，那么执行 <code>BGSAVE</code> 可能会导致系统长时间地停顿，也可能引发系统大量地使用虚拟内存，从而导致 Redis 的性能降低至无法使用的成都</p>
<p>执行 <code>BGSAVE</code> 而导致的停顿时间有多长取决于 Redis 所在的系统：对于真实的硬件、VMWare 虚拟机或者 KVM 虚拟机来说，Redis 进程每占用一个 GB 的内存，创建该进程的子进程所需的时间就要增加 10-20 毫秒；而对于 Xen 虚拟机来说，根据配置的不同，Redis 进程每占用一个 GB 的内存，创建该进程的子进程所需的时间就要增加 200-300 毫秒。</p>
<p>因此，如果我们的 Redis 进程占用了 20GB 的内存，那么在标准硬件上运行 <code>BGSAVE</code> 所创建的子进程将导致 Redis 停顿 200-400 毫秒；如果我们使用的是 Xen 虚拟机（亚马逊 EC2 和其他几个云计算供应商都使用这种虚拟机），那么相同的创建子进程操作将导致 Redis 停顿 4-6 秒。用户必须考虑自己的应用程序能否接受这种停顿。</p>
<p>为了防止 Redis 因为创建子进程二出现停顿，我们可以考虑关闭自动保存，转而通过手动发送 <code>BGSAVE</code> 或者 <code>SAVE</code> 来进行持久化。手动发送 <code>BGSAVE</code> 一样会引起停顿，唯一不同的是用户可以通过手动发送 <code>BGSAVE</code> 命令来控制停顿出现的时间。另一方面，虽然 <code>SAVE</code> 会一直阻塞 Redis 直到快照生成完毕，但是因为它不需要创建子进程，所以就不会像 <code>BGSAVE</code> 一样因为创建子进程而导致 Redis 停顿；并且因为没有子进程在争抢资源，所以 <code>SAVE</code> 创建快照的速度回避 <code>BGSAVE</code> 创建快照的速度要来得更快一些。</p>
<p>根据我的经验，在一台拥有 68GB 内存的 Xen 虚拟机上面，对一个占用 50GB 内存的 Redis 服务器执行 <code>BGSAVE</code> 命令的话，光是创建子进程就需要花费 15 秒以上，而生成快照则需要花费 15-20 分钟；蛋使用 <code>SAVE</code> 只需要 3-5 分钟就可以完成快照的生成工作。因为我的应用程序只需要每天生成一次快照，所以我写了一个脚本，让它在每天凌晨 3 点停止所有客户端对 Redis 的访问，调用 <code>SAVE</code> 命令并等待该命令执行完毕，之后备份刚刚生成的快照文件，并通知客户端继续执行操作。</p>
<p>如果用户能够妥善地处理快照持久化可能会带来的大量数据丢失，那么快照持久化对用户来说将是一个不错的选择，但对于很多应用程序来说，丢失 15 分钟的数据都将是不可接受的，在这种情况下，我们可以使用 AOF 持久化来存储在内存里面的数据尽快地保存到硬盘里面。</p>
<h3 id="AOF-持久化"><a href="#AOF-持久化" class="headerlink" title="AOF 持久化"></a>AOF 持久化</h3><p>简单来说，AOF 持久化会将被执行的写命令写到 AOF 文件的末尾，以此来记录数据发生的变化。因此，Redis 只要从头到尾执行一次 AOF 文件包含的所有写命令，就可以恢复 AOF 文件所记录的数据集。</p>
<p>在向硬盘写入文件时，至少会发生 3 件事。当调用 <code>file.write()</code> 方法对文件进行写入时，写入的内容首先会被存储到缓冲区，然后操作系统会在将来的某个时候将缓冲区存储的内容写入硬盘，而数据只有在被写入硬盘之后，才算是真正地保存到了硬盘里面。用户可以通过调用 <code>file.flush()</code> 方法来请求操作系统尽快地将缓冲区存储的数据写入硬盘里，但具体何时执行写入操作仍然由操作系统决定。除此之外，用户还可以命令操作系统将文件同步(sync)到硬盘，同步操作会一直阻塞直到指定的文件被写入硬盘为止。当同步操作执行完毕之后，即使系统出现故障也不会对被同步的文件造成任何影响。</p>
<p>如果用户使用 <code>appendfsync always</code> 选项的话，那么每个 Redis 写入命令都会被写入硬盘，从而将发生系统崩溃时出现的数据丢失减到最少。不过遗憾的是，因为这种同步策略需要对硬盘进行大量写入，所以 redis 处理命令的速度会受到硬盘性能的限制：机械硬盘在这种同步频率下每秒智能处理大约 200 个写命令，而固态硬盘每秒大概也只能处理几万个写命令。</p>
<p>使用固态硬盘的用户请谨慎使用 <code>appendfsync always</code> 选项，因为这个选项让 Redis 每次只写入一个命令，这种不断写入少量数据的做法可能会引发严重的写入放大(write amplification) 问题，在某些情况下甚至会将固态硬盘的寿命从原来的几年降低为几个月。</p>
<p>为了兼顾数据安全和写入性能，用户可以考虑使用 <code>appendfsync everysec</code> 选项，让 Redis 以每秒一次的频率对 AOF 文件进行同步。Redis 每秒同步一次 AOF 文件时的性能和不使用任何持久化特性时的性能相差无几。</p>
<p>为了解决 AOF 文件体积不断增大的问题，用户可以向 Redis 发送 <code>BGREWRIEAOF</code> 命令，这个命令会通过移除 AOF 文件中的冗余命令来重写 AOF 文件，使其体积尽可能小。</p>
<hr>
<p>使用复制和 AOF 持久化可以极大地保障数据安全；在多个客户端同时处理相同的数据时，可以使用 <code>WATCH</code>, <code>MULTI</code>, <code>EXEC</code> 等命令来防止数据出错。</p>
<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>通过 Redis 自带的性能测试程序 <code>redis-benchmark</code> 来了解 Redis 的性能特征</p>
<p><code>redis-benchmark -c 1 -q</code> 利用 <code>-q</code> 简化输出结果，给定 <code>-c 1</code> 让程序只使用一个客户端来进行测试</p>
<ul>
<li>单个客户端的性能达到了 redis-benchmark 的 50%~60% - 不使用流水线时的预期性能</li>
<li>单个客户端的性能达到了 redis-benchmark 的 25%~30% - 对于每个命令或者每组命令都创建了新的连接 - 通过重用已有的 Redis 连接解决</li>
<li>客户端返回错误 Cannot assign requested address - 对于每个命令或者每组命令都创建了新的连接 - 通过重用已有的 Redis 连接解决</li>
</ul>
<p>大部分 Redis 客户端都提供了某种级别的内置连接池（需要看看是否支持）</p>
<h2 id="基于搜索的应用程序"><a href="#基于搜索的应用程序" class="headerlink" title="基于搜索的应用程序"></a>基于搜索的应用程序</h2><ul>
<li>预处理：反向索引，parsing, tokenization, token, word</li>
<li>去 stop words</li>
<li>用户给出多个单词，就在多个单词对应的集合中求交集即可</li>
</ul>
<h2 id="广告定向"><a href="#广告定向" class="headerlink" title="广告定向"></a>广告定向</h2><p>广告服务器是一种小而复杂的技术。每当用户访问一个带有广告的 Web 页面时，Web 服务器和用户的 Web 浏览器都会向远程服务器发送请求以获取广告，广告服务器会接收各种各样的信息，并根据这些信息找出能够通过点击、浏览或动作获得最大经济收益的广告。</p>
<p>广告服务器需要接受一系列定向参数以便挑选出具体的广告，这些参数至少需要包含浏览者的基本位置信息（通常来源于 IP 地址）、浏览者使用的操作系统以及 Web 浏览器、可能还有浏览者正在浏览的页面的内容，甚至浏览者在当前网站上最近浏览过的一些页面。</p>
<p>广告预算：在典型的定向广告平台上面，每个广告通常都会带有一个随着时间减少的预算。一般来说，广告预算应该被分配到不同的时间上面，我发现的一种实用且有效的方法，就是基于小时数对广告的总预算进行划分，并在同一个小时的不同时间段把预算分配给不同的广告。</p>
<p>针对广告的索引操作和针对其他内容的索引操作并没有太大的不同。广告索引操作的特别之处在于它返回的不是一组广告或者一组搜索结果，而是单个广告；并且被索引的广告通常都拥有像位置、年龄或性别这类必须的定向参数。</p>
<p>接下来介绍的是基于位置和内容对广告进行索引的方法。我们先了解如何以一致的方式评估广告的价格。</p>
<h3 id="计算广告的价格"><a href="#计算广告的价格" class="headerlink" title="计算广告的价格"></a>计算广告的价格</h3><p>Web 页面上展示的广告主要有 3 种方式：按展示次数计费(cost per view)、按点击次数计费(cost per click)和按动作执行次数计费(cost per action)。按动作执行次数计费又称按购买次数计费(cost per acquisition)。按展示次数计费的广告又称 CPM 广告或按千次计费(cost per mille)广告，这种广告每展示 1000 次就需要收取固定的费用。按点击计费的广告又称 CPC 广告，这种广告根据被点击的次数收取固定的费用。按动作执行次数计费的广告又称 CPA 广告，这种广告根据用户在广告目的地网站上执行的动作收取不同的费用。</p>
<h3 id="让广告的价格保持一致"><a href="#让广告的价格保持一致" class="headerlink" title="让广告的价格保持一致"></a>让广告的价格保持一致</h3><p>为了尽可能地简化广告的计算方式，程序将对所有类型的广告进行转换，使得它们的价格可以基于每千次展示进行计算，产生出一个估算 CPM(estimated CPM)，简称 eCPM。对于 CPM 广告来说，因为这种广告已经给出了 CPM 价格，所以程序只要直接把它的 CPM 用作 eCPM 就可以了。至于 CPC 广告和 CPA 广告，程序则需要根据相应的规则为它们计算出 eCPM。</p>
<h3 id="计算-CPC-广告的-eCPM"><a href="#计算-CPC-广告的-eCPM" class="headerlink" title="计算 CPC 广告的 eCPM"></a>计算 CPC 广告的 eCPM</h3><p>对于 CPC 广告，程序只要将广告的每次点击架构乘以广告的点击通过率(click-through rate, CTR)，然后再乘以 1000，得出的结果就是广告的 eCPM（其中点击通过率可以用广告被点击的次数除以广告展示的次数计算得出）。举个例子，如果广告的每次点击价格为 0.25 美元，通过率为 0.2%(即0.002)，那么广告的 eCPM 为 0.25x0.002x1000=0.5 美元</p>
<h3 id="计算-CPA-广告的-eCPM"><a href="#计算-CPA-广告的-eCPM" class="headerlink" title="计算 CPA 广告的 eCPM"></a>计算 CPA 广告的 eCPM</h3><p>CPA 广告计算 eCPM 的方法和 CPC 广告计算 eCPM 的方法在某种程度上是相似的。程序只需要将广告的点击通过率、用户在广告投放者的目标页面上执行动作的概率、被执行动作的价格这三者相乘起来，然后再乘以 1000，得出的结果就是广告的 eCPM。举个例子，如果广告的点击通过率为 0.2%，用户执行动作的概率为 10%（即 0.1)，而广告的 CPA 为 3 美元，那么广告的 eCPM 为 0.002x0.1x3x1000=0.60 美元</p>
<h3 id="将广告插入索引"><a href="#将广告插入索引" class="headerlink" title="将广告插入索引"></a>将广告插入索引</h3><p>对广告进行定向需要用到一组定向参数，其中既有可选的参数，也有必须的参数。为了正确地进行广告定向，广告的索引必须考虑定向的需求。本节要实现的广告系统接受两个定向选项：位置和内容。其中位置选项（包括城市、州和国家）是必须的，而广告与页面内内容之间的任何匹配单词则是可选的，并且只作为广告的附加值存在。</p>
<h3 id="执行广告定向操作"><a href="#执行广告定向操作" class="headerlink" title="执行广告定向操作"></a>执行广告定向操作</h3><p>当系统收到广告定向请求的时候，它要做的就是在匹配用户所在位置的一系列广告里面，找出 eCPM 最高的那一个广告。除了基于位置对广告进行匹配之外，程序还会记录页面内容与广告内容的匹配程度，以及不同匹配程度的那些内容就回作为附加值被计入由 CPC 和 CPA 计算出的 eCPM 里面，使得哪些包含了匹配内容的广告能够更多地被展示出来。</p>
<p>在展示广告之前，系统不会为 Web 页面的任何内容设置附加值。但是当系统开始展示广告的时候，它就会记录下广告中包含的哪个单词改善或者损害了广告的预期效果，并据此修改各个可选的定向单词的相对价格。</p>
<h2 id="构建简单的社交网站"><a href="#构建简单的社交网站" class="headerlink" title="构建简单的社交网站"></a>构建简单的社交网站</h2><p>在用户与 Twitter 进行交互时，用户和状态消息这两类对象是最为重要的。用户对象存储了用户的基本身份标识信息、用户的关注者人数、用户已发布的状态消息数量等信息。用户对象对于社交网站来说非常重要，因为它是构建其他可用并且有趣的数据的起点。除了用户对象以外，状态消息也同样重要，因为它记录了不同的用户都说了些什么，以及不同用户之间进行了什么交互，这些由用户创建的状态消息是社交网站真正的内容。</p>
<p>用散列来存储用户信息，这些信息包括用户的用户名、用户拥有的关注者人数、用户正在关注的人的数量、用户已经发布的状态消息的数量、用户的注册日期以及其他一些元信息。</p>
<p>当一个新用户进行注册的时候，程序需要做的就是根据用户指定的用户名以及当时的时间戳，创建一个正在关注数量、关注者数量、已发布状态消息数量都被设置为 0 的对戏那个。</p>
<p>创建新用户的函数除了会对存储用户信息的散列进行初始化之外，还会对用户的用户名进行加锁，这个加锁操作是必须的，它可以防止多个请求在同一时间使用相同的用户名来创建新用户。在对用户名进行加锁之后，程序会检查这个用户名是否已经被其他用户抢先占用了，如果这个用户名尚未被占用的话，那么程序会为这个用户生成一个独一无二的 ID，并将用户名与用户 ID 进行关联，最后将这个用户信息存储到新创建的散列里面。</p>
<p>敏感的用户信息：因为程序会频繁地取出存储用户信息的散列用于渲染模板，或者直接用作 API 请求的回复，所以程序不能将散列吼的密码、邮件地址等敏感信息存储在这个用户信息散列里面。</p>
<p>程序既会将用户的个人信息存储到用户简介里面，又会将用户所说的话记录到状态消息里面，并且和存储用户个人信息时的方法一样，程序也使用散列结构来存储状态消息。</p>
<p>用户在已登录的情况下访问 Twitter 时，首先看到的是他们自己的主页时间线，这个时间线是一个列表，它由用户以及用户正在关注的人所发布的状态消息组成。因为主页时间线是用户访问网站时的主要入口，所以这些数据必须尽可能地易于获取。</p>
<p>我们希望能够尽快地获取展示一个页面所需的全部数据，因此我们决定使用有序集合来实现主页时间线，并使用有序集合的成员来记录状态消息的 ID，而有序集合的分值则用于记录状态消息发布时的时间戳。</p>
<p>因为主页时间线只存储了状态消息的 ID 而不是状态消息本身，所以负责获取最新发布的状态消息的函数除了要获取状态消息的 ID 之外，还需要根据所得的 ID 获取相应的状态消息数据。</p>
<p>用户的主页时间线和个人时间线都是由有序集合存储的，这些有序集合存储着状态消息的 ID 以及状态消息发布时的时间戳。用户的正在关注列表以及关注者列表同样由有序集合存储，其中有序集合的成员为用户 ID，而分值则记录了用户开始关注某人或者被某人关注时的时间戳。</p>
<p>当用户开始关注或者停止关注另一个用户的时候，程序就需要对这两个用户的正在关注有序集合以及关注者有序集合进行更新，并修改他们在用户信息散列里面记录的关注数量和被关注数量。如果用户执行的是关注操作，那么程序在对以上提到的有序集合和散列进行更新之后，还需要从被关注用户的个人时间线里面，复制一些状态消息 ID 到执行关注操作的用户的主页时间线里面，从而使得用户在关注另一个用户之后，可以立即看见被关注用户所发布的状态消息。</p>
<p>在关注某个人并阅读他的状态消息一段时间之后，用户可能会想要取消对那个人的关注。实现取消关注操作的方法和实现关注操作的方法正好相反：程序会从正在关注有序集合以及关注者有序集合里面移除关注者和被关注者双方的用户 ID，并从执行取消关注操作的用户的主页时间线里面移除被取消关注的人所发布的状态消息，最后对两个用户的正在关注数量以及关注者数量进行更新。</p>
<p>前面已经介绍了程序是如何创建新的状态消息的，而在此之后，程序要做的就是想办法把新状态消息的 ID 添加到每个关注者的主页时间线里面。具体的添加方式会根据消息发布人拥有的关注者数量的多少而有所不同。如果用户的关注者数量相对比较少，那么程序可以立即更新每个关注者的时间线。但是，如果用户的关注者数量非常庞大，那么直接执行添加操作将导致发布消息的用户需要长时间地进行等待，超出合理的等待时间。</p>
<p>为了让发布操作可以尽快地返回，程序需要做两件事情。首先，在发布状态消息的时候，程序会将状态消息的 ID 添加到前 1000 个关注者的主页时间线里面。剩余的会放到任务队列中进行执行延迟执行。</p>
<p>在开发社交网站的过程中，我们可能会想要知道更多网站上正在发生的事情——比如网站每个小时会发布多少条新的状态消息，网站上最热门的主题是什么，诸如此类。我们可以构建一些函数来广播简单的事件，然后由负责进行数据分析的事件监听器来接收并处理这些事件。</p>
<p>流 API 跟我们前面为了仿制 Twitter 而构建的其他部分完全不同，前面几节实现的 Twitter 典型操作都需要尽快地执行并完成，而流 API 请求则需要在一段比较长的时间内持续地返回数据。</p>
<p>在构建流 API 的过程中需要进行各种各样的决策，主要和以下三个问题有关：</p>
<ul>
<li>流 API 需要对外公开哪些事件</li>
<li>是否需要进行访问限制？如果需要的话，采取何种方式实现？</li>
<li>流 API 应该提供哪些过滤选项？</li>
</ul>
<p>我们的社交网站提供的过滤选项(filtering option)在特性和功能方面与 Twitter 为公开流(public stream)提供的 API 非常相似：用户既可以通过关注过滤器（基于用户进行过滤）、监测过滤器（基于关键字进行过滤）以及位置过滤器来获取过滤后的消息，又可以通过类似 Twitter 的消防水管(firehose)和样本(sample)这样的流来获取一些随机的消息。</p>
<p>每当新诞生的状态消息与过滤器相匹配的时候，流 APi 就会将这条消息返回给客户端。尽管 WebSockets 和 SPDY 这样的新技术可以以增量的方式不断地生成数据，甚至进行服务器端的消息推送，但是这些技术的相关协议并未完全制定好，而且很多编程语言的客户端也未能完全地支持这些新技术。幸运的是，只要使用分块(chunked)传输编码，我们就可以使用 HTTP 服务器生成并发送增量式数据。</p>
<h2 id="进阶内容"><a href="#进阶内容" class="headerlink" title="进阶内容"></a>进阶内容</h2><p>降低 Redis 内存占用的三种方法：</p>
<ul>
<li>短结构(short structure)</li>
<li>分片结构(shared structure)</li>
<li>打包存储二进制位和字节</li>
</ul>
<h3 id="短结构"><a href="#短结构" class="headerlink" title="短结构"></a>短结构</h3><p>Redis 为列表、集合、散列和有序集合提供了一组配置选项，这些选项可以让 Redis 以更节约空间的方式存储长度较短的结构。</p>
<p>在列表、散列和有序集合的长度较短或者体积较小的时候，Redis 可以选择使用一种名为压缩列表(ziplist)的紧凑存储方式来存储这些结构。压缩列表是列表、散列和有序集合这 3 种不同类型的对象的一种非结构化(unstructured)表示：与 Redis 在通常情况下使用双链表表示列表、使用散列表表示散列、使用散列表加上跳跃表(skiplist) 表示有序集合的做法不同，压缩列表会以序列化的方式存储数据，这些序列化数据每次被读取的时候都要进行解码，每次被写入的时候也要进行局部的重新，并且可能需要对内存里面的数据进行移动。</p>
<p>让键名保持简短！</p>
<h3 id="分片结构"><a href="#分片结构" class="headerlink" title="分片结构"></a>分片结构</h3><p>分片本质上就是基于某些简单的规则将数据划分为更小的部分，然后根据数据所属的部分来决定将数据发送到哪个位置上面。</p>
<p>程序不再是将值 X 存储到键 Y 里面，而是将值 X 存储到键 Y:<shardid> 里面。</shardid></p>
<p>对列表进行分片：想要在不使用 Lua 脚本的情况下对列表进行分片是非常困难的事。</p>
<h3 id="打包存储二进制位和字节"><a href="#打包存储二进制位和字节" class="headerlink" title="打包存储二进制位和字节"></a>打包存储二进制位和字节</h3><p>暂时略</p>
<h2 id="Lua-脚本"><a href="#Lua-脚本" class="headerlink" title="Lua 脚本"></a>Lua 脚本</h2><ul>
<li>通过 Redis 客户端可以载入 Lua 脚本</li>
<li>传递给 Lua 脚本的键和参数：尽管被载入程序包裹了起来，调用 Lua 脚本至少需要传递 3 个参数：第一个是必不可少的 Redis 连接，第二个是由任意多个键组成的列表，第三个是由任意多个需要传递给脚本的参数组成的列表</li>
<li>Lua 脚本跟单个 Redis 命令已经 <code>MULTI/EXEC</code> 事务一样，都是原子操作</li>
<li>已经对结构进行了修改的 Lua 脚本将无法被中断</li>
<li>Lua 重写锁的机制</li>
<li>移除 WATCH/MULTI/EXEC 事务</li>
<li>对列表进行分片</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis 是一个速度非常快的非关系型数据库，可以将存储在内存的键值对数据，可以使用复制特性来扩展性能，还可以使用客户端分片来扩展写性能。这本书从消灭瓶颈、简化代码、收集数据、分发数据、构建实用程序出发，并最终帮助读者更轻松地完成构建软件的任务。&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="实践" scheme="http://wdxtub.com/tags/%E5%AE%9E%E8%B7%B5/"/>
    
      <category term="Redis" scheme="http://wdxtub.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>欧洲『研究项目管理』相关公司小调查</title>
    <link href="http://wdxtub.com/2016/09/18/euro-project-company-guide/"/>
    <id>http://wdxtub.com/2016/09/18/euro-project-company-guide/</id>
    <published>2016-09-18T14:48:28.000Z</published>
    <updated>2016-09-18T14:50:23.000Z</updated>
    
    <content type="html"><![CDATA[<p>因为工作需要，对欧洲几个『研究项目管理』公司做了基本的调查，也大致了解基本的套路。作为刚刚接触这个领域的菜鸟，还是有很多基本的东西需要记录一下的。</p>
<a id="more"></a>
<hr>
<h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2><p>这类公司走的基本都是提供咨询跑腿写文档这类服务的路线，比较大一点的提供的服务齐全一些，从开始写 proposal 到具体的协商最后到项目的研发都可以在一旁打辅助。用他们的话说就是各种高大上的词汇：管理、人脉、训练、交流、沟通、协调、监督等等。</p>
<p>根据不同的合作程度，收费的方式也不大一样，有的是直接以『合作伙伴』的方式加入，拿走大约 7% 的经费；有的则是固定收费（收费标准得跟他们具体了解，不会明码标价写在网站上，似乎欧洲公司的风格就是如此）</p>
<p>这里主要介绍三家公司，它们的背景和资历都不大一样，涉及的业务方向也有差别，不过总体看来都是围绕着 European Commission 的相关项目进行的。接下来会简要介绍一下这三家公司。</p>
<h2 id="EURICE"><a href="#EURICE" class="headerlink" title="EURICE"></a>EURICE</h2><p>Eurice 公司成立与 2000 年，提供的围绕着研发项目的计划、启动、实施等服务，是德国最大的项目管理公司之一，总部在 Saarbrücken（位于德国，与法国的边境附近），2014 年在柏林开了分部。</p>
<p><img src="/images/14742101935820.jpg" alt=""></p>
<p>核心员工约 40 人，参与过的项目主要是疾病/医疗/癌症/生物/环保/农业/材料相关的。与我们公司的业务基本没有很多重合的部分，故暂时不予考虑。</p>
<h2 id="GABO-mi"><a href="#GABO-mi" class="headerlink" title="GABO:mi"></a>GABO:mi</h2><p>GABO:mi 成立于 2005 年，参与过 FP7, Horizon 2020 和 IMI 这几个大的研究项目，最近被 ATRRIC 公司收购（成立于 1987 年）。是 European Commission 认证的排名第一的公司（获得的 Agreements 最多）</p>
<p><img src="/images/14742101813143.jpg" alt=""></p>
<p>这家公司的合作方式比较特别，是以合作伙伴的方式来参与的，费用最多会占到整个项目经费的 7%。</p>
<p>另外一个优势是这家公司属于中小型公司(SME, small and medium-sized company)。在 European Commission 的计划中是有扶持的。</p>
<p>GABO:mi 在项目开始之前还提供以下服务:</p>
<ul>
<li>Grant Agreement(实际与 European Commission 进行接触)</li>
<li>Technical Annex(描述项目所需要完成的工作)</li>
<li>收集各类法律文件</li>
<li>Consortium Agreement(规范各个合作伙伴)</li>
<li>建立可持续的金融计划</li>
<li>遵守 EU 的规则和截止日期</li>
</ul>
<p>在提交 Proposal 阶段提供的服务有：</p>
<ul>
<li>基于多年经验的专家级知道建议</li>
<li>带细致描述的 proposal 模板</li>
<li>收集从各个合作伙伴公司获得的资料</li>
<li>预算准备</li>
<li>提供 EU Commission 的在线 proposal 系统的所有信息</li>
<li>与 EU commission  和 national contact points (NCP)</li>
</ul>
<p>如果 European Commission(EC) 给予了 proposal 积极评价的话，会进入协商阶段。GABO:mi 同样会提供全程的服务。包括：</p>
<ol>
<li>评估报告摘要，也就是 EC 的反馈和建议</li>
<li>GABO:mi 本身也会参与到 EC 给出评估报告的过程中</li>
<li>Annex I 准备，这是项目 proposal 的一个扩展，会根据 EC 的指南进行编写</li>
<li>协助进行各种文件的签署与提交</li>
</ol>
<h2 id="ZAZ-Ventures"><a href="#ZAZ-Ventures" class="headerlink" title="ZAZ Ventures"></a>ZAZ Ventures</h2><p>比较新的一个小公司，但是提供的服务是比较齐全的。需要先交一部分定金，后面的是根据申请情况来决定。</p>
<p>提供的服务有：</p>
<ul>
<li>不同项目的大致介绍，以及跟同领域的相关伙伴牵头（免费服务）</li>
<li>帮忙写 proposal（申请成功后按照一定比例收费）</li>
<li>由经验丰富的 EC 专家进行分析，提供完整的评估报告（必须申请成功，375 欧元/次）</li>
</ul>
<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><blockquote>
<p>研究经费是不是很晚才能到账？</p>
</blockquote>
<p>不是的，一般来说，在项目开始的时候会给 35% 的经费，不过从申请到项目正式开始的流程可能最多需要 8 个月才能完成。</p>
<blockquote>
<p>需要提前准备好大量的文档吗？</p>
</blockquote>
<p>​不是的，在获得 EC 的经费时候，需要填写一些报告，不过大部分的工作会由负责协调的公司来完成。</p>
<blockquote>
<p>EC 的经费算是贷款还是补贴吗？</p>
</blockquote>
<p>几乎所有的项目都是以补贴的形式进行的，意味着不需要提供对应的产权或偿还这笔钱。公司享有 100% 的所有权，唯一的责任是向 EC 提供项目的结果。</p>
<blockquote>
<p>完成一份好的 proposal 需要多久？</p>
</blockquote>
<p>不同的项目不一样，H2020 的 proposal 一般需要 400-600 小时，大部分工作会由研究项目管理公司完成，我们只需要不到 50 小时，提供具体的研究内容和审阅他们撰写的 proposal 草稿。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>不同的公司工作方式也不大一样，这类需要大量沟通和文书的工作最好还是有专人进行对接和负责，不能光看他们说什么，更重要的是他们怎么做。</p>
<p>个人感觉还是类似 GABO:mi 这种老牌公司稳定一些，但是对于小公司来说，也可能为了打响名声提供比老牌公司更走心的服务，还是要具体问题具体分析了。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="http://eurice.eu/" target="_blank" rel="external">EURICE</a></li>
<li><a href="http://gabo-mi.com/index.php" target="_blank" rel="external">GABO:mi</a></li>
<li><a href="http://www.zazventures.com/" target="_blank" rel="external">ZAZ Ventures</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;因为工作需要，对欧洲几个『研究项目管理』公司做了基本的调查，也大致了解基本的套路。作为刚刚接触这个领域的菜鸟，还是有很多基本的东西需要记录一下的。&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="欧洲" scheme="http://wdxtub.com/tags/%E6%AC%A7%E6%B4%B2/"/>
    
      <category term="公司" scheme="http://wdxtub.com/tags/%E5%85%AC%E5%8F%B8/"/>
    
      <category term="管理" scheme="http://wdxtub.com/tags/%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>第十四周 - 故梦</title>
    <link href="http://wdxtub.com/2016/09/16/old-dream/"/>
    <id>http://wdxtub.com/2016/09/16/old-dream/</id>
    <published>2016-09-16T09:49:07.000Z</published>
    <updated>2016-09-16T12:25:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>旧忆像一扇窗，推开再难合上。就这样去流浪，到美丽的地方。谁的歌声轻轻唱，谁的泪水静静淌，斜阳渐矮只影长，昏黄烛火轻摇晃。</p>
<a id="more"></a>
<hr>
<p>因为中秋假期，这周过得似乎特别快。工作之后，哪怕只是多休息一天，都有如此强的幸福感。虽然做的事情自己还蛮喜欢，不过确实比在学校里辛苦多了。话虽如此，当初选择回来就是要苦吾心智劳吾筋骨的，我心甘情愿接受挑战，和挑战过程中的所有磨难。接下来因为同事任性出去耍两周，所以要扛起俩项目了，希望不要出什么差错。</p>
<p>上周末恰逢生日，爸妈从广州来深圳陪我过，让这样一座人来人往脚步匆匆的城市于我有了些许家的感觉。晚上和几个要好的同事一起吃火锅，又在隔壁的日式甜品店里瞎胡照相，有这么一群一起疯疯癫癫的好朋友，真的很开心。</p>
<p>周是和我一起长大的兄弟，我们的生日也只差两天，还记得有一年的中秋是十二号，于是十一十二十三一连三天都成了节日。因为有太多太多回忆，真要我写下来，太难，不过倒是可以做几期播客节目（这事儿我都谋划了快一年半了，还是没正式启动，拖延症啊）。</p>
<p>跑步经过一段时间系统练习，已经有了不小的进步。关于跑步已经写过太多，不过跑得越多，体验也越新奇。越来越了解自己的节奏和极限在哪里，也越来越能够在快坚持不住的时候再坚持一下。晚睡和不节制的饮食就是会给身体带来巨大的负担，跑起来的每一步都会让自己意识到，对自己不负责是最悔恨的事情，因为只能眼睁睁看着自己被过去的自己落下，却什么也做不了。</p>
<p>不对，其实是能做点什么的，早睡早起，饮食清淡，坚持运动阅读写作思考，跑在正轨上很多时候就是每天类似的风景，但正式这种日复一日的坚持才让人蜕变。</p>
<p>趁着中秋节给老爸换了新手机，今天也把家里用了十多年的宽带换成了光纤（居然是大院里第一个接入的），终于也开始以自己的努力为家里做点贡献了。</p>
<p>这周其实还有一件事儿值得一提，就是我终于转正啦。最开心的居然是工牌终于可以有自己的照片了，一定要找一张狂拽酷炫屌炸天，力劈华山不要脸的图。慢慢掌握了工作的节奏，也就稍微游刃有余了起来，一边学习一边实践一边思考，能够有一个这么大的舞台让我瞎折腾，还是很开心的。</p>
<p>接着按照惯例通报一下各项事务的进度，</p>
<ul>
<li>大部分技术文章都加入了更新历史这个部分，因为随着自己学习的深入，还在不断补充和修正，自己能知道上次做到什么程度，大家看起来也比较有条理</li>
<li>写书的进度，目前确定了目录和章节，一共八章，还有三章就能完成 Alpha 版本，估计下周可以完成。然后就是正式的初稿、二稿，我的计划是从初稿开始交给出版社那边帮忙审审，因为也没真的写过书，估计这个阶段还需要比较多调整，希望自己能以最好的状态坚持下来</li>
<li>重构在生产环境中运行的代码，类似于空间站在太空升级，整个动态的过程不但需要考虑静态的存量，还需要处理好动态的增量，有难度，也非常有趣</li>
<li>架构的设计一定要谨慎，我一直认为，在前期架构思考上多花一个星期，可能后期开发和维护中可以节约三个月，这笔买卖很值</li>
</ul>
<p>最后祝贺天宫二号发射成功，航天人十年磨一剑，虽然我只能搞搞无人机，但是也会努力搞出些名堂的。</p>
<p>回忆像默片播放，刻下一寸一寸旧时光。团聚是一种微妙的心情，如果一定要描述，就是一觉醒来，很多东西，仿佛永远不会变。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;旧忆像一扇窗，推开再难合上。就这样去流浪，到美丽的地方。谁的歌声轻轻唱，谁的泪水静静淌，斜阳渐矮只影长，昏黄烛火轻摇晃。&lt;/p&gt;
    
    </summary>
    
      <category term="Gossip" scheme="http://wdxtub.com/categories/Gossip/"/>
    
    
      <category term="周记" scheme="http://wdxtub.com/tags/%E5%91%A8%E8%AE%B0/"/>
    
      <category term="工作" scheme="http://wdxtub.com/tags/%E5%B7%A5%E4%BD%9C/"/>
    
      <category term="中秋" scheme="http://wdxtub.com/tags/%E4%B8%AD%E7%A7%8B/"/>
    
  </entry>
  
  <entry>
    <title>写给爸爸妈妈的 iPhone 指南</title>
    <link href="http://wdxtub.com/2016/09/16/iphone-guide-for-parents/"/>
    <id>http://wdxtub.com/2016/09/16/iphone-guide-for-parents/</id>
    <published>2016-09-15T23:26:35.000Z</published>
    <updated>2016-09-16T06:54:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>给爸妈换新手机，好事儿。带他们走进移动新时代，开始享受互联网带来的各种便利，大好事儿。这也正是我写这篇文章的原因，用轻松易懂的方式替代繁琐的操作指南，生动形象做到知其所以然。</p>
<a id="more"></a>
<hr>
<p>更新历史</p>
<ul>
<li>2016.09.16: 初稿，基础应用使用</li>
</ul>
<p>本文的重点不是操作指南，重点是讲解基本的概念（当然会配上一些操作指南），这样即使遇到新情况，爸爸妈妈也可以利用这些基本概念来做出判断，或者自己摸索进行学习。简单来说，就是授人以渔。</p>
<p>当然，考虑到受众的特殊性，这里不会介绍特别新潮、小众、繁杂的应用，而专注于生活基本服务，主要着眼于简单易用和安全这两个方面。会随着爸爸妈妈水平的提高逐步更新。</p>
<h2 id="智能手机到底是个什么东西？"><a href="#智能手机到底是个什么东西？" class="headerlink" title="智能手机到底是个什么东西？"></a>智能手机到底是个什么东西？</h2><p>随着时代的发展，打电话和发短信基本成为了手机最不重要的功能。但是对于老一辈来说，可能智能手机仅仅意味着屏幕更大的功能机，只用来打电话发短信，最多再来个微信什么的。换句话说，移动时代年轻人习以为常的生活方式，爸爸妈妈们是不懂的。</p>
<p>造成这种现象的原因很多，首先是学习成本，时代发展很快，对于没怎么接触过智能手机的人来说，一上来就面对如此多的新概念，如此多的帐号，的确是很心累的事情；其次是媒体妖魔化般的报道，把智能手机搞得像洪水猛兽一样，的确，通过手机完成各类事情不如打电话到柜台那样有直接的反馈，也不如一手交钱一手交货那样简单粗暴，不过一点点安全上的牺牲换来的却是巨大的效率提升，况且经过不断发展，如果自己不起贪念再小心一点，是可以躲开大部分诈骗的。</p>
<p>之所以选择给爸爸妈妈买 iPhone，一是因为 iOS（iPhone 中的操作系统）的简单易用，二是没有安卓这么群魔乱舞。很高兴爸爸妈妈能主动学习来拥抱时代变化，我当然要大力支持，大力支持不只是嘴上说说，而是拿出实际行动，本文就是一点微小的工作。</p>
<h2 id="我要联网我要联网我要联网"><a href="#我要联网我要联网我要联网" class="headerlink" title="我要联网我要联网我要联网"></a>我要联网我要联网我要联网</h2><p>首先我们要知道，在大陆主要有三大运营商（也就是提供打电话发短信上网等服务的公司），它们是：</p>
<ul>
<li>中国移动</li>
<li>中国联通</li>
<li>中国电信</li>
</ul>
<p>所以，第一步要弄清楚不同的服务用的是哪个运营商。比方说我家的宽带用的是电信，那么联通和移动的宽带优惠就可以直接不看了。这里的宽带，指的是电脑和家里 WiFi 上网的服务，一般是按年签约续约的，可能的话就直接上光纤吧。</p>
<p>然后来说说手机上网，基本上这是 4G 的问题。如果平时只是上上微信看看新闻（视频最好还是连接 WiFi 才看）的话，基本上 50 元以下的套餐就可以满足了，比方说我刚刚看到的『4G飞享套餐（青春版）』，基本上就够用了。具体可以去营业厅问问业务员，但要小心被忽悠，40 块左右是合理的，在这个前提下尽量多一点流量就好。</p>
<p>这里的流量是什么意思呢？其实就是一种计费方式，指的是按照使用的数量来收费。比方说发微信需要发送和接收数据，这个数据的量就是流量。不同的操作所花费的流量是不同的，微信的文字消息所需要的流量很少，语音和图片就稍微大一些，而视频是最大的（所以在 4G 下看视频要慎重！）</p>
<p>流量的单位主要有三种：K, M 和 G。1 M = 1024 K。1 G = 1024 M。用具体的例子来说</p>
<ul>
<li>一条文字微信消息可能不到 1 K</li>
<li>一张图片/一条语音可能是几十 K</li>
<li>一个视频可能是几 M</li>
</ul>
<p><img src="/images/14739911099191.jpg" alt=""></p>
<p>这里的『闲时』流量，意思是深夜和清晨时候，使用 4G 是另外算的。可以认为每个月有几个不同的流量存折，平日白天使用，是从『国内通用流量』这个存折里取钱；而深夜或清晨，则是从『闲时』这个存折里取钱。</p>
<p>以防万一，最好还是在设置 -&gt; 蜂窝移动网络中限制一下可以使用 4G 的应用，如下图：</p>
<p><img src="/images/14739918145070.jpg" alt=""></p>
<h2 id="点击之外还有什么操作？"><a href="#点击之外还有什么操作？" class="headerlink" title="点击之外还有什么操作？"></a>点击之外还有什么操作？</h2><p>新的 iPhone 基本都支持一种新的操作，名为 3D Touch，实际上就是稍微大力一点按压屏幕。比方说，在主界面中（就是按 Home 键之后的页面），用力按压不同的应用图标，就会有不同的快捷菜单出来，类似于鼠标的右键。</p>
<p><img src="/images/14739930763978.jpg" alt=""></p>
<p>总是输密码其实特别心累，所以现在很多应用都支持指纹或声音进行识别。比方说微信的『声音锁』和支付宝的 Touch ID 登录</p>
<p><img src="/images/14739934698321.jpg" alt=""></p>
<p>另外，我们还可以按压屏幕左边来进行不同应用的切换</p>
<p><img src="/images/14739943909914.jpg" alt=""></p>
<p>用力按压可能是比较新的体验，多尝试几次就有感觉了。</p>
<h2 id="各类-App-是个什么魔法？"><a href="#各类-App-是个什么魔法？" class="headerlink" title="各类 App 是个什么魔法？"></a>各类 App 是个什么魔法？</h2><p>智能手机之所以强大，很大程度是因为可以自由下载安装各种各样的应用，也就是我们常说的 App，这些应用我们都需要在 App Store 中进行下载。</p>
<p><img src="/images/14739949883134.jpg" alt=""></p>
<p>这里需要输入我们的 Apple 帐号和密码（第一次需要输入密码，后面可以使用指纹）。这里我们来一个小测验，试试看把下面的应用都下载下来：</p>
<p><img src="/images/14740019138114.jpg" alt=""></p>
<p>然后我们就可以进入下一节了。</p>
<h2 id="这么多帐号是个什么情况？"><a href="#这么多帐号是个什么情况？" class="headerlink" title="这么多帐号是个什么情况？"></a>这么多帐号是个什么情况？</h2><p>不同的应用，就像不同的银行，我们想在对应的银行里办业务，首先要做的就是开户。所以，我们会发现：</p>
<ul>
<li>要用微信，需要注册微信帐号（因为和 QQ 一样也是腾讯的，所以用 QQ 号也行）</li>
<li>要用支付宝，需要注册支付宝帐号（因为和淘宝一样也是阿里巴巴的，所以用淘宝帐号也行）</li>
<li>要用京东，需要注册京东帐号</li>
<li>要用铁路12306，需要注册铁路12306帐号</li>
<li>要用航旅纵横（坐飞机的），需要注册航旅纵横帐号</li>
<li>要用携程，需要注册携程帐号</li>
</ul>
<p>这么多帐号，怎么办呢？我的做法是找个小本本，把不同应用的不同帐号都记下来。不过现在很多应用支持用微信/支付宝账户登录，这就方便很多</p>
<p><img src="/images/14739961953103.jpg" alt=""></p>
<p>点击左下角的微信图标，就有如下提示</p>
<p><img src="/images/14739963692353.jpg" alt=""></p>
<p>其他的应用无论是注册还是登录，基本大同小异，尝试一下就可以了。</p>
<h2 id="怕被骗？要怎么保护自己？"><a href="#怕被骗？要怎么保护自己？" class="headerlink" title="怕被骗？要怎么保护自己？"></a>怕被骗？要怎么保护自己？</h2><p>安全问题一定是爸爸妈妈最关心的，如何尽可能保护自己呢？下面是我总结的一些经验：</p>
<ul>
<li>看起来再真的消息，也可能是假的，除非百分百确定（比方说自己点击了获取验证码，然后收到了验证码）之外，尤其要注意：  <ul>
<li>不点击任何链接</li>
<li>不从非 App Store 的途径下载应用</li>
<li>不要见到二维码就扫一扫（除非是特定的可信场景）</li>
</ul>
</li>
<li>涉及金钱相关的操作，一定要核实后再确认，不要图省事儿（比方说朋友要你帮忙充话费，要想办法确认下）</li>
<li>天上不会掉馅饼，抽奖中奖什么的，百分之两百是假的，直接删掉就好</li>
<li>不随意添加陌生人</li>
<li>姓名、生日、证件号码、住址、职业、手机号等都是隐私，他人无法证明索取信息的合法合理性之前，请一律拒绝提供</li>
<li>发送到手机上的验证码切勿随意告诉别人</li>
<li>看不懂的选项一律选否\不同意\拒绝，千万不能看都不看就选 Yes</li>
<li>使用百度进行搜索的时候一定要注意，出来的第一个可能不是官方的链接，而是骗子花钱打的广告，专门来坑钱的。要问百度为什么这么不要脸，我也很纳闷，这样吸人血的公司居然还活着，我也很气愤。</li>
</ul>
<p>总而言之，防骗最好的防守就是不起贪念，最好的进攻就是多方查证，凡事多长个心眼总是好些。</p>
<h2 id="如何绑定银行卡？"><a href="#如何绑定银行卡？" class="headerlink" title="如何绑定银行卡？"></a>如何绑定银行卡？</h2><p>一般来说，建议在微信和支付宝中绑定一张余额较少的借记卡（用来转账，因为信用卡是无法转账的）和一张信用卡（用来消费）。然后就可以在支付的时候选择微信支付或者支付宝支付了。</p>
<p>微信支付中添加银行卡的方法是：</p>
<p><img src="/images/14740011748516.jpg" alt=""></p>
<p>在支付宝中添加银行卡的方法是：</p>
<p><img src="/images/14740015814794.jpg" alt=""></p>
<p>然后根据页面中的提示，输入指定的信息即可。添加完成之后，就可以把手机当钱包用了。</p>
<h2 id="如何把手机用成钱包？"><a href="#如何把手机用成钱包？" class="headerlink" title="如何把手机用成钱包？"></a>如何把手机用成钱包？</h2><p>在具体介绍流程之前，先简要说一下两种方式，一种是我们去扫商家提供的二维码，另一种是商家来扫我们的二维码。</p>
<p><strong>我们扫商家</strong></p>
<p>【我们扫商家】商家收银台有一个写着微信/支付宝的小牌子，上面印着一个二维码，我们扫描之后，就会有一个输入金额的页面，输入商家告知的金额然后支付，就算买单完成了。</p>
<p>如果是我们去扫商家提供的二维码，可以在主界面用力按压微信/支付宝的图标，在弹出来的菜单中选择『扫一扫』</p>
<p><img src="/images/14740027401647.jpg" alt=""></p>
<p>或者在微信/支付宝的程序中选择『扫一扫』功能：</p>
<p><img src="/images/14740031759423.jpg" alt=""></p>
<p><strong>商家扫我们</strong></p>
<p>【商家扫我们】商家收银员会拿着扫描枪来扫我们的二维码，我们只需要给出我们的二维码即可。</p>
<p>如果是商家来扫我们的二维码，我们同样有两种操作方式。第一种仍然是在主界面用力按压微信/支付宝的图标，然后选择『收付款』或『付款』</p>
<p><img src="/images/14740033214802.jpg" alt=""></p>
<p>如果是在应用中，可以通过如下操作：</p>
<p><img src="/images/14740035615559.jpg" alt=""></p>
<p>多试几次应该就没问题啦，先弄清楚到底是谁扫谁，剩下的就很简单了。</p>
<h2 id="如何用手机打车？"><a href="#如何用手机打车？" class="headerlink" title="如何用手机打车？"></a>如何用手机打车？</h2><p>用手机打车其实非常简单，打开『滴滴出行』，然后选择快车，确定一下上车地点和去哪里，如果觉得价格没问题，直接点击『呼叫快车』即可。</p>
<p><img src="/images/14740085230181.jpg" alt=""></p>
<p>然后师傅就会打电话跟我们联系，找个合适的地方上车即可，下车之后需要支付的话，直接选择微信/支付宝支持即可。</p>
<h2 id="衣食住行吃喝玩乐"><a href="#衣食住行吃喝玩乐" class="headerlink" title="衣食住行吃喝玩乐"></a>衣食住行吃喝玩乐</h2><p>这部分内容稍微有些难度，会根据爸爸妈妈的学习速度不断更新，目前打算写的主题有：</p>
<ul>
<li>饮食</li>
<li>购物</li>
<li>买票</li>
<li>酒店</li>
<li>旅游</li>
<li>电影</li>
</ul>
<p>如果有任何意见建议，比方说不同的主题，或者给爸爸妈妈看但是他们还是没办法看明白的话，欢迎评论告诉我，我争取写得更清楚些。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;给爸妈换新手机，好事儿。带他们走进移动新时代，开始享受互联网带来的各种便利，大好事儿。这也正是我写这篇文章的原因，用轻松易懂的方式替代繁琐的操作指南，生动形象做到知其所以然。&lt;/p&gt;
    
    </summary>
    
      <category term="Life" scheme="http://wdxtub.com/categories/Life/"/>
    
    
      <category term="互联网" scheme="http://wdxtub.com/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="iPhone" scheme="http://wdxtub.com/tags/iPhone/"/>
    
      <category term="指南" scheme="http://wdxtub.com/tags/%E6%8C%87%E5%8D%97/"/>
    
  </entry>
  
  <entry>
    <title>中秋、月饼与职业精神</title>
    <link href="http://wdxtub.com/2016/09/15/mooncake-festival-2016/"/>
    <id>http://wdxtub.com/2016/09/15/mooncake-festival-2016/</id>
    <published>2016-09-15T03:11:18.000Z</published>
    <updated>2016-09-15T10:28:39.000Z</updated>
    
    <content type="html"><![CDATA[<p>螺丝钉有了归属感与主人翁精神的话，很多时候就像电影中有了情感的机器人一样，结果都是被 neng 死。</p>
<a id="more"></a>
<hr>
<h2 id="关于月饼"><a href="#关于月饼" class="headerlink" title="关于月饼"></a>关于月饼</h2><p>中秋佳节，没想到一百多盒月饼引起了如此大的波澜。从知乎到微博再到朋友圈，从老江湖到小菜鸟再到学生党，不同群体的声音确实代表着不同群体的利益。</p>
<p>老江湖历经风风雨雨，看人看事特别透彻，尤其是工程师出身的，爱才之心溢于言表，有容人之心才能聚人，或者说，还是活人。</p>
<p>小菜鸟有的激愤，路见不平一声吼，声音大却说不准重点；有的屁股放错了位置，真以为替老板守护『价值观』就成了老板；还有的明哲保身，反正事不关己，安安心心过过日子。</p>
<p>学生党和实习党就不多说了，要么是书（尤其是历史书）读得太少，要么是太天真烂漫。估计只有自己摔几个跟头才能明白，遇到这种我基本都懒得解释，毕竟解释了也没用嘛。</p>
<p>思来想去，还是觉得要发出自己的声音，权利都是自己争取来的，从天上掉下来的是施舍，不是福利。我的观点其实就一句：</p>
<p><strong>所谓公平、所谓道德、所谓价值观，不过是有目的的人拿来的冠冕堂皇的工具罢了。</strong></p>
<p>真要较真的，去《史记》，再不济《三国演义》里就有太多太多你要的答案。只能说，一小部分程序员不要走白左圣母小清新的路线，该斗争就要斗争，程序正义和用爱发电这一套已经不好使了，还是国际歌写得好——『起来全世界受苦的人！满腔的热血已经沸腾，要为真理而斗争！』</p>
<p>最后再转一发和菜头的微博：</p>
<blockquote>
<p>在互联网世界里，程序员就是巫师，大众就是麻瓜。巫师的事情和大众根本说不清楚，因为做大众太容易，懂得道德判断就可以了。所以，程序员宁愿去网站Github写程序交基友，也懒得和大众啰B嗦。而程序员组建起来的技术公司，也天然地压制各种麻瓜，推崇巫师文化。没有什么扁平化管理，不过是厌恶麻瓜罢了</p>
</blockquote>
<p>是不是很眼熟？合金装备里的 Outer Heaven 也就是这么个意思。</p>
<h2 id="关于职业精神"><a href="#关于职业精神" class="headerlink" title="关于职业精神"></a>关于职业精神</h2><p>可能因为之前读了点历史书，工作之后，只缘此山中后，对于公司和社会的认识反而更深刻了。虽然有些不愿意承认，但跟相对单纯的校园相比，确实是一摊浑水。不过我的目标绝不是摸鱼，而是把事情做好。所以看到知乎上一句话特别有同感：</p>
<blockquote>
<p>我无法接受的是那一撮迎合高层癖好，拿着鸡毛当令箭，整天溜须拍马，今天看这个不爽，明天瞧那个有问题，不停搞阶级斗争的红卫兵们。</p>
</blockquote>
<p>他们压根儿不是蠢，就是™坏。所有的属于不属于你的屎盆子都会往你头上扣，这时候他们绝不会想起所谓的公平。或者说，符合他们利益的，才是公平。</p>
<p>不黑不吹，就我接触过程序员，技术水平和领域因人而异，但是对待工作是非常严谨认真的，尤其是重任在肩的时候，宁可睡在公司也要保证服务正常。而在工作之外，更多是随意的，拖鞋短裤小背心，游戏饮料肉松饼。用这种小事化大的方式来处理，真的是以阶级斗争为纲了。照这个套路，我都不敢写代码了，写个 bug 是不是就是企图颠覆公司了？</p>
<p>不过这也让我对职业精神有了更加深刻的认识，归属感和主人翁精神看起来那么诱人，但真因为锐意进取捅了篓子，天天洗脑灌输企业价值观的老板们两个小时就可以把你一脚踢开。</p>
<p>在大公司里，对于新人来说，一没有股份，二没有期权，拿着一点儿死工资还会被各种理由东扣扣西扣扣，很多时候却依然操着卖白粉的心，不是为了什么升官发财，只不过是心中还怀着憧憬。大老板们用响亮的耳光昭告天下：我们要的是没有灵魂没有情感的机器人，活生生的人也请按照机器人的标准表现。</p>
<p>当然，这不是要把个人和企业完全对立起来，只是觉得干什么事儿还是要带着脑子，主观能动不是主观乱动，不在其位不谋其政。职业精神这事儿，堂堂正正，问心无愧就好。归属感和主人翁精神终究是属于自己的，要有自己的方向，合则同路，异则扬镳。江湖嘛，好聚好散，相逢何必曾相识呢？</p>
<p>话是这么说，但估计平日里工程师们还是会怀揣着对这个世界最原初的热爱，努力捣鼓努力前进。只是希望大家能多一些理解，很多时候正是因为这样的『单纯』和『小孩子气』，才让我们一直坚持着。如果可能，请不要用那些充满恶意的有罪推定给我们加上莫须有的罪名。</p>
<h2 id="关于中秋"><a href="#关于中秋" class="headerlink" title="关于中秋"></a>关于中秋</h2><p>最后，祝大家中秋快乐，和家人团聚，比几盒月饼重要多了。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="https://www.zhihu.com/question/50600301" target="_blank" rel="external">如何看待阿里巴巴安全部门的月饼事件？</a></li>
<li><a href="https://www.zhihu.com/question/50608658" target="_blank" rel="external">由月饼事件，你对阿里的价值观有什么看法？</a></li>
<li><a href="https://www.zhihu.com/question/50659896" target="_blank" rel="external">如何看待阿里“月饼门”中最后一人（第五人）也被开除的事情？</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;螺丝钉有了归属感与主人翁精神的话，很多时候就像电影中有了情感的机器人一样，结果都是被 neng 死。&lt;/p&gt;
    
    </summary>
    
      <category term="Gossip" scheme="http://wdxtub.com/categories/Gossip/"/>
    
    
      <category term="中秋" scheme="http://wdxtub.com/tags/%E4%B8%AD%E7%A7%8B/"/>
    
      <category term="月饼" scheme="http://wdxtub.com/tags/%E6%9C%88%E9%A5%BC/"/>
    
      <category term="2016" scheme="http://wdxtub.com/tags/2016/"/>
    
  </entry>
  
  <entry>
    <title>Mac CLI 指南</title>
    <link href="http://wdxtub.com/2016/09/12/mac-cli-guide/"/>
    <id>http://wdxtub.com/2016/09/12/mac-cli-guide/</id>
    <published>2016-09-12T13:22:47.000Z</published>
    <updated>2016-09-13T11:32:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>终于，Mac 上有了一款能用命令行自由操作各种软件获取各种系统信息的工具 —— Mac CLI，废话不多说，赶紧来看看它的强大威力（但是并不推荐）。</p>
<a id="more"></a>
<hr>
<p>更新记录</p>
<ul>
<li>2016.09.12: 初稿</li>
</ul>
<h2 id="安装与删除"><a href="#安装与删除" class="headerlink" title="安装与删除"></a>安装与删除</h2><p>安装方式非常简单，一行即可 <code>sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/guarinogabriel/mac-cli/master/mac-cli/tools/install)&quot;</code>。安装完成之后需要各种配置一下，可以根据个人需要进行选择，我主要挑选了常用的工具类插件，诸如 MySQL 之类的都没有装（因为不需要）</p>
<p>删除的话也是一句 <code>sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/guarinogabriel/mac-cli/master/mac-cli/tools/uninstall)&quot;</code></p>
<p>不过之前安装的各种小插件如果有强迫症可能也需要删除</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">pip uninstall glances</div><div class="line">npm uninstall --global fast-cli</div><div class="line">brew uninstall pv</div></pre></td></tr></table></figure>
<p>其他就看心情随意啦</p>
<h2 id="快速入门"><a href="#快速入门" class="headerlink" title="快速入门"></a>快速入门</h2><p>这类工具的使用都是非常简单的（但是功能多了反而有些繁琐），输入 <code>mac list</code> 就可以查看各种命令，非常长，给大家感受一下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># dawang @ wdxtub in ~/Documents/Blog [16-09-12 21:29:11]</span></div><div class="line">$ mac list</div><div class="line"></div><div class="line"> mac CLI – OS X <span class="built_in">command</span> line tools <span class="keyword">for</span> developers</div><div class="line">====================================================</div><div class="line"></div><div class="line">General Utilities:</div><div class="line">mac update: Install OS X software updates, update installed Ruby gems, Homebrew, npm and their installed packages</div><div class="line">mac lock: Lock</div><div class="line">mac restart: Restart OS X</div><div class="line">mac sleep: Sleep mode</div><div class="line">mac shutdown: Shutdown</div><div class="line">mac time: Show clock at top right position <span class="keyword">in</span> Terminal/iTerm</div><div class="line">mac uptime: Get the time since last restart</div><div class="line">mac volume: Get the volume from the terminal</div><div class="line">mac volume X: Set the volume from the terminal - X = Level (0-100)</div><div class="line">mac volume:mute: Mute volume</div><div class="line">mac volume:unmute: Unmute volume</div><div class="line">mac volume:ismute: Check <span class="keyword">if</span> the volume is muted or not</div><div class="line">mac screensaver: Start screensaver</div><div class="line">mac folders:list: List folders <span class="keyword">in</span> current directory with their current size</div><div class="line">mac folder:size: Calculate current folder size</div><div class="line">mac folders:remove-empty: Remove empty subdirectories</div><div class="line">mac apps:close-all: Close all opened apps</div><div class="line">mac apps:app-store: Get list of installed apps from App Store</div><div class="line">mac eject-all: Eject all mounted volumes and disks</div><div class="line">mac battery: Get battery information</div><div class="line">mac info: Get OS X version information</div><div class="line">mac find:text X: Find exact phrase recursively inside directory - X = Text string</div><div class="line">mac find:biggest-files : Find biggest files inside directory</div><div class="line">mac find:biggest-directories : Find biggest directories inside directory</div><div class="line">mac zip:extract X: Extract Zip file to current folder - X = Zip file to extract</div><div class="line">mac gzip:compress X: Compress current file using Gzip - X = File to compress</div><div class="line">mac gzip:extract X: Extract Gzip file to current folder - X = Gzip file to extract</div><div class="line">mac tar:compress X: Compress X file/directory using tar with progress indicator - X = File or directory</div><div class="line">mac tar:extract X: Extract tar file to current folder - X = Tar file to extract</div><div class="line"></div><div class="line"></div><div class="line">Search Utilities:</div><div class="line">mac find:recent X: Find files modified <span class="keyword">in</span> the last N minutes - X = number of minutes</div><div class="line">mac search:replace X: Search and replace string <span class="keyword">in</span> file - X = File to perform the search and replace operation</div><div class="line"></div><div class="line"></div><div class="line">Network Utilities:</div><div class="line">mac speedtest: Internet connection speed <span class="built_in">test</span></div><div class="line">mac speedtest:infinite: Run internet speed <span class="built_in">test</span> each 5 minutes</div><div class="line">mac ports: List of used ports</div><div class="line">mac ip:<span class="built_in">local</span>: Get <span class="built_in">local</span> IP address</div><div class="line">mac ip:public: Get public IP address</div><div class="line">mac dhcp:renew: Renew DHCP Lease</div><div class="line">mac dns:clear: Clear DNS Cache</div><div class="line"></div><div class="line"><span class="comment"># 省略</span></div><div class="line">LAMP Utilities:</div><div class="line"></div><div class="line">SSH Utilities:</div><div class="line">mac ssh:download-file X: Download file from remote server through SSH - X = Path of the remote file to download</div><div class="line">mac ssh:download-folder X: Download entire folder from remote server through SSH - X = Path of the remote folder to download</div><div class="line">mac ssh:download-database X: Download database from remote server through SSH - X = Name of the database to download</div><div class="line">mac ssh:sync:<span class="built_in">local</span> X: Sync <span class="built_in">local</span> folder with remote folder using rsync through SSH (download remote folder to <span class="built_in">local</span> folder)</div><div class="line">mac ssh:sync:remote X: Path of the remote folder to sync from <span class="built_in">local</span> folder (upload <span class="built_in">local</span> folder to remote folder)</div><div class="line">mac ssh:upload X: Upload file to remote server through SSH - X = Path of the file to upload to the remote server</div><div class="line">mac ssh:public-key X: Get public SSH key <span class="keyword">for</span> <span class="built_in">local</span> machine</div><div class="line"></div><div class="line"></div><div class="line">Web Development Utilities:</div><div class="line">mac dev:monitor X: Monitor file changes (<span class="keyword">for</span> example: <span class="built_in">log</span> file) - X = File to monitor</div><div class="line">mac dev:optimize-images: Optimize all images <span class="keyword">in</span> current directory and subdirectories</div><div class="line">mac dev:css:convert-to-scss: Convert CSS file to SCSS</div><div class="line"></div><div class="line"></div><div class="line">Performance and maintenance Utilities:</div><div class="line">mac system: Show system information to review mac performance</div><div class="line">mac temp: Show temperature, fan and battery statistics</div><div class="line">mac memory: See memory usage sorted by memory consumption</div><div class="line">mac trash:empty: Empty trash</div><div class="line">mac trash:size: Calculate trash size</div><div class="line">mac desktop:cleanup: Remove all files and directories from the Desktop directory</div><div class="line">mac downloads:cleanup: Remove all files and directories from the Downloads directory</div><div class="line"></div><div class="line"></div><div class="line">iTerm / Terminal Utilities:</div><div class="line">mac iterm:tab-title: Set title to current iTerm tab</div><div class="line"></div><div class="line"></div><div class="line">Git Utilities:</div><div class="line">mac git:config: Display <span class="built_in">local</span> Git configuration</div><div class="line">mac git:open: Open current repository on Github</div><div class="line">mac git:create:branch: Create branch based on current branch</div><div class="line">mac git:branches:date: Get last update date <span class="keyword">for</span> all branches <span class="keyword">in</span> current project</div><div class="line">mac git:undo-commit: Undo latest commit</div><div class="line">mac git:<span class="built_in">log</span>: See latest commits IDs and titles <span class="keyword">for</span> current branch</div><div class="line">mac git:branch: See all branches</div><div class="line">mac git:branch:rename: Rename Git branch</div><div class="line">mac git:branch:remove-local: Remove <span class="built_in">local</span> Git branch</div><div class="line">mac git:branch:remove-remote: Remove <span class="built_in">local</span> and remote Git branch</div><div class="line">mac git:removeecho mac git:branch: See all branches : Remove Git from current project</div><div class="line">mac git:config: Check Git settings</div><div class="line">mac git:add-removed: Add removed files to staged files</div><div class="line">mac git:size: Get size <span class="keyword">for</span> current Git repository</div><div class="line"></div><div class="line"></div><div class="line">Web Utilities:</div><div class="line">mac web:download-images: Download all images from website to current directory</div><div class="line"></div><div class="line"></div><div class="line">Homebrew Utilities:</div><div class="line">mac brew:update: Upgrade Homebrew, installed Homebrew packages, and cleanup</div><div class="line"></div><div class="line"></div><div class="line">Xcode Utilities:</div><div class="line">mac xcode:cleanup: Cleanup XCode files to free up hard disk space</div><div class="line"></div><div class="line"></div><div class="line">Image Utilities:</div><div class="line">mac image:generate:mobile-app-icons X Y: Generate mobile app icons - X = Path of the original image file, Y= Path of the output file path</div><div class="line"></div><div class="line"><span class="comment"># 省略</span></div><div class="line">Magento Utilities:</div></pre></td></tr></table></figure>
<p>有这么多命令，而且现在还支持插件，完全可以根据自己的需要来自定义了，不懂的话直接 <code>mac help</code> 即可，非常方便。不过考虑到我的内存有限，还是挑一些我个人觉得比较常用的分享给大家，其他比较鸡肋的就不介绍了（比方说显示个时间什么的，就有点蛋疼了）</p>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><ul>
<li><code>mac update</code> 更新各类软件，包括 ruby gems, homebrew, npm 和对应的包，不过基本需要翻墙</li>
<li><code>mac lock</code> 锁屏，有动画效果</li>
<li><code>mac restart</code> 重启</li>
<li><code>mac sleep</code> 睡眠</li>
<li><code>mac shutdown</code> 关机</li>
<li><code>mac hidden:show</code> 显示隐藏文件</li>
<li><code>mac hidden:hide</code> 关闭显示隐藏文件</li>
<li><code>mac zip:extract filename</code> zip 解压</li>
<li><code>mac gzip:compress [file|folder]</code> gzip 压缩文件/文件夹</li>
<li><code>mac gzip:extract filename</code> gzip 解压</li>
<li><code>mac tar:compress [file|folder]</code> tar 压缩文件/文件夹</li>
<li><code>mac tar:extract filename</code> tar 解压</li>
<li><code>mac speedtest</code> 测试网速</li>
<li><code>mac ports</code> 显示被占用的端口（其实就是 <code>sudo lsof -iTCP -sTCP:LISTEN -P</code>）</li>
<li><code>mac ip:local</code> 显示内网 ip（其实就是 <code>ipconfig getifaddr en0</code>）</li>
<li><code>mac ip:public</code> 显示外网 ip（其实就是 <code>wget http://ipinfo.io/ip -qO -</code>）</li>
</ul>
<p>总体来说，基本可以认为是把各个常用的命令封装了一次，用统一的接口暴露出来，但是因为我的需求没这么多，其实直接用 zsh 的 alias 就足够了（所以最终我还是删掉了它）</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>经过短暂的使用，感觉这个工具和我的风格不太符合，比方说明明我用 <code>date</code> 命令就可以获取到当前的时间，为什么还要用 <code>mac time</code> 来呢？明明可以直接 <code>ls -lh</code> 来查看文件大小，为什么要用 <code>mac folders:list</code> 呢？明明可以直接 <code>du -h -d 1</code> 来查看当前文件夹里所有内容的大小，为什么要用 <code>mac folder:size</code> 呢？总有种脱裤子放屁的感觉。</p>
<p>还是更喜欢或许是『莫须有』的对自己电脑的『掌控力』，那么如果觉得这些命令太长太难记，完全可以自己实现一套嘛。我还是喜欢简单一点的语法，命令里有冒号简直是『大逆不道』。</p>
<p>当然，如果是新手，但是又想通过一系列风格统一的命令来（自动化）管理电脑的话，这个还是还可以考虑的。不过相信懂得越多，就越不需要这类看起来很有用的『工具』了吧。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="https://github.com/guarinogabriel/mac-cli/" target="_blank" rel="external">guarinogabriel/Mac-CLI</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;终于，Mac 上有了一款能用命令行自由操作各种软件获取各种系统信息的工具 —— Mac CLI，废话不多说，赶紧来看看它的强大威力（但是并不推荐）。&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="Mac" scheme="http://wdxtub.com/tags/Mac/"/>
    
      <category term="工具" scheme="http://wdxtub.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>祝我生日快乐 - 2016</title>
    <link href="http://wdxtub.com/2016/09/11/new-born-2016/"/>
    <id>http://wdxtub.com/2016/09/11/new-born-2016/</id>
    <published>2016-09-10T23:20:45.000Z</published>
    <updated>2016-09-11T01:08:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>我走过山的时候山不说话，我路过海的时候海不说话。</p>
<a id="more"></a>
<hr>
<p>生日，是在给自己一个机会向过去告别的同时，以一种颇有仪式感的方式开启一段新的旅程。错过了 25 次这样的机会之后，我终于在 2016 年生日当天的清晨，以文字为马，启程了。从校园到社会的转变，也在今天正式完成。于我，每天都是新生，只是今天也许是不一样的新。</p>
<p>特别感谢爸爸妈妈给我走出国门的机会，让我得以跳脱出去，看看自己在这个国家的位置，看看国家在世界的位置。我意识到了对个人对国家的责任，感觉到了轰轰烈烈的变化，酝酿出了去超越的欲望。</p>
<p>脚下这片大地，切切实实让我感受到了规模的力量。面对尚未固化的市场，我们甚至有机会去定制规则，去让技术超越科技本身，成为文化的一部分。需求是巨大的，资源是有限的，新的车库精神和浪潮在酝酿，从最初的模仿，到目前的改进，相信在不久的将来，我们会成为引领时代的弄潮儿。</p>
<p>一个人的命运啊，当然要靠自我奋斗，但是也要考虑到历史的行程。回头望，才发现历史的脚步从未停止。『探索发现』频道的纪录片『运行中国(How China Works)』中有两个片段给我留下了特别深刻的印象。</p>
<p>一是上海的三座摩天大厦。首先是金茂大厦，分层的金字塔式收束象征着传统；其次是上海环球金融中心，开瓶器式造型暗含着打开国门向外学习；最后是上海中心大厦，我们用内外结合的分层层叠的垂直都市花园完成了设计的超越，在传统与现代，钢铁与自然间找到了某种平衡。</p>
<p>二是平塘在建的世界最大球面射电望远镜，科研团队花了十年时间，从三百个地方选中了平塘。建成之后，我们有机会真正把目光投入到没有人见过的地方，甚至是宇宙的边界。全球各地优秀的科学家会因为这只『眼睛』，更多以中国为中心来开展合作和研究，我们在逐渐找回属于自己的地位。</p>
<p>国家如此，个人亦是如此。有各种各样的不足，但一口吃不成个胖子，需要循序渐进改正；有各种各样的成绩，但像投篮一样，差一点就是差百分之百，没有松懈的理由。</p>
<p>希望自己在新的一岁中：从零开始，带着侠客的精神，用更加成熟和冷静的方式回归初心，用最真诚的方式扛起责任赢得信任，用少年般勇敢且浪漫的方式面对危机接受使命。遇到困境和挫折，主动从自己身上找原因，不推托，不懈怠。更加专注，培养自己对信息的敏锐度和钻研精神，发展自己的见解和主张，坚持自己的兴趣，做出有价值的产品。</p>
<p>希望自己在新的一岁中：更加关注人与人之间的连接，努力进入更大的圈子，用个人的努力把文化和艺术的概念带给大家，开始属于我们的文艺复兴时代。坚持开源和分享精神。接触不同的人群，了解不同领域的信息，去探索那些不知道自己不知道的区域，不要把所有的事情都功利化。</p>
<p>希望自己在新的一岁中：完成自己的第一本书，在计算机基础教育领域进行真正的尝试，用责任心和事业心把工作做好。并以此为切入点锻炼自己去适应社会理解社会，低调踏实，在实战中强化自己解决问题的能力。学会倾听他人的意见不说没有依据的话，节约大家的时间，真正以平等的心态做事。避免处在一个我们表现得越愚蠢，它就提供越多回报的变态激励系统之中。</p>
<p>希望自己在新的一岁中：保持乐观和好奇的心态，世间不公之事甚多，面对不公之事，去想这件事应不应该，有没有改进的空间。避免陷入嫉妒、怨憎、仇恨和自怜的思想状态中。仇恨和自怜都是灾难性的思想状态。过度自怜可以让人近乎偏执，偏执是最难逆转的东西之一。生活中的每一次不幸，无论多么倒霉，都是一个锻炼的机会。不应该在自怜中沉沦，而是应该利用每次打击来提高自我。</p>
<p>希望自己在新的一岁中：找到情投意合的另一半，共同为将来努力。无论如何要照顾好自己，规律作息，节制饮食，坚持运动，花更多时间在重要的人身上。</p>
<p>愿望许完了，祝自己生日快乐。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我走过山的时候山不说话，我路过海的时候海不说话。&lt;/p&gt;
    
    </summary>
    
      <category term="Life" scheme="http://wdxtub.com/categories/Life/"/>
    
    
      <category term="生日" scheme="http://wdxtub.com/tags/%E7%94%9F%E6%97%A5/"/>
    
      <category term="新生" scheme="http://wdxtub.com/tags/%E6%96%B0%E7%94%9F/"/>
    
  </entry>
  
  <entry>
    <title>第十三周 - 上海三月</title>
    <link href="http://wdxtub.com/2016/09/10/march-in-shanghai/"/>
    <id>http://wdxtub.com/2016/09/10/march-in-shanghai/</id>
    <published>2016-09-09T16:15:35.000Z</published>
    <updated>2016-09-09T17:06:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>甜甜莓茶醉，悠悠春雨喂，问寻难走心中一片白；风飞进，灯光残，忘却茶香独生叹，唯有时光难消亡。</p>
<a id="more"></a>
<hr>
<p>这周工作特别忙，三个项目并行，虽然只有其中一个我是负责人，但是另外俩需要开会沟通协调催促，不得不占据我许多时间，实话说，还不如写代码来得轻松愉快。不过借此机会认识了不少不同部门的同事，找机会还是可以多去请教下各方面的知识，也是挺不错的。</p>
<p>事情一多，原来习惯的依赖记忆和感觉来做事儿的方法已经不堪重负。虽然也还没有溢出，但是我依然不喜欢这种无头苍蝇哪个急做哪个的做事方式，所以也开始用任务管理软件了。就这两天的体验来说，非常不错，至少各个项目的需求能够一一理清并且完成了（实在完成不了的就往后排期嘛）。</p>
<p>因为写代码的时间非常宝贵，所以我会在设计上花更多的时间，争取每一行代码都发挥真正的价值，而不是拍脑袋设计最终导致成倍时间的浪费。不过在公司里写代码，有的时候直接给出没什么 bug 线上可以一直稳定运行的程序反而会让不明真相的人觉得你的工作没什么技术含量，因为一切都显得理所当然。奇怪的是，那些线上整天出问题，大家忙忙叨叨不过是为了把本应该一次做好的工作做好，在不懂的人看来竟是『上心』和『努力』的象征，这就有点搞笑了。</p>
<p>所以说一个好的技术人员不但应该技术做得好，更应该让别人知道之所以线上服务能够快速上线并且不出问题不是因为问题简单，而是因为经验积累和全面思考得到的解决方案靠谱，更不是天天低效加班做那些『看起来很努力』的事情能够比得上的。如果不扭转这种外行看内行的心态，恐怕只会劣币驱逐良币，最终大家事不关己高高挂起，毕竟人往高处走嘛。</p>
<p>最近两周，在我负责的项目上，平时对接的美国团队基本撒手不管了。这™就很尴尬了，从需求到构思设计，从开发到部署测试，一人分饰多角。不过这样也好，沟通成本基本为零了，我也很注意文档和注释的编写，一个人扛就一个人扛呗，唯一影响的可能就是项目进度，毕竟在质量上我还是对自己有要求的。</p>
<p>周中原来的 CMU 同学从美国回来办事儿，一起在公司附近吃了一顿饭，有朋自远方来，不亦乐乎。毕业之后老同学再想见面真的很需要缘分，只是希望能聚的时候，不要因为懒或者天气而轻易放弃。这段时间在公司里也交到了不少新朋友，情投意合且都有强迫症洁癖的同事合作起来非常轻松愉快，能够感受到的技术积累和深入思考，三人行必有我师，要以老司机为榜样，努力提升自己。</p>
<p>说到这个，这周起也开始了自己在代码上比较系统的技术积累（之前以写博客居多），也参考各种技能树大概制定了自己技术发展的路径。这种又有新挑战开启的感觉，既刺激又紧张还能收获很多，想想还有点小激动呢。希望能在一年之内取得让自己满意的成绩。</p>
<p>制定目标 -&gt; 努力训练 -&gt; 坚持不懈 -&gt; 最终突破，这其实是非常靠谱的成长方式，这周我的跑步目标终于初步达成，配速终于在四分三十秒之内了，比大学和研究生的时候每公里都快了一分多钟。看到自己成绩的时候，真的有些不可思议，原本以为要到今年年底才能达到的速度，居然提前三个多月完成了，我算了一下，只要每三步比原来的自己快一秒，每公里所花费的时间就可以少一分钟。不要想着目标有多大有多难，专注每一次呼吸和每一次步伐，一直向前就好了。</p>
<p>鞋脏了又如何，袜子湿了又如何，刮风下雨又如何？大国重器，真正的成绩，真正的改变，就是要经得起各种考验。</p>
<p>下周就要转正了，很高兴能在这个关头完成新的改变，我也做好了所有的准备，等待真正成长起来的那一天。</p>
<p>是雨潺潺，不问窗外寒；孤衾影，长夜莫过知己难，往事已故此景谁还在；世事漫随流水，算来一梦浮生。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;甜甜莓茶醉，悠悠春雨喂，问寻难走心中一片白；风飞进，灯光残，忘却茶香独生叹，唯有时光难消亡。&lt;/p&gt;
    
    </summary>
    
      <category term="Gossip" scheme="http://wdxtub.com/categories/Gossip/"/>
    
    
      <category term="朋友" scheme="http://wdxtub.com/tags/%E6%9C%8B%E5%8F%8B/"/>
    
      <category term="周记" scheme="http://wdxtub.com/tags/%E5%91%A8%E8%AE%B0/"/>
    
      <category term="工作" scheme="http://wdxtub.com/tags/%E5%B7%A5%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>个人技能发展指南</title>
    <link href="http://wdxtub.com/2016/09/09/wdx-skill-set/"/>
    <id>http://wdxtub.com/2016/09/09/wdx-skill-set/</id>
    <published>2016-09-08T22:28:58.000Z</published>
    <updated>2016-09-09T15:08:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>工作也有一段时间了，基本上也参与到了公司除硬件外的各条业务与研发线，在具体的学习和开发过程中也逐渐有了对未来的认知。这里以技能树的方式来给自己定简单的规划。</p>
<a id="more"></a>
<hr>
<p>本文的主要技能点来自 StuQ 的云计算工程师/研发工程师/大数据工程师必备技能这三种，按照我个人的喜欢和判断进行了糅合。</p>
<h2 id="开发"><a href="#开发" class="headerlink" title="开发"></a>开发</h2><ul>
<li>命令行工具: tmux(screen), vim, zsh(oh-my-zsh), git</li>
<li>操作系统: Ubuntu, macOS</li>
<li>语言: Go, Java(maven, gradle), Python(pip, ipython), Javascript(node.js), Ruby(gem)</li>
<li>文档: markdown</li>
<li>编辑器: Visual Studio Code</li>
<li>流程: Scrum, Crystal, FDD</li>
<li>持续集成: Jenkins</li>
<li>协作: Teambition, Slack, Trello</li>
</ul>
<h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><ul>
<li>数据结构: JSON, cPickle, protobuf</li>
<li>网络: TCP/IP, VLANs, DNS, CDN, HTTP/HTTPS 协议</li>
<li>调度<ul>
<li>crontab 最原生的定时调度</li>
<li>基于 redis 实现的分布式调度</li>
<li>基于 rpyc 实现的分布式调度</li>
<li>celery/gearman 等调度</li>
</ul>
</li>
<li>并发<ul>
<li>协程 gevent</li>
<li>线程池</li>
<li>多进程 os.fork, idea multiprocessing</li>
</ul>
</li>
<li>调试<ul>
<li>pdb, logging, Sentry, lsof, strace, trace</li>
<li>top, htop, free, iostat, vmstat, ifconfig, iftop</li>
</ul>
</li>
<li>算法<ul>
<li>一致性: Paxos, Raft, Gossip</li>
<li>数据结构: 栈、队列、链表, 散列表, 二叉树、红黑树、B 树, 图</li>
<li>常用算法: 插入排序, 桶排序, 堆排序, 快速排序, 最大子数组, 最长公共子序列, 最小生成树, 最短路径, 矩阵的存储和运算</li>
</ul>
</li>
</ul>
<h2 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h2><ul>
<li>云计算: SaaS/PaaS/Iaas, Openstack, Docker</li>
<li>大数据通用处理平台: Spark, Hadoop, ELK</li>
<li>资源调度: Yarn, Mesos</li>
<li>SQL: MySQL, Sqlite, AWS RDS, PostgreSQL </li>
<li>NoSQL: MongoDB, Cassandra, DynamoDB, MongoDB, HBase</li>
<li>缓存: Memcached, Redis, AWS ElastiCache</li>
<li>检索: Solr, ElasticSearch, AWS ElasticSearch </li>
<li>数据分析: Pig, Hive, Spark SQL, Spark DataFrame, Impala, Phoenix,  ELK</li>
<li>消息队列: Kafka, RocketMQ, ZeroMQ, ActiveMQ, RabbitMQ</li>
<li>流式计算: Storm/JStorm, Spark Streaming, AWS Kinesis</li>
<li>日志收集: ELK, Scribe, Flume, Fluentd, AWS CloudTrail</li>
<li>机器学习: Mahout, Spark Mlib, TensorFlow(Google), Amazon Machine Learning, DMTK(MS), scikit learn</li>
</ul>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><ul>
<li>计算<ul>
<li>自动扩展: AWS Autoscaling, OpenStack/Hoo!</li>
<li>负载均衡: AWS ELB, HAProxy, Nginx</li>
<li>虚拟化: Hypervisor, Xen, KVM, Hyper-V</li>
<li>容器: Docker, CoreOS, UnixLXC</li>
</ul>
</li>
<li>分布式消息<ul>
<li>消息队列: ZeroMQ, ActiveMQ, RabbitMQ, AWS SQS</li>
<li>事件/消息驱动: AWS SWS, AWS Lambda, AKKA</li>
<li>RPC: Thrift, Protobuf</li>
</ul>
</li>
<li>存储<ul>
<li>网络存储: AWS EBS, NFS v4, Ceph, Apache CloudStack</li>
<li>对象存储: AWS S3, OpenStack Swift</li>
<li>块存储: SAN, AWS EBS, RAID 概念</li>
<li>灾难恢复</li>
<li>文件系统: ext4, XFS</li>
</ul>
</li>
<li>安全: Firewall, DDoS, iptables, WAF, IDS/IPS, VPN</li>
<li>身份认证: SAML, OpenID, Microsoft AD, AWS IAM</li>
<li>监控: ZABBIX, OBSERVIUM, INICGA, AWS CloudWatch<ul>
<li>系统, 日志, 流量, 接口, 数据库</li>
</ul>
</li>
<li>理论: Microservices, RESTful, CAP</li>
<li>设计: 扩展性, 可用性, 可靠性, 一致性, 负载均衡, 过载保护</li>
<li>协议: 二进制协议, 文本协议</li>
<li>接入层: DNS 轮训, 动静态分离, 静态化, 反向代理, LVS, F5, CDN<ul>
<li>nginx, apache, lighttpd, tomcat</li>
</ul>
</li>
<li>逻辑层: 连接池, 串行化, 批量写入, 配置中心, 去中心化</li>
<li>数据层: 缓存优化, DAO, ORM, 双主架构, 主从同步, 读写分离</li>
<li>同步通讯: RPC, RMI</li>
<li>异步通讯: MQ, Cron</li>
<li>性能优化<ul>
<li>代码层: 关联代码优化, cache 对齐, 分之预测, Copy on Write, 内联优化</li>
<li>工具: OProfile, Gprof, JDK 工具</li>
<li>系统优化: 缓存, 延迟计算, 数据预读, 异步, 轮询与通知, 内存池, 模块化</li>
</ul>
</li>
<li>测试: 单元测试, 接口测试, 性能测试, 集成测试</li>
</ul>
<h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><ul>
<li>核心: Docker, LXC, RunC, Rkt, Systemd-nspawn, Hyper, VMWare Photon, Jetpack, Kurma, Bosh</li>
<li>监控: Sysdig, Guardrail, cAdvisor</li>
<li>管理: DockerUI, Kitematic, Decking.io, Shipyard, StackEngine, Panamx, Fabric8, Triton</li>
<li>基础设施集成: Nova-docker, Magnum, Clocker, Machine, MaestroNG, CloudFoundry Containers Service Broker, Mesos, Fit2Cloud, Boot2Docker</li>
<li>编排调度: Crane, Compose, Swarm, Yarn, Kubernets, Fleet, Marathon, OpenShift, GearD, Rancher</li>
<li>平台: Alauda, DaoCloud, TenxCloud, CSphere, AWS Container Service, Google Container Engine, StackDock, Orchard, Quay.io, Baremetal.io, Tutum, Giant Swarm</li>
<li>服务发现: Consul, Etcd, Zookeeper, SkyDNS, Skydock</li>
<li>日志收集: Splunk, Elasticsearch, Logstach, Kibana, Heka, Fluent, Flume</li>
<li>相关发行版: CoreOS, Project Atomic, RancherOS, ClearLinux</li>
<li>容器 PaaS: Dokku, Deis, Voxoz, Flynn, Octohost</li>
<li>容器网络: Pipework, Flannel, Calico, Weave, Socketplane.io, Pertino, Nuage</li>
<li>容器安全: Notary, SELinux on docker</li>
<li>数据持久化: Flocker, Ceph</li>
<li>开发流程工具: Drone.io, Shippable, Runnable, NodeChecker, Jenkins Docker plugin, Wercker, Totem, Packet, Docker Repository, Packer</li>
</ul>
<h2 id="运维"><a href="#运维" class="headerlink" title="运维"></a>运维</h2><ul>
<li>DevOps: SSH 证书, Fabric, SaltStack, puppet, pssh/dsh, 运维进阶</li>
<li>部署: 蓝绿部署, 灰度发布, 金丝雀发布, Canary 部署, PHOENIX 部署, AWS CloudFormation</li>
<li>基础服务: LAMP/LNMP, FTP, DNS, SAMBA, EMAIL, NTP, DHCP</li>
<li>配置: Chef, Puppet, Ansible, AWS OpsWorks, Nagios, Zabbix, Cacti, SaltStack, pssh/dsh, Fabric</li>
<li>安全: iptables, ipset</li>
<li>网络: TCP/IP, tcpdump</li>
</ul>
<p><img src="/images/14734336749159.jpg" alt=""></p>
<p>引用自 <a href="http://www.brendangregg.com/linuxperf.html" target="_blank" rel="external">Brendan Gregg <linux performance="" analysis="" and="" tools=""></linux></a></p>
<h2 id="前端"><a href="#前端" class="headerlink" title="前端"></a>前端</h2><ul>
<li>语言: JavaScript/Node.js, TypeScript</li>
<li>编辑器: Vim, Visual Studio Code</li>
<li>调试工具: Chrome Dev Tools</li>
<li>框架: Vue.js, React, jQuery, Botostrap</li>
<li>规范: HTTP/1.1 RFCs 7230-7235, HTTP/2, ECMAScript 5/6/7, DOM/BOM/XHTML/XML/JSON/JSONP, CommonJS Modules, MicroData/RDFa</li>
<li>文档: JSDoc, Dox/Doxmate/Grunt-Doxmate</li>
<li>构建工具: make/ant, GYP, Grunt, Gulp, Yeoman, FIS, Mod, Webpack</li>
<li>安全: CSRF/XSS, CSP, Same-origin policy, ADsafe/Caja/Sandbox</li>
<li>移动: HTML5/CSS3, 响应式网页设计, Zeptojs/iScroll, React Native/Week</li>
</ul>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="https://github.com/TeamStuQ/skill-map" target="_blank" rel="external">StuQ 程序员技能图谱</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;工作也有一段时间了，基本上也参与到了公司除硬件外的各条业务与研发线，在具体的学习和开发过程中也逐渐有了对未来的认知。这里以技能树的方式来给自己定简单的规划。&lt;/p&gt;
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
    
      <category term="云计算" scheme="http://wdxtub.com/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
      <category term="技能树" scheme="http://wdxtub.com/tags/%E6%8A%80%E8%83%BD%E6%A0%91/"/>
    
      <category term="研发" scheme="http://wdxtub.com/tags/%E7%A0%94%E5%8F%91/"/>
    
  </entry>
  
</feed>
